model:
  class_path: trajdl.algorithms.t2vec.T2VEC
  init_args:
    embedding_dim: 256
    hidden_size: 256
    tokenizer:
      class_path: trajdl.tokenizers.t2vec.T2VECTokenizer.load_pretrained
      init_args:
        path: output/porto/tokenizer.pkl
    knn_indices_path: output/porto/knn_indices.npy
    knn_distances_path: output/porto/knn_distances.npy
    num_layers: 3
    bidirectional_encoder: True
    # embedding_path: output/porto/word2vec.model
    dropout: 0.2
    freeze_embedding: False

data:
  class_path: trajdl.datasets.modules.t2vec.T2VECDataModule
  init_args:
    tokenizer:
      class_path: trajdl.tokenizers.t2vec.T2VECTokenizer.load_pretrained
      init_args:
        path: output/porto/tokenizer.pkl
    train_src_path: output/porto/full_train_src.parquet
    train_trg_path: output/porto/full_train_trg.parquet
    val_src_path: output/porto/full_val_src.parquet
    val_trg_path: output/porto/full_val_trg.parquet
    train_batch_size: 256
    val_batch_size: 256
    num_train_batches: 1000
    buckets_boundaries:
      - [20, 30]
      - [30, 50]
      - [50, 70]
      - [70, 100]
    num_cpus: -1

seed_everything: 42

optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 1e-3

trainer:
  default_root_dir: output/porto
  max_epochs: 1000
  precision: 32-true
  gradient_clip_val: 0.1
  gradient_clip_algorithm: norm
  plugins:
    - class_path: lightning.pytorch.plugins.io.AsyncCheckpointIO
  callbacks:
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: val_loss
        mode: min
        patience: 20
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        save_top_k: 20
        monitor: val_loss
        mode: min
        filename: model-{epoch:03d}-{val_loss:.6f}