model:
  class_path: trajdl.algorithms.loc_pred.stlstm.STLSTMModule
  init_args:
    tokenizer:
      class_path: trajdl.tokenizers.locseq.LocSeqTokenizer.load_pretrained
      init_args:
        path: output/gowalla/tokenizer.pkl
    embedding_dim: 128
    hidden_size: 256
    ts_bucketizer:
      class_path: trajdl.tokenizers.slot.Bucketizer.load
      init_args:
        path: output/gowalla/ts_bucketizer.pkl
    loc_bucketizer:
      class_path: trajdl.tokenizers.slot.Bucketizer.load
      init_args:
        path: output/gowalla/loc_bucketizer.pkl
    use_sampled_softmax: true
    num_neg_samples: 128
    loc_emb_layer:
      class_path: trajdl.algorithms.embeddings.base.Word2VecEmbedding
      init_args:
        tokenizer:
          class_path: trajdl.tokenizers.locseq.LocSeqTokenizer.load_pretrained
          init_args:
            path: output/gowalla/tokenizer.pkl
        model_path: output/gowalla/word2vec.model

data:
  class_path: trajdl.datasets.modules.stlstm.STLSTMDataModule
  init_args:
    tokenizer:
      class_path: trajdl.tokenizers.locseq.LocSeqTokenizer.load_pretrained
      init_args:
        path: output/gowalla/tokenizer.pkl
    train_parquet_path: output/gowalla/train_ds.parquet
    val_parquet_path: output/gowalla/val_ds.parquet
    test_parquet_path: output/gowalla/test_ds.parquet
    train_batch_size: 256
    val_batch_size: 256
    num_cpus: -1
    num_train_batches: 100
    num_val_batches: 1000
    ts_bucketizer:
      class_path: trajdl.tokenizers.slot.Bucketizer.load
      init_args:
        path: output/gowalla/ts_bucketizer.pkl
    loc_bucketizer:
      class_path: trajdl.tokenizers.slot.Bucketizer.load
      init_args:
        path: output/gowalla/loc_bucketizer.pkl

seed_everything: 42

optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 1e-3
    weight_decay: 1e-5

trainer:
  default_root_dir: output/gowalla
  max_epochs: 1000
  precision: 32-true
  gradient_clip_val: 0.1
  plugins:
    - class_path: lightning.pytorch.plugins.io.AsyncCheckpointIO
  callbacks:
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: val_loss
        mode: min
        patience: 5
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        save_top_k: 3
        monitor: val_loss
        mode: min
        filename: model-{epoch:03d}-{val_loss:.6f}