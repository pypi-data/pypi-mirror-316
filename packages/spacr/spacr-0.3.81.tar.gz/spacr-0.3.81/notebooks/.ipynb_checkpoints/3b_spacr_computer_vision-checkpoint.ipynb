{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335dcd14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Description: use this cell to generate train and test folders: datasets/train/nc and pc and datasets/test/nc and pc\n",
    "from spacr.io import generate_training_dataset\n",
    "\n",
    "settings = {'src':'/nas_mnt/carruthers/yifan/Yifan_Einar screen/yifanUbtrial11h_20240705_184432/plate1', # (path) path to source folder (where origional images were stored)\n",
    "            'dataset_mode':'metadata_annotation', # (string) annotation, measurement, metadata, annotation_metadata\n",
    "            'tables':['cell'],# (list of strings) The tabels present in the database, excluding png_list\n",
    "            'test_split':0.1, # (float) Fraction of images used for the test set\n",
    "            'annotation_column':'test', # (Optional, string) If using mode annotation, The annotation column in the database\n",
    "            'annotated_classes':[1], # (Optional, list of integers) If using mode annotation, The interger in annotation_column, if len(annotated_classes) is 1, class 2 will be generated from a random selection of images.\n",
    "            'metadata_type_by':'column_name', # (Optional, strin) If using mode medatada, If using mode medatada,the column class_metadata elements are in\n",
    "            'class_metadata':['c10','c11','c12','c22','c23','c24'], # (Optional, list of lists of strings) If using mode medatada, the elements that deffine each class \n",
    "            'png_type':'cell_png', # (Optional, string) string in the path of each image (used to filter images)\n",
    "            'nuclei_limit':False, # (Optional, bool) if cell and nucleus in tables, filter for number of nuclei per cell\n",
    "            'pathogen_limit':0, # (Optional, integer) if cell and pathogen in tables, filter for number of pathogen per cell\n",
    "            'uninfected':True, # (Optional, bool) if cell and pathogen in tables, bool for uninfected cells (cells)\n",
    "            'size':None # (Optional, integer or NoneType) limit for number of images to include in total (test + train) per class\n",
    "           }\n",
    "\n",
    "generate_training_dataset(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4431164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models already downloaded to: /home/carruthers/anaconda3/envs/spacr/lib/python3.9/site-packages/spacr/resources/models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>src</td>\n",
       "      <td>/nas_mnt/carruthers/yifan/Yifan_Einar screen/y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>custom_model</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>classes</td>\n",
       "      <td>[nc, pc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model_type</td>\n",
       "      <td>maxvit_t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>optimizer_type</td>\n",
       "      <td>adamw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>schedule</td>\n",
       "      <td>reduce_lr_on_plateau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>loss_type</td>\n",
       "      <td>focal_loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>normalize</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>image_size</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>batch_size</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>epochs</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>val_split</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>learning_rate</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>weight_decay</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dropout_rate</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>init_weights</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>amsgrad</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>use_checkpoint</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gradient_accumulation</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gradient_accumulation_steps</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>intermedeate_save</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>pin_memory</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>n_jobs</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>train_channels</td>\n",
       "      <td>[r, g, b]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>augment</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>verbose</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dst</td>\n",
       "      <td>/nas_mnt/carruthers/yifan/Yifan_Einar screen/y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Key  \\\n",
       "0                           src   \n",
       "1                         train   \n",
       "2                          test   \n",
       "3                  custom_model   \n",
       "4                       classes   \n",
       "5                    model_type   \n",
       "6                optimizer_type   \n",
       "7                      schedule   \n",
       "8                     loss_type   \n",
       "9                     normalize   \n",
       "10                   image_size   \n",
       "11                   batch_size   \n",
       "12                       epochs   \n",
       "13                    val_split   \n",
       "14                learning_rate   \n",
       "15                 weight_decay   \n",
       "16                 dropout_rate   \n",
       "17                 init_weights   \n",
       "18                      amsgrad   \n",
       "19               use_checkpoint   \n",
       "20        gradient_accumulation   \n",
       "21  gradient_accumulation_steps   \n",
       "22            intermedeate_save   \n",
       "23                   pin_memory   \n",
       "24                       n_jobs   \n",
       "25               train_channels   \n",
       "26                      augment   \n",
       "27                      verbose   \n",
       "28                          dst   \n",
       "\n",
       "                                                Value  \n",
       "0   /nas_mnt/carruthers/yifan/Yifan_Einar screen/y...  \n",
       "1                                                True  \n",
       "2                                               False  \n",
       "3                                               False  \n",
       "4                                            [nc, pc]  \n",
       "5                                            maxvit_t  \n",
       "6                                               adamw  \n",
       "7                                reduce_lr_on_plateau  \n",
       "8                                          focal_loss  \n",
       "9                                                True  \n",
       "10                                                224  \n",
       "11                                                 64  \n",
       "12                                                100  \n",
       "13                                                0.1  \n",
       "14                                             0.0001  \n",
       "15                                            0.00001  \n",
       "16                                                0.1  \n",
       "17                                               True  \n",
       "18                                               True  \n",
       "19                                               True  \n",
       "20                                               True  \n",
       "21                                                  4  \n",
       "22                                               True  \n",
       "23                                               True  \n",
       "24                                                 30  \n",
       "25                                          [r, g, b]  \n",
       "26                                              False  \n",
       "27                                               True  \n",
       "28  /nas_mnt/carruthers/yifan/Yifan_Einar screen/y...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a network on channels: [1, 2, 3]\n",
      "Channel 1: Red, Channel 2: Green, Channel 3: Blue\n",
      "Loading Train and validation datasets\n",
      "Train data:4863, Validation data:541\n",
      "Generating Dataloader with 30 workers\n",
      "Train batches:76, Validation batches:9\n",
      "Using cuda for Torch\n",
      "Loading Model to cuda...ecture: maxvit_t init_weights: True dropout_rate: 0.1 use_checkpoint: True\n",
      "Training ...\n",
      "Progress: 1/100, operation_type: Training, Train Loss: 0.005, Val Loss: 0.048, Train acc.: 0.525, Val acc.: 0.530, Train NC acc.: 0.052, Val NC acc.: 0.067, Train PC acc.: 0.999, Val PC acc.: 0.993, Train PRAUC: 0.802, Val PRAUC: 0.794\n",
      "Progress: 2/100, operation_type: Training, Train Loss: 0.003, Val Loss: 0.021, Train acc.: 0.800, Val acc.: 0.791, Train NC acc.: 0.609, Val NC acc.: 0.611, Train PC acc.: 0.991, Val PC acc.: 0.970, Train PRAUC: 0.949, Val PRAUC: 0.930\n",
      "Progress: 3/100, operation_type: Training, Train Loss: 0.002, Val Loss: 0.039, Train acc.: 0.895, Val acc.: 0.876, Train NC acc.: 0.806, Val NC acc.: 0.793, Train PC acc.: 0.984, Val PC acc.: 0.959, Train PRAUC: 0.982, Val PRAUC: 0.965\n",
      "Progress: 4/100, operation_type: Training, Train Loss: 0.001, Val Loss: 0.006, Train acc.: 0.950, Val acc.: 0.906, Train NC acc.: 0.948, Val NC acc.: 0.904, Train PC acc.: 0.951, Val PC acc.: 0.908, Train PRAUC: 0.991, Val PRAUC: 0.974\n",
      "Nc class accuracy: 0.9481907894736842 Pc class Accuracy: 0.951048951048951\n",
      "Found: 94.0% accurate model\n",
      "Progress: 5/100, operation_type: Training, Train Loss: 0.000, Val Loss: 0.037, Train acc.: 0.945, Val acc.: 0.908, Train NC acc.: 0.904, Val NC acc.: 0.867, Train PC acc.: 0.986, Val PC acc.: 0.948, Train PRAUC: 0.993, Val PRAUC: 0.973\n",
      "Progress: 6/100, operation_type: Training, Train Loss: 0.000, Val Loss: 0.009, Train acc.: 0.977, Val acc.: 0.921, Train NC acc.: 0.979, Val NC acc.: 0.941, Train PC acc.: 0.974, Val PC acc.: 0.900, Train PRAUC: 0.997, Val PRAUC: 0.975\n",
      "Nc class accuracy: 0.9786184210526315 Pc class Accuracy: 0.9744960921431509\n",
      "Found: 95.0% accurate model\n",
      "Progress: 7/100, operation_type: Training, Train Loss: 0.001, Val Loss: 0.035, Train acc.: 0.963, Val acc.: 0.900, Train NC acc.: 0.997, Val NC acc.: 0.974, Train PC acc.: 0.929, Val PC acc.: 0.827, Train PRAUC: 0.998, Val PRAUC: 0.976\n"
     ]
    }
   ],
   "source": [
    "# Description: train a torch model\n",
    "from spacr.deep_spacr import train_test_model\n",
    "\n",
    "settings = {'src':'/nas_mnt/carruthers/yifan/Yifan_Einar screen/yifanUbtrial11h_20240705_184432/plate1/datasets/training', # (path) path to source folder (ends with datasets/training)\n",
    "            'train':True, # (bool) - Train\n",
    "            'test': False, # (bool) - Test\n",
    "            'custom_model':False, # (path) - path to a custom model\n",
    "            'classes':['nc','pc'], # (list) - list of classes (folder names in dataset/training/train or test)\n",
    "            'model_type':'maxvit_t', # (string) - Name of torch model architecture\n",
    "            'optimizer_type':'adamw', # (string) - type of optimizer\n",
    "            'schedule':'reduce_lr_on_plateau', # (string) - type of scheduler (reduce_lr_on_plateau or step_lr)\n",
    "            'loss_type':'focal_loss', # (string) - Loss function (binary_cross_entropy_with_logits or focal_loss)\n",
    "            'normalize':True, # (bool) - Apply ImageNet normalization to images before training.\n",
    "            'image_size':224, # (int) - Size of images, height and width.\n",
    "            'batch_size':64, # (int) - Nr. of images per batch\n",
    "            'epochs':100, # (int) - Nr. of epochs for training\n",
    "            'val_split':0.1, # (float) - Fraction of images in validation dataset\n",
    "            'learning_rate':0.0001, # (float) - Learning rate per epoch\n",
    "            'weight_decay':0.00001, # (float) - Fraction of random weights decay (regularization)\n",
    "            'dropout_rate':0.1, # (float) - Fraction of weights to omit per epoch (regularization)\n",
    "            'init_weights':True, # (bool) - Initiate model with ImageNet weights\n",
    "            'amsgrad':True, # (bool) - guard against exploding gradients\n",
    "            'use_checkpoint':True, # (bool) - checkpoint gradient calculations to save VRAM at the expence of computation\n",
    "            'gradient_accumulation':True, # (bool) - Accumulate gradients to mimic larger batches\n",
    "            'gradient_accumulation_steps':4, # (int) - Epochs to accumulate gradients\n",
    "            'intermedeate_save':True, # Save intermediate states of the model\n",
    "            'pin_memory':True, # (bool) - Whether to pin memory for the data loader\n",
    "            'n_jobs':30, # (int) - Number of threads to use\n",
    "            'train_channels':['r','g','b'], # (list of 'r', 'g', and/or 'b') - PNG channels to use for training\n",
    "            'augment':False, # (bool) - Augment the dataset, vertical, horizontal flip and rotate each image to artificially expand the dataset 8 fold.\n",
    "            'verbose':True}\n",
    "\n",
    "train_test_model(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770fb79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Description: generate a tar dataset\n",
    "\n",
    "from spacr.io import generate_dataset\n",
    "\n",
    "settings = {'src':'path', # (path) path to source folder (where origional images were stored)\n",
    "           'file_metadata':'cell_png', # (Optional, string) string in the path of each image (used to filter images)\n",
    "           'experiment':'test', # (string) - Name of dataset\n",
    "           'sample':10000} # (Optional, integer or NoneType) limit for number of images to include in the dataset\n",
    "\n",
    "generate_dataset(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086fcefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: apply a model to a tar dataset\n",
    "\n",
    "from spacr.deep_spacr import apply_model_to_tar\n",
    "\n",
    "settings = {'dataset':'path.tar', # (path) - path to tar dataset (ends with .tar) \n",
    "            'model_path':'path.pth', # (path) - path to model (ends with .pth) \n",
    "            'file_type':'cell_png', # (Optional, string) string in the path of each image (used to filter images)\n",
    "            'image_size':224, # (int) - Size of images, height and width\n",
    "            'batch_size':64, # (int) - Nr. of images per batch\n",
    "            'normalize':True, # (bool) - Apply ImageNet normalization to images before training.\n",
    "            'score_threshold':0.5, # (float) - Score to byass the classes\n",
    "            'n_jobs':30, # (int) - Number of threads to use\n",
    "            'verbose':True}\n",
    "\n",
    "result_df = apply_model_to_tar(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9916c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: Fit a regression model to estimate the effect size of gRNAs on cell scores.\n",
    "from spacr.ml import perform_regression\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "settings = {'count_data':'path', # (path) path or list of paths to sequencing count data\n",
    "            'score_data':'path', # (path) path or list of paths to score data\n",
    "            'score_column':'column', # () - column with cell scores\n",
    "            'metadata_files':['path.csv','path.csv'], # (list) pahts to gene metadata \n",
    "            'positive_control':'gene', # (string) - gene to highlight in volcano plot\n",
    "            'negative_control':'gene', # (string) - gene to highlight in volcano plot\n",
    "            'min_n':3, # () - \n",
    "            'fraction_threshold':None, # (Optional, float or NoneType) - Minimum threshold for gene fraction, if None automatically calculated\n",
    "            'target_unique_count':5, # () - Number of expected unique gRNAs per well\n",
    "            'tolerance':0.02, # (float) - Tollerance for cells per well limit\n",
    "            'log_x':False, # () - gRNA Fraction plot X axis log\n",
    "            'log_y':False, # () - gRNA Fraction plot Y axis log\n",
    "            'x_lim':None, # () - Volcano X axis limit\n",
    "            'control_wells':['c1','c2','c3'], # (list) - Metadata to exclude from regression model\n",
    "            'filter_column':'column', # (str) - Column containing control metadata to remove\n",
    "            'dependent_variable': 'column', # (string) - Dependent variable for regression\n",
    "            'threshold_method':'var', # (string) - effect size thresold type (std or var)\n",
    "            'threshold_multiplier':4, # (integer) - effect size threshold multiplyer \n",
    "            'transform':'log', # (string) - Transform dependent variable\n",
    "            'agg_type':'mean', # (string) - aggregation for dependent variable\n",
    "            'min_cell_count':None, # (integer) - Minimum number of cells per well\n",
    "            'regression_type':'ols', # (string) - Type of regression (ols, glm, mixed, ridge, lasso).\n",
    "            'random_row_column_effects':False, # (bool) - Remove plate , row and column random effects.\n",
    "            'y_lims':[[0,9], [12, 16]], # (list of lists) limits for broken y axis\n",
    "            'plate':None, # (string or NoneType) - strinf to replace plate column values with\n",
    "            'cov_type':None, # (string) - covariance type for ols regression\n",
    "            'volcano':'gene', # (string) - mode for significant resuls (gene, grna, all)\n",
    "            'alpha':0.8} # (float) - alpha for hinge and lasso regression\n",
    "\n",
    "coef_df = perform_regression(settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacr",
   "language": "python",
   "name": "spacr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
