{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335dcd14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Description: use this cell to generate train and test folders: datasets/train/nc and pc and datasets/test/nc and pc\n",
    "from spacr.io import generate_training_dataset\n",
    "\n",
    "settings = {'src':'path', # (path) path to source folder (where origional images were stored)\n",
    "            'dataset_mode':'metadata_annotation', # (string) annotation, measurement, metadata, annotation_metadata\n",
    "            'tables':['cell'],# (list of strings) The tabels present in the database, excluding png_list\n",
    "            'test_split':0.1, # (float) Fraction of images used for the test set\n",
    "            'annotation_column':'test', # (Optional, string) If using mode annotation, The annotation column in the database\n",
    "            'annotated_classes':[1], # (Optional, list of integers) If using mode annotation, The interger in annotation_column, if len(annotated_classes) is 1, class 2 will be generated from a random selection of images.\n",
    "            'metadata_type_by':'column_name', # (Optional, strin) If using mode medatada, If using mode medatada,the column class_metadata elements are in\n",
    "            'class_metadata':['c10','c11','c12','c22','c23','c24'], # (Optional, list of lists of strings) If using mode medatada, the elements that deffine each class \n",
    "            'png_type':'cell_png', # (Optional, string) string in the path of each image (used to filter images)\n",
    "            'nuclei_limit':False, # (Optional, bool) if cell and nucleus in tables, filter for number of nuclei per cell\n",
    "            'pathogen_limit':0, # (Optional, integer) if cell and pathogen in tables, filter for number of pathogen per cell\n",
    "            'uninfected':True, # (Optional, bool) if cell and pathogen in tables, bool for uninfected cells (cells)\n",
    "            'size':None # (Optional, integer or NoneType) limit for number of images to include in total (test + train) per class\n",
    "           }\n",
    "\n",
    "generate_training_dataset(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4431164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models already downloaded to: /home/carruthers/anaconda3/envs/spacr/lib/python3.9/site-packages/spacr/resources/models\n",
      "Training a network on channels: [1, 2, 3]\n",
      "Channel 1: Red, Channel 2: Green, Channel 3: Blue\n",
      "Loading test dataset\n",
      "Results wil be saved in: /nas_mnt/carruthers/yifan/Yifan_Einar screen/yifanUbtrial11h_20240705_184432/plate1/datasets/training/model/maxvit_t/rgb/epochs_100/maxvit_t_time_241205_test_result.csv\n",
      "Copied 50 misclassified images.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/nas_mnt/carruthers/yifan/Yifan_Einar screen/yifanUbtrial11h_20240705_184432/plate1/datasets/training/model/maxvit_t/rgb/epochs_100/maxvit_t_time_241205_test_result.csv'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description: train a torch model\n",
    "from spacr.deep_spacr import train_test_model\n",
    "\n",
    "settings = {'src':'/nas_mnt/carruthers/yifan/Yifan_Einar screen/yifanUbtrial11h_20240705_184432/plate1/datasets/training', # (path) path to source folder (ends with datasets/training)\n",
    "            'train':False, # (bool) - Train\n",
    "            'test': True, # (bool) - Test\n",
    "            'custom_model':'/nas_mnt/carruthers/yifan/Yifan_Einar screen/yifanUbtrial11h_20240705_184432/plate1/datasets/training/model/maxvit_t/rgb/epochs_100/maxvit_t_epoch_100_channels_rgb.pth', # (path) - path to a custom model\n",
    "            'classes':['nc','pc'], # (list) - list of classes (folder names in dataset/training/train or test)\n",
    "            'model_type':'maxvit_t', # (string) - Name of torch model architecture\n",
    "            'optimizer_type':'adamw', # (string) - type of optimizer\n",
    "            'schedule':'reduce_lr_on_plateau', # (string) - type of scheduler (reduce_lr_on_plateau or step_lr)\n",
    "            'loss_type':'focal_loss', # (string) - Loss function (binary_cross_entropy_with_logits or focal_loss)\n",
    "            'normalize':True, # (bool) - Apply ImageNet normalization to images before training.\n",
    "            'image_size':224, # (int) - Size of images, height and width.\n",
    "            'batch_size':64, # (int) - Nr. of images per batch\n",
    "            'epochs':100, # (int) - Nr. of epochs for training\n",
    "            'val_split':0.1, # (float) - Fraction of images in validation dataset\n",
    "            'learning_rate':0.0001, # (float) - Learning rate per epoch\n",
    "            'weight_decay':0.00001, # (float) - Fraction of random weights decay (regularization)\n",
    "            'dropout_rate':0.1, # (float) - Fraction of weights to omit per epoch (regularization)\n",
    "            'init_weights':True, # (bool) - Initiate model with ImageNet weights\n",
    "            'amsgrad':True, # (bool) - guard against exploding gradients\n",
    "            'use_checkpoint':True, # (bool) - checkpoint gradient calculations to save VRAM at the expence of computation\n",
    "            'gradient_accumulation':True, # (bool) - Accumulate gradients to mimic larger batches\n",
    "            'gradient_accumulation_steps':4, # (int) - Epochs to accumulate gradients\n",
    "            'intermedeate_save':True, # Save intermediate states of the model\n",
    "            'pin_memory':True, # (bool) - Whether to pin memory for the data loader\n",
    "            'n_jobs':30, # (int) - Number of threads to use\n",
    "            'train_channels':['r','g','b'], # (list of 'r', 'g', and/or 'b') - PNG channels to use for training\n",
    "            'augment':False, # (bool) - Augment the dataset, vertical, horizontal flip and rotate each image to artificially expand the dataset 8 fold.\n",
    "            'verbose':True}\n",
    "\n",
    "train_test_model(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770fb79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Description: generate a tar dataset\n",
    "\n",
    "from spacr.io import generate_dataset\n",
    "\n",
    "settings = {'src':'path', # (path) path to source folder (where origional images were stored)\n",
    "           'file_metadata':'cell_png', # (Optional, string) string in the path of each image (used to filter images)\n",
    "           'experiment':'test', # (string) - Name of dataset\n",
    "           'sample':10000} # (Optional, integer or NoneType) limit for number of images to include in the dataset\n",
    "\n",
    "generate_dataset(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086fcefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: apply a model to a tar dataset\n",
    "\n",
    "from spacr.deep_spacr import apply_model_to_tar\n",
    "\n",
    "settings = {'dataset':'path.tar', # (path) - path to tar dataset (ends with .tar) \n",
    "            'model_path':'path.pth', # (path) - path to model (ends with .pth) \n",
    "            'file_type':'cell_png', # (Optional, string) string in the path of each image (used to filter images)\n",
    "            'image_size':224, # (int) - Size of images, height and width\n",
    "            'batch_size':64, # (int) - Nr. of images per batch\n",
    "            'normalize':True, # (bool) - Apply ImageNet normalization to images before training.\n",
    "            'score_threshold':0.5, # (float) - Score to byass the classes\n",
    "            'n_jobs':30, # (int) - Number of threads to use\n",
    "            'verbose':True}\n",
    "\n",
    "result_df = apply_model_to_tar(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9916c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: Fit a regression model to estimate the effect size of gRNAs on cell scores.\n",
    "from spacr.ml import perform_regression\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "settings = {'count_data':'path', # (path) path or list of paths to sequencing count data\n",
    "            'score_data':'path', # (path) path or list of paths to score data\n",
    "            'score_column':'column', # () - column with cell scores\n",
    "            'metadata_files':['path.csv','path.csv'], # (list) pahts to gene metadata \n",
    "            'positive_control':'gene', # (string) - gene to highlight in volcano plot\n",
    "            'negative_control':'gene', # (string) - gene to highlight in volcano plot\n",
    "            'min_n':3, # () - \n",
    "            'fraction_threshold':None, # (Optional, float or NoneType) - Minimum threshold for gene fraction, if None automatically calculated\n",
    "            'target_unique_count':5, # () - Number of expected unique gRNAs per well\n",
    "            'tolerance':0.02, # (float) - Tollerance for cells per well limit\n",
    "            'log_x':False, # () - gRNA Fraction plot X axis log\n",
    "            'log_y':False, # () - gRNA Fraction plot Y axis log\n",
    "            'x_lim':None, # () - Volcano X axis limit\n",
    "            'control_wells':['c1','c2','c3'], # (list) - Metadata to exclude from regression model\n",
    "            'filter_column':'column', # (str) - Column containing control metadata to remove\n",
    "            'dependent_variable': 'column', # (string) - Dependent variable for regression\n",
    "            'threshold_method':'var', # (string) - effect size thresold type (std or var)\n",
    "            'threshold_multiplier':4, # (integer) - effect size threshold multiplyer \n",
    "            'transform':'log', # (string) - Transform dependent variable\n",
    "            'agg_type':'mean', # (string) - aggregation for dependent variable\n",
    "            'min_cell_count':None, # (integer) - Minimum number of cells per well\n",
    "            'regression_type':'ols', # (string) - Type of regression (ols, glm, mixed, ridge, lasso).\n",
    "            'random_row_column_effects':False, # (bool) - Remove plate , row and column random effects.\n",
    "            'y_lims':[[0,9], [12, 16]], # (list of lists) limits for broken y axis\n",
    "            'plate':None, # (string or NoneType) - strinf to replace plate column values with\n",
    "            'cov_type':None, # (string) - covariance type for ols regression\n",
    "            'volcano':'gene', # (string) - mode for significant resuls (gene, grna, all)\n",
    "            'alpha':0.8} # (float) - alpha for hinge and lasso regression\n",
    "\n",
    "coef_df = perform_regression(settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacr",
   "language": "python",
   "name": "spacr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
