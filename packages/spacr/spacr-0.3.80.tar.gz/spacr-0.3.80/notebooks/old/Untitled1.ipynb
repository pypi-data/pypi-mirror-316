{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40424f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import openai\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def prepare_data_for_finetuning(image_folder, test_size=0.2, output_file=\"fine_tune_dataset.jsonl\"):\n",
    "    \"\"\"\n",
    "    Prepares a dataset for fine-tuning GPT-4 using grayscale images and corresponding masks.\n",
    "\n",
    "    Args:\n",
    "        image_folder (str): Path to the folder containing grayscale images and a \"masks\" subfolder.\n",
    "        test_size (float): Proportion of the dataset to include in the test split.\n",
    "        output_file (str): Output JSONL file for fine-tuning.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Paths to the training and testing datasets in JSONL format.\n",
    "    \"\"\"\n",
    "    def convert_to_16bit(image):\n",
    "        \"\"\"\n",
    "        Converts an image to 16-bit format.\n",
    "        \"\"\"\n",
    "        if image.dtype == np.uint8:  # Convert 8-bit to 16-bit\n",
    "            image = cv2.normalize(image, None, 0, 65535, cv2.NORM_MINMAX, dtype=cv2.CV_16U)\n",
    "        elif image.dtype == np.float32:  # Convert float32 to 16-bit\n",
    "            image = (image * 65535).clip(0, 65535).astype(np.uint16)\n",
    "        elif image.dtype != np.uint16:  # Convert other types to 16-bit\n",
    "            image = cv2.normalize(image, None, 0, 65535, cv2.NORM_MINMAX, dtype=cv2.CV_16U)\n",
    "        return image\n",
    "\n",
    "    images_path = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "    masks_folder = os.path.join(image_folder, \"masks\")\n",
    "    data = []\n",
    "\n",
    "    for image_file in images_path:\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        mask_path = os.path.join(masks_folder, image_file)\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            continue  # Skip if mask does not exist\n",
    "        \n",
    "        # Load image and mask\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        # Skip if images fail to load\n",
    "        if image is None or mask is None:\n",
    "            print(f\"Skipping {image_file}: Unable to load.\")\n",
    "            continue\n",
    "\n",
    "        # Convert to 16-bit if necessary\n",
    "        image = convert_to_16bit(image)\n",
    "        mask = convert_to_16bit(mask)\n",
    "\n",
    "        # Create a prompt-response pair\n",
    "        prompt = f\"Generate a mask for the grayscale image with dimensions {image.shape}.\"\n",
    "        completion = f\"The mask has been generated with specific contours and intensity ranges.\"\n",
    "        \n",
    "        # Append to the dataset\n",
    "        data.append({\"prompt\": prompt, \"completion\": completion})\n",
    "\n",
    "    # Split the data\n",
    "    train_data, test_data = train_test_split(data, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Save the datasets\n",
    "    train_file = f\"train_{output_file}\"\n",
    "    test_file = f\"test_{output_file}\"\n",
    "    \n",
    "    with open(train_file, \"w\") as train_f:\n",
    "        for entry in train_data:\n",
    "            train_f.write(json.dumps(entry) + \"\\n\")\n",
    "    \n",
    "    with open(test_file, \"w\") as test_f:\n",
    "        for entry in test_data:\n",
    "            test_f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "    return train_file, test_file\n",
    "\n",
    "\n",
    "def fine_tune_gpt4(train_file, model=\"gpt-4\", epochs=4, learning_rate=1e-4):\n",
    "    \"\"\"\n",
    "    Fine-tunes GPT-4 using the prepared training dataset.\n",
    "\n",
    "    Args:\n",
    "        train_file (str): Path to the training dataset in JSONL format.\n",
    "        model (str): Base GPT-4 model to fine-tune.\n",
    "        epochs (int): Number of epochs for fine-tuning.\n",
    "        learning_rate (float): Learning rate for fine-tuning.\n",
    "    \n",
    "    Returns:\n",
    "        str: Fine-tuned model ID.\n",
    "    \"\"\"\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    # Upload the training file\n",
    "    print(\"Uploading training file...\")\n",
    "    try:\n",
    "        with open(train_file, \"rb\") as f:\n",
    "            response = openai.File.create(file=f, purpose=\"fine-tune\")\n",
    "        training_file_id = response[\"id\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading training file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Fine-tune the model\n",
    "    print(\"Starting fine-tuning...\")\n",
    "    try:\n",
    "        fine_tune_response = openai.FineTune.create(\n",
    "            model=model,\n",
    "            training_file=training_file_id,\n",
    "            n_epochs=epochs,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "        fine_tune_id = fine_tune_response[\"id\"]\n",
    "        print(f\"Fine-tuning initiated with ID: {fine_tune_id}\")\n",
    "        return fine_tune_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error during fine-tuning: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_fine_tuned_model(fine_tune_id, output_model_path):\n",
    "    \"\"\"\n",
    "    Saves the fine-tuned model to disk.\n",
    "\n",
    "    Args:\n",
    "        fine_tune_id (str): The fine-tune ID returned after training.\n",
    "        output_model_path (str): Path to save the fine-tuned model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fine_tune_details = openai.FineTune.retrieve(id=fine_tune_id)\n",
    "        fine_tuned_model = fine_tune_details[\"fine_tuned_model\"]\n",
    "        \n",
    "        with open(output_model_path, \"w\") as f:\n",
    "            f.write(fine_tuned_model)\n",
    "        print(f\"Fine-tuned model saved to: {output_model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving fine-tuned model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cbc2b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading training file...\n",
      "Error uploading training file: \n",
      "\n",
      "You tried to access openai.File, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "Error saving fine-tuned model: \n",
      "\n",
      "You tried to access openai.FineTune, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_folder = '/nas_mnt/carruthers/Einar/dsred/train'\n",
    "test_size=0.1\n",
    "\n",
    "# Step 1: Prepare data\n",
    "train_file, test_file = prepare_data_for_finetuning(image_folder)\n",
    "\n",
    "# Step 2: Fine-tune GPT-4\n",
    "fine_tune_id = fine_tune_gpt4(train_file, epochs=3, learning_rate=5e-5)\n",
    "\n",
    "# Step 3: Save the fine-tuned model\n",
    "save_fine_tuned_model(fine_tune_id, \"./fine_tuned_gpt4_mask_generator.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac25b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacr",
   "language": "python",
   "name": "spacr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
