{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa887db9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tradable symbols found: 7648\n",
      "Fetching historical data once for all batches and horizons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched data for batch 1 with 1000 symbols.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched data for batch 2 with 1000 symbols.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched data for batch 3 with 1000 symbols.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched data for batch 4 with 1000 symbols.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched data for batch 5 with 1000 symbols.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched data for batch 6 with 1000 symbols.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched data for batch 7 with 1000 symbols.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n",
      "sleep 3 seconds and retrying https://data.alpaca.markets/v2/stocks/bars 3 more time(s)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched data for batch 8 with 648 symbols.\n",
      "\n",
      "Processing horizon: 1d\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid comparison between dtype=datetime64[ns, UTC] and datetime64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/spacr/lib/python3.9/site-packages/pandas/core/arrays/datetimelike.py:536\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._validate_comparison_value\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_compatible_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, IncompatibleFrequency) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;66;03m# e.g. tzawareness mismatch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:540\u001b[0m, in \u001b[0;36mDatetimeArray._check_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 540\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_tzawareness_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:786\u001b[0m, in \u001b[0;36mDatetimeArray._assert_tzawareness_compat\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m other_tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 786\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    787\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot compare tz-naive and tz-aware datetime-like objects\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    788\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot compare tz-naive and tz-aware datetime-like objects",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidComparison\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/spacr/lib/python3.9/site-packages/pandas/core/arrays/datetimelike.py:983\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 983\u001b[0m     other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_comparison_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidComparison:\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr/lib/python3.9/site-packages/pandas/core/arrays/datetimelike.py:539\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._validate_comparison_value\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, IncompatibleFrequency) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;66;03m# e.g. tzawareness mismatch\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidComparison(other) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(other):\n",
      "\u001b[0;31mInvalidComparison\u001b[0m: 2024-10-03 16:27:48.064640",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 248\u001b[0m\n\u001b[1;32m    245\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m StockAnalyzer(alpaca_api_key, alpaca_secret_key)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# Run in test mode to prevent actual trades\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m ranked_stocks \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_stocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 196\u001b[0m, in \u001b[0;36mStockAnalyzer.run\u001b[0;34m(self, test_mode, batch_size, data_threshold, top_stocks)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Filter data for the required date range per horizon\u001b[39;00m\n\u001b[1;32m    195\u001b[0m horizon_start_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_days_ago\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 196\u001b[0m data_horizon \u001b[38;5;241m=\u001b[39m data_horizon[\u001b[43mdata_horizon\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhorizon_start_date\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    197\u001b[0m data_horizon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_features_for_horizon(data_horizon, params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorizon\u001b[39m\u001b[38;5;124m'\u001b[39m], tradeapi\u001b[38;5;241m.\u001b[39mTimeFrame\u001b[38;5;241m.\u001b[39mDay)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_horizon\u001b[38;5;241m.\u001b[39mempty:\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr/lib/python3.9/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr/lib/python3.9/site-packages/pandas/core/arraylike.py:60\u001b[0m, in \u001b[0;36mOpsMixin.__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ge__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mge\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr/lib/python3.9/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:330\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    322\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m, lvalues\u001b[38;5;241m.\u001b[39mshape, rvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    323\u001b[0m         )\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    326\u001b[0m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    328\u001b[0m ):\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_scalar(rvalues) \u001b[38;5;129;01mand\u001b[39;00m isna(rvalues):  \u001b[38;5;66;03m# TODO: but not pd.NA?\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;66;03m# numpy does not like comparisons vs None\u001b[39;00m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m operator\u001b[38;5;241m.\u001b[39mne:\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr/lib/python3.9/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr/lib/python3.9/site-packages/pandas/core/arraylike.py:60\u001b[0m, in \u001b[0;36mOpsMixin.__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ge__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mge\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr/lib/python3.9/site-packages/pandas/core/arrays/datetimelike.py:985\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m    983\u001b[0m     other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_comparison_value(other)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidComparison:\n\u001b[0;32m--> 985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minvalid_comparison\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype):\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;66;03m# We have to use comp_method_OBJECT_ARRAY instead of numpy\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m#  comparison otherwise it would raise when comparing to None\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spacr/lib/python3.9/site-packages/pandas/core/ops/invalid.py:40\u001b[0m, in \u001b[0;36minvalid_comparison\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     typ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(right)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid comparison between dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleft\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid comparison between dtype=datetime64[ns, UTC] and datetime64"
     ]
    }
   ],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # To suppress warnings for cleaner output\n",
    "\n",
    "class StockAnalyzer:\n",
    "    def __init__(self, alpaca_api_key, alpaca_secret_key, base_url='https://paper-api.alpaca.markets'):\n",
    "        # Initialize Alpaca API\n",
    "        self.api = tradeapi.REST(alpaca_api_key, alpaca_secret_key, base_url, api_version='v2')\n",
    "        self.test_mode = False\n",
    "\n",
    "    def get_all_symbols(self):\n",
    "        # Fetch all active and tradable assets\n",
    "        assets = self.api.list_assets(status='active')\n",
    "        symbols = [\n",
    "            asset.symbol for asset in assets\n",
    "            if asset.tradable and asset.exchange in ['NYSE', 'NASDAQ']\n",
    "        ]\n",
    "        print(f\"Total tradable symbols found: {len(symbols)}\")\n",
    "        return symbols\n",
    "\n",
    "    def fetch_historical_data(self, symbols, start_date, end_date, time_frame, feed='iex', batch_size=100, aggregate_to_hour=False):\n",
    "        # Adjust date formats to match API requirements\n",
    "        start = start_date.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        end = end_date.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "        all_data = pd.DataFrame()\n",
    "\n",
    "        # Batch symbols to avoid exceeding rate limits\n",
    "        for i in range(0, len(symbols), batch_size):\n",
    "            batch_symbols = symbols[i:i + batch_size]\n",
    "            success = False\n",
    "            attempts = 0\n",
    "            max_attempts = 5\n",
    "            while not success and attempts < max_attempts:\n",
    "                try:\n",
    "                    bars = self.api.get_bars(\n",
    "                        batch_symbols,\n",
    "                        time_frame,\n",
    "                        start=start,\n",
    "                        end=end,\n",
    "                        adjustment='raw',\n",
    "                        feed=feed\n",
    "                    ).df\n",
    "                    if not bars.empty:\n",
    "                        all_data = pd.concat([all_data, bars])\n",
    "                        print(f\"Fetched data for batch {i // batch_size + 1} with {len(batch_symbols)} symbols.\")\n",
    "                    else:\n",
    "                        print(f\"No data returned for batch {i // batch_size + 1} with symbols {batch_symbols[0]} to {batch_symbols[-1]}\")\n",
    "                    time.sleep(1)  # Pause to respect rate limits\n",
    "                    success = True\n",
    "                except tradeapi.rest.APIError as e:\n",
    "                    if 'rate limit' in str(e).lower():\n",
    "                        attempts += 1\n",
    "                        wait_time = 3 * attempts\n",
    "                        print(f\"Rate limit exceeded. Sleeping for {wait_time} seconds and retrying (Attempt {attempts}/{max_attempts})...\")\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"Error fetching data for symbols {batch_symbols[0]} to {batch_symbols[-1]}: {e}\")\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(f\"Unexpected error: {e}\")\n",
    "                    break\n",
    "            if not success:\n",
    "                print(f\"Failed to fetch data for batch {i // batch_size + 1} after {max_attempts} attempts.\")\n",
    "            else:\n",
    "                # Sleep between batches to respect rate limits\n",
    "                time.sleep(2)  # Adjust sleep time as needed\n",
    "        all_data.reset_index(inplace=True)\n",
    "\n",
    "        if aggregate_to_hour and time_frame == tradeapi.TimeFrame.Minute:\n",
    "            # Aggregate minute data to hourly data\n",
    "            all_data['timestamp'] = all_data['timestamp'].dt.floor('H')\n",
    "            all_data = all_data.groupby(['symbol', 'timestamp']).agg({\n",
    "                'open': 'first',\n",
    "                'high': 'max',\n",
    "                'low': 'min',\n",
    "                'close': 'last',\n",
    "                'volume': 'sum',\n",
    "                'trade_count': 'sum',\n",
    "                'vwap': 'mean'\n",
    "            }).reset_index()\n",
    "        return all_data\n",
    "\n",
    "    def prepare_features_for_horizon(self, data, horizon, time_frame):\n",
    "        data = data.copy()\n",
    "        # Sort data and reset index\n",
    "        data = data.sort_values(['symbol', 'timestamp']).reset_index(drop=True)\n",
    "        # Filter symbols with data less than data_threshold\n",
    "        data_counts = data.groupby('symbol').size()\n",
    "        valid_symbols = data_counts[data_counts >= self.data_threshold].index.tolist()\n",
    "        data = data[data['symbol'].isin(valid_symbols)]\n",
    "        # Compute features grouped by symbol\n",
    "        data['return'] = data.groupby('symbol')['close'].pct_change()\n",
    "        data['volatility'] = data.groupby('symbol')['close'].transform(lambda x: x.rolling(window=5).std())\n",
    "        data['momentum'] = data.groupby('symbol')['close'].transform(lambda x: x / x.shift(5) - 1)\n",
    "        data['ma5'] = data.groupby('symbol')['close'].transform(lambda x: x.rolling(window=5).mean())\n",
    "        data['ma10'] = data.groupby('symbol')['close'].transform(lambda x: x.rolling(window=10).mean())\n",
    "        data['ma_ratio'] = data['ma5'] / data['ma10']\n",
    "        # Shift 'close' to create the target variable based on the horizon\n",
    "        data['target'] = data.groupby('symbol')['close'].shift(-horizon)\n",
    "        # Drop rows with any NaN values in the required columns\n",
    "        data = data.dropna(subset=['return', 'volatility', 'momentum', 'ma_ratio', 'target'])\n",
    "        return data\n",
    "\n",
    "    def train_and_predict_for_horizon(self, data, horizon_name):\n",
    "        if data.empty:\n",
    "            print(f\"No data available after feature preparation for {horizon_name}.\")\n",
    "            return {}\n",
    "        # Separate the latest features per symbol for prediction\n",
    "        latest_data = data.groupby('symbol').tail(1)\n",
    "        # Remove the last data point per symbol from training data\n",
    "        training_data = data.groupby('symbol').apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "        # Ensure we have enough data to train\n",
    "        if training_data.empty:\n",
    "            print(f\"No training data available for {horizon_name}.\")\n",
    "            return {}\n",
    "        # Training features and target\n",
    "        X_train = training_data[['return', 'volatility', 'momentum', 'ma_ratio']]\n",
    "        y_train = training_data['target']\n",
    "        # Remove infinite or NaN values\n",
    "        X_train = X_train.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        y_train = y_train.loc[X_train.index]\n",
    "        # Train the model on combined data\n",
    "        print(f\"Training the model on combined data for {horizon_name}...\")\n",
    "        model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "        # Prepare test data (latest features)\n",
    "        X_test = latest_data[['return', 'volatility', 'momentum', 'ma_ratio']]\n",
    "        X_test = X_test.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        symbols = X_test.index.get_level_values('symbol')\n",
    "        current_prices = latest_data.loc[symbols]['close'].values\n",
    "        # Predict expected prices\n",
    "        predicted_prices = model.predict(X_test)\n",
    "        # Calculate expected returns\n",
    "        expected_returns = {}\n",
    "        for i, symbol in enumerate(symbols):\n",
    "            predicted_price = predicted_prices[i]\n",
    "            current_price = current_prices[i]\n",
    "            expected_return = (predicted_price - current_price) / current_price * 100\n",
    "            expected_returns[symbol] = expected_return\n",
    "        return expected_returns\n",
    "\n",
    "    def run(self, test_mode=False, batch_size=100, data_threshold=60, top_stocks=10):\n",
    "        self.test_mode = test_mode\n",
    "        self.data_threshold = data_threshold  # Store data_threshold as an instance variable\n",
    "\n",
    "        # Define time horizons and corresponding parameters\n",
    "        horizons = {\n",
    "            '1d': {'horizon': 1, 'start_days_ago': 60},\n",
    "            '5d': {'horizon': 5, 'start_days_ago': 300},\n",
    "            '1y': {'horizon': 252, 'start_days_ago': 700},\n",
    "        }\n",
    "\n",
    "        # Get all symbols\n",
    "        symbols = self.get_all_symbols()\n",
    "\n",
    "        # Limit symbols to avoid rate limits if necessary\n",
    "        # symbols = symbols[:1000]  # Adjust as needed\n",
    "\n",
    "        # Determine the earliest start_date needed among all horizons\n",
    "        earliest_start_days_ago = max(params['start_days_ago'] for params in horizons.values())\n",
    "        start_date = datetime.now() - timedelta(days=earliest_start_days_ago)\n",
    "        end_date = datetime.now() - timedelta(days=1)\n",
    "\n",
    "        # Fetch historical data for all symbols once\n",
    "        print(\"Fetching historical data once for all batches and horizons...\")\n",
    "        data = self.fetch_historical_data(\n",
    "            symbols,\n",
    "            start_date,\n",
    "            end_date,\n",
    "            tradeapi.TimeFrame.Day,  # Assuming daily data for all horizons\n",
    "            batch_size=batch_size,\n",
    "            aggregate_to_hour=False\n",
    "        )\n",
    "\n",
    "        if data.empty:\n",
    "            print(\"No historical data fetched.\")\n",
    "            return\n",
    "\n",
    "        # Initialize a dictionary to hold expected returns for each horizon\n",
    "        horizon_returns = {}\n",
    "\n",
    "        for horizon_name, params in horizons.items():\n",
    "            print(f\"\\nProcessing horizon: {horizon_name}\")\n",
    "\n",
    "            # Prepare features and target for this horizon\n",
    "            data_horizon = data.copy()\n",
    "            # Filter data for the required date range per horizon\n",
    "            horizon_start_date = datetime.now() - timedelta(days=params['start_days_ago'])\n",
    "            data_horizon = data_horizon[data_horizon['timestamp'] >= np.datetime64(horizon_start_date)]\n",
    "            data_horizon = self.prepare_features_for_horizon(data_horizon, params['horizon'], tradeapi.TimeFrame.Day)\n",
    "\n",
    "            if data_horizon.empty:\n",
    "                print(f\"No data available after feature preparation for {horizon_name}.\")\n",
    "                continue\n",
    "\n",
    "            # Train model and predict expected returns\n",
    "            expected_returns = self.train_and_predict_for_horizon(data_horizon, horizon_name)\n",
    "\n",
    "            if not expected_returns:\n",
    "                print(f\"No expected returns calculated for {horizon_name}.\")\n",
    "                continue\n",
    "\n",
    "            # Store the expected returns\n",
    "            horizon_returns[horizon_name] = expected_returns\n",
    "\n",
    "        # Combine results and rank stocks\n",
    "        combined_returns = {}\n",
    "        for symbol in symbols:\n",
    "            symbol_returns = {horizon: horizon_returns.get(horizon, {}).get(symbol, None) for horizon in horizons if horizon in horizon_returns}\n",
    "            if all(value is not None for value in symbol_returns.values()):\n",
    "                combined_returns[symbol] = symbol_returns\n",
    "\n",
    "        # Sort stocks based on average expected return across horizons\n",
    "        ranked_stocks = sorted(\n",
    "            combined_returns.items(),\n",
    "            key=lambda x: sum(x[1].values()) / len(x[1]),\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        print(f\"\\nTop {top_stocks} Stocks ranked by average expected return:\")\n",
    "        for symbol, returns in ranked_stocks[:top_stocks]:\n",
    "            print(f\"{symbol}: \", end=\"\")\n",
    "            for horizon in horizons:\n",
    "                if horizon in returns:\n",
    "                    print(f\"{horizon}: {returns[horizon]:.2f}% \", end=\"\")\n",
    "                else:\n",
    "                    print(f\"{horizon}: N/A \", end=\"\")\n",
    "            print()\n",
    "\n",
    "        return ranked_stocks\n",
    "    \n",
    "# Usage Example:\n",
    "if __name__ == '__main__':\n",
    "    alpaca_api_key = 'PKJATKYKR4NWCYALKL58' \n",
    "    alpaca_secret_key = '8aFRppO0HdabLAO8b05ZImUwSd0bEmv4hqpU0Hqs'\n",
    "\n",
    "    # Initialize the analyzer\n",
    "    analyzer = StockAnalyzer(alpaca_api_key, alpaca_secret_key)\n",
    "\n",
    "    # Run in test mode to prevent actual trades\n",
    "    ranked_stocks = analyzer.run(test_mode=True, batch_size=1000, data_threshold=30, top_stocks=100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f366a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e4710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacr",
   "language": "python",
   "name": "spacr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
