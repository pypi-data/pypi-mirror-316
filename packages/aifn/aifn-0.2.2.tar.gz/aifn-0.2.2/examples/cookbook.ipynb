{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A client facing API for interacting with the [Weco AI](https://www.weco.ai/)'s AI function [platform](https://www.aifunction.com). It empowers you to go from zero to AI in just a few seconds!\n",
    "\n",
    "Here are a few features our users often ask about. Feel free to follow along:\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/WecoAI/aifn-python/blob/main/examples/cookbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" width=110 height=20/></a>\n",
    "<a target=\"_blank\" href=\"https://lightning.ai/new?repo_url=https%3A%2F%2Fgithub.com%2FWecoAI%2Faifn-python%2Fblob%2Fmain%2Fexamples%2Fcookbook.ipynb\"><img src=\"https://pl-bolts-doc-images.s3.us-east-2.amazonaws.com/app-2/studio-badge.svg\" alt=\"Open in Studio\" width=100 height=20/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package\n",
    "%pip install aifn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find/setup your API key [here](https://www.aifunction.com/account/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WECO_API_KEY\"] = \"YOUR_WECO_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build powerful AI functions for complex tasks quickly and without friction. For example, you can create an AI function on our [platform](https://www.aifunction.com/function/new) with a simple description as shown below:\n",
    "\n",
    "> \"Analyze a business idea and provide a well reasoned evaluation. Return 'viability_score' (0-100), 'strengths' (list), 'weaknesses' (list), and 'next_steps' (list).\"\n",
    "\n",
    "Once the function has been built, you can call, test and deploy it anywhere in your code with just three lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aifn import AIFunction\n",
    "\n",
    "idea_evaluator = AIFunction(\"BusinessIdeaAnalyzer-XYZ123\") # Replace with your actual function name\n",
    "\n",
    "response = idea_evaluator(\"A subscription service for personalized, AI-generated bedtime stories for children.\").output\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a 100% guarantee of a structured output on an function call! This means that you can pass any unstructured input in and get back a valid structured output that follows the JSON schema optimally determined by the AI function for your task. You can also edit, write and replace the JSON schema for an AI function on our [platform](https://www.aifunction.com/).\n",
    "\n",
    "Here's an example where we extract relevant information about the different object in this image:\n",
    "\n",
    "![Objects on Table](https://us.images.westend61.de/0001348304i/directly-above-shot-of-various-objects-on-table-EYF01650.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aifn import build\n",
    "\n",
    "information_extractor = build(\"Describe the unique set of the objects present in the image. Provide the 'object', a 'description' and 'count' of how many times that particular object appeared in the image.\")\n",
    "\n",
    "# You may be wondering what the metadata here is. We'll get to that in a second.\n",
    "object_dict, metadata = information_extractor(images_input=[\"https://us.images.westend61.de/0001348304i/directly-above-shot-of-various-objects-on-table-EYF01650.jpg\"])\n",
    "for object in object_dict['objects']:\n",
    "    print(f\"{object['object']}: {object['description']} (appeared {object['count']} times)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Function and Function Response Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do recommend building AI functions on our [platform](https://www.aifunction.com/) to prototype faster and achieve the right balance between speed, intelligence and cost. Here's how you can find the AI function we built in the previous example on the [platform](https://www.aifunction.com/). Simply extract the function name, and use it to find the corresponding AI function on the [platform](https://www.aifunction.com/). If you need to know the exact version, you can extract that from the `AIFunction` class as well to find the exact version being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_name = information_extractor.fn_name\n",
    "print(f\"Function name: {fn_name}\")\n",
    "version = information_extractor.version\n",
    "print(f\"Version: {version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're a developer and you want to use AI powered functions, you probably care about things like the input and output token counts and the latency of the AI function. Its easily accessible! Let's look at how we can get this information for the previous function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input_tokens = metadata[\"in_tokens\"]\n",
    "n_output_tokens = metadata[\"out_tokens\"]\n",
    "latency_milliseconds = metadata[\"latency_ms\"]\n",
    "print(f\"Input tokens: {n_input_tokens}, Output tokens: {n_output_tokens}, Latency: {latency_milliseconds}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sync-Async Duality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI Functions can be made to be both synchronous or asynchronous functions, allowing for more flexible use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aifn import build\n",
    "\n",
    "# Build an synchronous function\n",
    "translator = build(\"Return the 'translation' of english to french.\")\n",
    "translation = translator(\"Hello, how are you?\").output['translation']\n",
    "print(translation)\n",
    "\n",
    "# Make it asynchronous\n",
    "async_translator = translator.make_async()\n",
    "output, metadata = await async_translator(\"Hello, how are you?\")\n",
    "print(output['translation'])\n",
    "\n",
    "# Build an asynchronous function\n",
    "translator = build(\"Return the 'translation' of english to french.\", is_async=True)\n",
    "output, metadata = await translator(\"Hello, how are you?\")\n",
    "print(output['translation'])\n",
    "\n",
    "# Make it synchronous\n",
    "sync_translator = translator.make_sync()\n",
    "translation = sync_translator(\"Hello, how are you?\").output['translation']\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous examples, we've shown you how to call an AI function with just one input. We understand that sometimes you want to submit a large batch of inputs to be processed in concurrently. Every AI function, whether synchronous or asynchronous, can perform batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_evaluator = build(task_description=\"I want to know if AI can solve a problem for me, how easy it is to arrive at a solution and whether any helpful tips for me along the way. Help me understand this through - 'feasibility', 'justification', and 'suggestions'.\")\n",
    "\n",
    "task1 = {\n",
    "    \"text_input\": \"I want to train a model to predict house prices using the Boston Housing dataset hosted on Kaggle.\"\n",
    "}\n",
    "task2 = {\n",
    "    \"text_input\": \"I want to train a model to classify digits using the MNIST dataset hosted on Kaggle using a Google Colab notebook. Attached is an example of what some of the digits would look like.\",\n",
    "}\n",
    "responses = task_evaluator.batch([task1, task2])\n",
    "for response in responses:\n",
    "    print(\"=\" * 50)\n",
    "    print(response.output)\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our AI functions can interpret complex visual information, follow instructions in natural language and provide practical insights. We accept a variety of different forms of image input:\n",
    "1. Base64 encoding\n",
    "2. Publically available URL\n",
    "3. Local image path\n",
    "\n",
    "Let's explore how we can have an AI function manage a part of our household. By running this once a month, I am able to find ways to cut down my energy consumption and ultimately save me money!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "task_description = \"\"\"\n",
    "You are a smart home energy analyzer that can process images of smart meters, home exteriors, \n",
    "and indoor spaces to provide energy efficiency insights. The analyzer should:\n",
    "    1. Interpret smart meter readings\n",
    "    2. Assess home features relevant to energy consumption\n",
    "    3. Analyze thermostat settings\n",
    "    4. Provide energy-saving recommendations\n",
    "    5. Evaluate renewable energy potential\n",
    "\n",
    "The output should include:\n",
    "    - 'energy_consumption': current usage and comparison to average\n",
    "    - 'home_analysis': visible energy features and potential issues\n",
    "    - 'thermostat_settings': current settings and recommendations\n",
    "    - 'energy_saving_recommendations': actionable suggestions with estimated savings\n",
    "    - 'renewable_energy_potential': assessment of current and potential renewable energy use\n",
    "    - 'estimated_carbon_footprint': current footprint and potential reduction\n",
    "\"\"\"\n",
    "\n",
    "energy_analyzer = build(task_description=task_description)\n",
    "\n",
    "request = \"\"\"\n",
    "Analyze these images of my home and smart meter to provide energy efficiency insights \n",
    "and recommendations for reducing my electricity consumption.\n",
    "\"\"\"\n",
    "\n",
    "# Base64 encoded image\n",
    "with open(\"/path/to/home_exterior.jpeg\", \"rb\") as img_file:\n",
    "    my_home_exterior = base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "analysis = energy_analyzer(\n",
    "    text_input=request,\n",
    "    images_input=[\n",
    "        \"https://example.com/my_smart_meter_reading.png\",  # Public URL\n",
    "        f\"data:image/jpeg;base64,{my_home_exterior}\",      # Base64 encoding\n",
    "        \"/path/to/living_room_thermostat.jpg\"              # Local image path\n",
    "    ]\n",
    ").output\n",
    "\n",
    "for key, value in analysis.items(): print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grounding via Access to the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of our models even have access to the web. Here's a complete list of models that do:\n",
    "\n",
    "\n",
    "| Model Name                        | Provider    |\n",
    "|-----------------------------------|-------------|\n",
    "| gemini-1.5-pro-002-online         | Google      |\n",
    "| gemini-1.5-flash-002-online       | Google      |\n",
    "| llama-3.1-sonar-huge-128k-online  | Perplexity  |\n",
    "| llama-3.1-sonar-large-128k-online | Perplexity  |\n",
    "| llama-3.1-sonar-small-128k-online | Perplexity  |\n",
    "\n",
    "To enable this, you need to the **Settings** menu of the specific function and select one of the above as the model to use. After, that simply change the `version` to the latest version or pass $-1$ when retrieving the `AIFunction` and deploy your code to production! An even easier way when deploying your code to production is to pass a particular alias that you set for the function version on our [platform](https://www.aifunction.com). This way, whenever you want to switch to a particular function version, you just need to set the alias on our [platform](https://www.aifunction.com) and it will automatically be deployed to your production code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your AI function has access to the web, it opens up a whole new way to ground your model outputs in every day events such as the stock market, current news and more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now understand why a model generated an output. For this, you'll need to enable Chain of Thought (CoT) for the function version on the [platform](https://www.aifunction.com). You can find this under the **Settings** for a particular function version. Then, to view the model's reasoning behind an output, simply use `return_reasoning=True` when you call the function on an input! This can be done for both synchronous and asynchronous and can be be done with the batched inputs as well. The reasoning behind the output can be found in the `.metadata[\"reasoning_steps\"]` attribute of the function response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_evaluator = build(task_description=\"I want to know if AI can solve a problem for me, how easy it is to arrive at a solution and whether any helpful tips for me along the way. Help me understand this through - 'feasibility', 'justification', and 'suggestions'.\")\n",
    "\n",
    "output, metadata = task_evaluator(\"I want to train a model to predict house prices using the Boston Housing dataset hosted on Kaggle.\", return_reasoning=True)\n",
    "for key, value in output.items(): print(f\"{key}: {value}\")\n",
    "for i, step in enumerate(metadata[\"reasoning_steps\"]): print(f\"Step {i+1}: {step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on what AI functions can do, check out these [examples](.)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
