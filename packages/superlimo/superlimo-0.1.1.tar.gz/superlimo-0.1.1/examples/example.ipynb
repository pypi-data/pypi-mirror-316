{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "\n",
    "from superlimo.lib import get_n, get_destimation_domain, warp, clip_and_pad_images, keypoints2position, get_pm_grids, pattern_matching, apply_pm_corrections\n",
    "from superlimo.matcher import Matcher\n",
    "from superlimo.superlimo import SuperLIMo\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "conf = OmegaConf.load('example_config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-downloaded images\n",
    "f0 = '../images/S1A_EW_GRDM_1SDH_20150121T132623_20150121T132723_004270_005316_D11B.SAFE'\n",
    "f1 = '../images/S1A_EW_GRDM_1SDH_20150123T063756_20150123T063856_004295_0053AD_73C7.SAFE'\n",
    "\n",
    "# Use Nansat to read data and custom simple preprocessing to resize SAR images\n",
    "n0 = get_n(f0)\n",
    "n1 = get_n(f1)\n",
    "# Create destiation domain (al paramerets are taken from configuration file)\n",
    "dst_dom = get_destimation_domain(conf.proj4, conf.extent, conf.sar_resolution)\n",
    "image_time_delta = (n1.time_coverage_start - n0.time_coverage_start).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warp (reproject SAR data to the destination domain)\n",
    "d = {}\n",
    "d['hh0'] = warp(n0, n0[1], dst_dom)\n",
    "d['hh1'] = warp(n1, n1[1], dst_dom)\n",
    "d['hv0'] = warp(n0, n0[2], dst_dom)\n",
    "d['hv1'] = warp(n1, n1[2], dst_dom)\n",
    "d = clip_and_pad_images(d, conf.min_sar_signal, conf.plim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axs[0].imshow(d['hh0'], cmap='gray')\n",
    "axs[1].imshow(d['hh1'], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy data to torch tensors\n",
    "img0 = torch.tensor(np.stack([d['hh0'], d['hv0']], 0))[None].float()\n",
    "img1 = torch.tensor(np.stack([d['hh1'], d['hv1']], 0))[None].float()\n",
    "img0[img0.isnan()] = 0\n",
    "img1[img1.isnan()] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SuperLIMo model and perform inference\n",
    "# Predictions from two images (pre0, pre1) contain keypoints positions, scores and descriptors\n",
    "superlimo = SuperLIMo(conf)\n",
    "with torch.no_grad():\n",
    "    pre0 = superlimo(img0)\n",
    "    pre1 = superlimo(img1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute position of keypoints in the coordinates of the destination domain\n",
    "pos0 = keypoints2position(pre0['keypoints'], dst_dom)\n",
    "pos1 = keypoints2position(pre1['keypoints'], dst_dom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do matching and filtering of the keypoints using brute force matcher, maximum drift filter and RANAC filter\n",
    "matcher = Matcher(plot=False, time_delta=image_time_delta, **conf)\n",
    "idx0, idx1, model = matcher.match(pos0, pos1, pre0['descriptors'].numpy().T, pre1['descriptors'].numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.quiver(pos0[idx0, 0], pos0[idx0, 1], pos1[idx1, 0] - pos0[idx0, 0], pos1[idx1, 1] - pos0[idx0, 1], angles='xy', scale_units='xy', scale=1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the matched keypoints to the initial coordinates of drift vectors and the first guess of the final coordinates of drift vectors\n",
    "c0pm, r0pm, x0pm, y0pm, c1pmfg, r1pmfg, gpi_pm = get_pm_grids(model, dst_dom, conf.pm_step, conf.pm_template_size, conf.pm_border, conf.proj4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform pattern matching and get corrections of the drift vectors\n",
    "corrections = pattern_matching(d, c0pm, r0pm, c1pmfg, r1pmfg, gpi_pm, conf.pm_template_size, conf.pm_border, conf.pm_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply corrections to the drift vectors\n",
    "x1pm, y1pm, c1pm, r1pm, mccpm = apply_pm_corrections(corrections, c1pmfg, r1pmfg, gpi_pm, dst_dom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpi = mccpm > 0.4\n",
    "plt.imshow(d['hh0'], extent=[x0pm.min(), x0pm.max(), y0pm.min(), y0pm.max()], cmap='gray')\n",
    "plt.quiver(x0pm[gpi], y0pm[gpi], x1pm[gpi] - x0pm[gpi], y1pm[gpi] - y0pm[gpi], mccpm[gpi], angles='xy', scale_units='xy', scale=3, cmap='jet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
