Metadata-Version: 2.1
Name: intel_optimization_for_horovod
Version: 0.28.1.6
Summary: Intel® Optimization for Horovod* is the distributed training framework for TensorFlow* and PyTorch*.
Home-page: https://github.com/intel/intel-optimization-for-horovod
Download-URL: https://github.com/intel/intel-optimization-for-horovod/tags
Author: Intel Corporation
License: Apache 2.0
Project-URL: Bug Tracker, https://github.com/intel/intel-optimization-for-horovod/issues
Keywords: deep learning,tensorflow,keras,pytorch,mxnet,spark,AI
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.6
License-File: LICENSE
License-File: NOTICE
Requires-Dist: cloudpickle
Requires-Dist: psutil
Requires-Dist: pyyaml
Requires-Dist: dataclasses; python_version < "3.7"
Requires-Dist: packaging
Requires-Dist: cffi>=1.4.0
Provides-Extra: all-frameworks
Requires-Dist: tensorflow; extra == "all-frameworks"
Requires-Dist: keras!=2.0.9,!=2.1.0,!=2.1.1,>=2.0.8; extra == "all-frameworks"
Requires-Dist: torch; extra == "all-frameworks"
Requires-Dist: mxnet>=1.4.1; extra == "all-frameworks"
Requires-Dist: numpy; extra == "all-frameworks"
Requires-Dist: petastorm>=0.12.0; extra == "all-frameworks"
Requires-Dist: pyarrow<11.0,>=0.15.0; extra == "all-frameworks"
Requires-Dist: fsspec>=2021.07.0; extra == "all-frameworks"
Requires-Dist: pyspark>=2.3.2; python_version < "3.8" and extra == "all-frameworks"
Requires-Dist: pyspark>=3.0.0; python_version >= "3.8" and extra == "all-frameworks"
Provides-Extra: tensorflow
Requires-Dist: tensorflow; extra == "tensorflow"
Provides-Extra: tensorflow-cpu
Requires-Dist: tensorflow-cpu; extra == "tensorflow-cpu"
Provides-Extra: tensorflow-gpu
Requires-Dist: tensorflow-gpu; extra == "tensorflow-gpu"
Provides-Extra: keras
Requires-Dist: keras!=2.0.9,!=2.1.0,!=2.1.1,>=2.0.8; extra == "keras"
Provides-Extra: pytorch
Requires-Dist: torch; extra == "pytorch"
Provides-Extra: mxnet
Requires-Dist: mxnet>=1.4.1; extra == "mxnet"
Provides-Extra: spark
Requires-Dist: numpy; extra == "spark"
Requires-Dist: petastorm>=0.12.0; extra == "spark"
Requires-Dist: pyarrow<11.0,>=0.15.0; extra == "spark"
Requires-Dist: fsspec>=2021.07.0; extra == "spark"
Requires-Dist: pyspark>=2.3.2; python_version < "3.8" and extra == "spark"
Requires-Dist: pyspark>=3.0.0; python_version >= "3.8" and extra == "spark"
Provides-Extra: pytorch-spark
Requires-Dist: torch; extra == "pytorch-spark"
Requires-Dist: numpy; extra == "pytorch-spark"
Requires-Dist: petastorm>=0.12.0; extra == "pytorch-spark"
Requires-Dist: pyarrow<11.0,>=0.15.0; extra == "pytorch-spark"
Requires-Dist: fsspec>=2021.07.0; extra == "pytorch-spark"
Requires-Dist: pyspark>=2.3.2; python_version < "3.8" and extra == "pytorch-spark"
Requires-Dist: pyspark>=3.0.0; python_version >= "3.8" and extra == "pytorch-spark"
Requires-Dist: pytorch_lightning<1.5.10,>=1.3.8; extra == "pytorch-spark"
Provides-Extra: ray
Requires-Dist: ray; extra == "ray"
Requires-Dist: aioredis<2; extra == "ray"
Requires-Dist: google-api-core<2.9.0; extra == "ray"
Provides-Extra: dev
Requires-Dist: tensorflow-cpu==2.2.0; extra == "dev"
Requires-Dist: keras==2.3.1; extra == "dev"
Requires-Dist: torch==1.4.0; extra == "dev"
Requires-Dist: torchvision==0.5.0; extra == "dev"
Requires-Dist: pytorch_lightning<1.5.10,>=1.3.8; extra == "dev"
Requires-Dist: mxnet==1.5.0; extra == "dev"
Requires-Dist: pyspark==3.0.1; extra == "dev"
Requires-Dist: numpy; extra == "dev"
Requires-Dist: petastorm>=0.12.0; extra == "dev"
Requires-Dist: pyarrow<11.0,>=0.15.0; extra == "dev"
Requires-Dist: fsspec>=2021.07.0; extra == "dev"
Provides-Extra: test
Requires-Dist: mock; extra == "test"
Requires-Dist: pytest; extra == "test"
Requires-Dist: pytest-forked; extra == "test"
Requires-Dist: pytest-subtests; extra == "test"
Requires-Dist: parameterized; extra == "test"

Intel® Optimization for Horovod* is the distributed training framework for TensorFlow* and PyTorch*.
The goal of Intel® Optimization for Horovod* is to make distributed Deep Learning fast and easy to use on Intel XPU(GPU, CPU, etc) devices.
