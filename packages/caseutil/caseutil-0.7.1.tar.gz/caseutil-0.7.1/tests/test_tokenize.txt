>>> from caseutil import tokenize

>>> tokenize('Space-separated,phrase')
'Space separated phrase'

>>> tokenize('some_0_Digits111')
'some 0 Digits111'

>>> ascii = ''.join(str(chr(c)) for c in range(256))
>>> import re
>>> sep = '_' + re.sub(r'\w', '', ascii)
>>> set(tokenize('Word1' + s + 'Word2') for s in sep) == {'Word1 Word2'}
True

>>> tokenize('ErrorType')
'Error Type'

>>> tokenize('Http404Error')
'Http404 Error'
>>> tokenize('Http404error')
'Http404error'

>>> tokenize('HTTPError')
'HTTP Error'
>>> tokenize('HTTP2Error')
'HTTP2 Error'

>>> tokenize('_some_name_')
'some name'

>>> tokenize('some-._name')
'some name'

>>> tokenize('')
''

