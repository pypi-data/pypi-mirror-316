# yapf: disable
# isort: skip_file
# ruff: noqa

# Standard imports.
from __future__ import annotations

# The following MUST appear before the rest of the imports, since those imports
# may be invalid (broken) if the generated code is mismatched with the installed
# libraries.
import reboot.version
if reboot.version.REBOOT_VERSION != "0.22.0":
    raise ImportError(
        "This code was generated for Reboot version '0.22.0', but the "
        f"installed Reboot version is '{ reboot.version.REBOOT_VERSION }'. "
        "Please run `rbt dev run` or `rbt protoc` to regenerate this code."
    )

# ATTENTION: no types in this file should be imported with their unqualified
#            name (e.g. `from typing import Any`). That would cause clashes
#            with user-defined methods that have the same name. Use
#            fully-qualified names (e.g. `typing.Any`) instead.
import asyncio
import dataclasses
import google.protobuf.descriptor
import google.protobuf.json_format
import google.protobuf.message
import grpc
import grpc_status._async as rpc_status_async
from grpc_status import rpc_status as rpc_status_sync
import json
import logging
import os
import sys
import traceback
import uuid
import pickle
import reboot
import log.log   # type: ignore[import]
import typing
import reboot.aio.backoff
import functools
from abc import abstractmethod
from datetime import datetime, timedelta
from google.protobuf import timestamp_pb2, wrappers_pb2
import reboot.aio.tracing
from google.rpc import status_pb2
import reboot.aio.call
import reboot.aio.contexts
import reboot.aio.headers
import reboot.aio.idempotency
import reboot.aio.internals.channel_manager
import reboot.aio.internals.middleware
from reboot.aio.internals.middleware import (
    maybe_run_function_twice_to_validate_effects,
)
import reboot.aio.internals.tasks_cache
import reboot.aio.internals.tasks_dispatcher
import reboot.aio.placement
import reboot.aio.servicers
import reboot.aio.state_managers
import reboot.aio.stubs
import reboot.aio.tasks
import reboot.aio.types
from reboot.aio.types import assert_type
import reboot.aio.external
from reboot.settings import MAX_ACTOR_ID_LENGTH, MIN_ACTOR_ID_LENGTH, MAX_BEARER_TOKEN_LENGTH
from rbt.v1alpha1 import tasks_pb2, tasks_pb2_grpc
import typing

# User defined or referenced imports.
import rbt.v1alpha1.options_pb2
import reboot.memoize.v1.memoize_pb2
import reboot.memoize.v1.memoize_pb2_grpc
# Additionally re-export all messages and enums from the pb2 module.
from reboot.memoize.v1.memoize_pb2 import (
    FailRequest,
    FailResponse,
    ResetRequest,
    ResetResponse,
    StartRequest,
    StartResponse,
    StatusRequest,
    StatusResponse,
    StoreRequest,
    StoreResponse,
)

logger = log.log .get_logger(__name__)

# When we are running this code within `node` we might want to log
# things differently. For example, if we already have some logging in
# our TypeScript code these logs may be redundant. Or we want to avoid
# printing stack traces as those are Python specific.
NODEJS: bool = os.environ.get(
    reboot.settings.ENVVAR_REBOOT_NODEJS, "false"
).lower() == "true"


############################ Legacy gRPC Servicers ############################
# This section is relevant (only) for servicers that implement a legacy gRPC
# service in a Reboot context. It is irrelevant to clients.

def MakeLegacyGrpcServiceable(
    # A legacy gRPC servicer type can't be more specific than `type`,
    # because legacy gRPC servicers (as generated by the gRPC `protoc`
    # plugin) do not share any common base class other than `object`.
    servicer_type: type
) -> reboot.aio.servicers.Serviceable:
    raise ValueError(f"Unknown legacy gRPC servicer type '{servicer_type}'")



############################ Reboot Servicer Middlewares ############################
# This section is relevant (only) for servicers implementing a Reboot servicer. It
# is irrelevant to clients, except for the fact that some clients are _also_ such
# servicers.

# For internal calls, we can use a magic token to bypass token verification and
# authorization checks. The token provides no auth information (e.g.,
# `context.auth is None`).
__internal_magic_token__: str = f'internal-{str(uuid.uuid4())}'

class MemoizeServicerMiddleware(reboot.aio.internals.middleware.Middleware):

    def __init__(
        self,
        *,
        servicer: MemoizeServicer,
        application_id: reboot.aio.types.ApplicationId,
        consensus_id: reboot.aio.types.ConsensusId,
        state_manager: reboot.aio.state_managers.StateManager,
        placement_client: reboot.aio.placement.PlacementClient,
        channel_manager: reboot.aio.internals.channel_manager._ChannelManager,
        tasks_cache: reboot.aio.internals.tasks_cache.TasksCache,
        token_verifier: typing.Optional[reboot.aio.auth.token_verifiers.TokenVerifier],
        effect_validation: reboot.aio.contexts.EffectValidation,
        app_internal_api_key_secret: str,
        ready: asyncio.Event,
    ):
        super().__init__(
            application_id=application_id,
            consensus_id=consensus_id,
            state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            service_names = [
                reboot.aio.types.ServiceName("reboot.memoize.v1.MemoizeMethods"),
            ],
            placement_client=placement_client,
            channel_manager=channel_manager,
            effect_validation=effect_validation,
            app_internal_api_key_secret=app_internal_api_key_secret,
        )

        self._servicer = servicer
        self._state_manager = state_manager
        self.tasks_dispatcher = reboot.aio.internals.tasks_dispatcher.TasksDispatcher(
            application_id=application_id,
            dispatch=self.dispatch,
            tasks_cache=tasks_cache,
            ready=ready,
        )

        # Store the type of each method's request so that stored requests can be
        # deserialized into the correct type.
        self.request_type_by_method_name: dict[str, type[google.protobuf.message.Message]] = {
            'Reset': reboot.memoize.v1.memoize_pb2.ResetRequest,
            'Start': reboot.memoize.v1.memoize_pb2.StartRequest,
            'Store': reboot.memoize.v1.memoize_pb2.StoreRequest,
            'Fail': reboot.memoize.v1.memoize_pb2.FailRequest,
            'Status': reboot.memoize.v1.memoize_pb2.StatusRequest,
        }

        # Create authorizer.
        self._authorizer: typing.Optional[reboot.aio.auth.authorizers.Authorizer] = servicer.authorizer()

        # Create token verifier.
        self._token_verifier: typing.Optional[reboot.aio.auth.token_verifiers.TokenVerifier] = (
            servicer.token_verifier() or token_verifier
        )

        if self._token_verifier is not None and self._authorizer is None:
            raise RuntimeError(
                f"'TokenVerifier' provided but no 'Authorizer' returned for "
                f"'reboot.memoize.v1.Memoize'"
            )

        # Since users specify errors as proto messages they can't raise them
        # directly - to do so they have to use the `Aborted` wrapper, which will
        # hold the original proto message. On errors we'll need to check whether
        # such wrappers hold a proto message for a specified error, so we can
        # avoid retrying tasks that complete with a specified error.
        self._specified_errors_by_service_method_name: dict[str, list[str]] = {
        }


    def add_to_server(self, server: grpc.aio.Server) -> None:
        reboot.memoize.v1.memoize_pb2_grpc.add_MemoizeMethodsServicer_to_server(
            self, server
        )

    async def inspect(self, state_ref: reboot.aio.types.StateRef) -> typing.AsyncIterator[google.protobuf.message.Message]:
        """Implementation of `Middleware.inspect()`."""
        context = self.create_context(
            headers=reboot.aio.headers.Headers(
                application_id=self.application_id,
                state_ref=state_ref,
            ),
            state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            context_type=reboot.aio.contexts.ReaderContext,
        )

        async with self._state_manager.streaming_reader_idempotency_key(
            context,
            self._servicer.__state_type__,
            authorize=None,
        ) as states:
            async for (state, idempotency_key) in states:
                yield state

    async def react_query(
        self,
        headers: reboot.aio.headers.Headers,
        method: str,
        request_bytes: bytes,
    ) -> typing.AsyncIterator[tuple[typing.Optional[google.protobuf.message.Message], list[uuid.UUID]]]:
        """Returns the response of calling 'method' given a message
        deserialized from the provided 'request_bytes' for each state
        update that creates a different response.

        # The caller (react.py) should have already ensured that this consensus
        # is authoritative for this traffic.
        assert self.placement_client.consensus_for_actor(
            headers.application_id,
            headers.state_ref,
        ) == self._consensus_id

        NOTE: only unary reader methods are supported."""
        # Need to define these up here since we can only do that once.
        last_response: typing.Optional[google.protobuf.message.Message] = None
        aggregated_idempotency_keys: list[uuid.UUID] = []
        if method == 'Reset':
            # Invariant here is that users should not have called this
            # directly but only through code generated React
            # components which should not have been generated except
            # for valid method candidates.
            logger.warning(
                "Got a React query request with an invalid method name: "
                f"Method '{method}' is invalid for servicer Memoize."
                "\n"
                "Do you have a browser tab open for an older version "
                "of this application, or for a different application all together?"
            )
            raise reboot.aio.aborted.SystemAborted(
                rbt.v1alpha1.errors_pb2.InvalidMethod(),
                message=
                    f"Method '{method}' is invalid"
            )
            yield  # Necessary for type checking.
        elif method == 'Start':
            # Invariant here is that users should not have called this
            # directly but only through code generated React
            # components which should not have been generated except
            # for valid method candidates.
            logger.warning(
                "Got a React query request with an invalid method name: "
                f"Method '{method}' is invalid for servicer Memoize."
                "\n"
                "Do you have a browser tab open for an older version "
                "of this application, or for a different application all together?"
            )
            raise reboot.aio.aborted.SystemAborted(
                rbt.v1alpha1.errors_pb2.InvalidMethod(),
                message=
                    f"Method '{method}' is invalid"
            )
            yield  # Necessary for type checking.
        elif method == 'Store':
            # Invariant here is that users should not have called this
            # directly but only through code generated React
            # components which should not have been generated except
            # for valid method candidates.
            logger.warning(
                "Got a React query request with an invalid method name: "
                f"Method '{method}' is invalid for servicer Memoize."
                "\n"
                "Do you have a browser tab open for an older version "
                "of this application, or for a different application all together?"
            )
            raise reboot.aio.aborted.SystemAborted(
                rbt.v1alpha1.errors_pb2.InvalidMethod(),
                message=
                    f"Method '{method}' is invalid"
            )
            yield  # Necessary for type checking.
        elif method == 'Fail':
            # Invariant here is that users should not have called this
            # directly but only through code generated React
            # components which should not have been generated except
            # for valid method candidates.
            logger.warning(
                "Got a React query request with an invalid method name: "
                f"Method '{method}' is invalid for servicer Memoize."
                "\n"
                "Do you have a browser tab open for an older version "
                "of this application, or for a different application all together?"
            )
            raise reboot.aio.aborted.SystemAborted(
                rbt.v1alpha1.errors_pb2.InvalidMethod(),
                message=
                    f"Method '{method}' is invalid"
            )
            yield  # Necessary for type checking.
        elif method == 'Status':

            context = self.create_context(
                headers=headers,
                state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                context_type=reboot.aio.contexts.ReaderContext,
            )

            context.auth = await self._maybe_verify_token(headers)

            request = reboot.memoize.v1.memoize_pb2.StatusRequest()
            request.ParseFromString(request_bytes)

            async with self._state_manager.reactively(
                context,
                self._servicer.__state_type__,
                authorize=self._maybe_authorize(
                    method_name='reboot.memoize.v1.MemoizeMethods.Status',
                    headers=headers,
                    auth=context.auth,
                    request=request,
                ),
            ) as states:
                async for (state, idempotency_keys) in states:

                    aggregated_idempotency_keys.extend(idempotency_keys)

                    # Note: This does not do any defensive copying currently:
                    # see https://github.com/reboot-dev/respect/issues/2636.
                    @maybe_run_function_twice_to_validate_effects
                    async def run__Status(validating_effects: bool) -> google.protobuf.message.Message:
                        return await self.__Status(
                            context,
                            state,
                            request,
                            validating_effects=validating_effects,
                        )

                    response = await run__Status()

                    if last_response != response:
                        yield (response, aggregated_idempotency_keys)
                        last_response = response
                    else:
                        yield (None, aggregated_idempotency_keys)

                    aggregated_idempotency_keys.clear()
        else:
            logger.warning(
                "Got a React query request with an invalid method name: "
                "Method '{method}' is invalid for servicer Memoize."
                "\n"
                "Do you have a browser tab open for an older version "
                "of this application, or for a different application all together?"
            )
            raise reboot.aio.aborted.SystemAborted(
                rbt.v1alpha1.errors_pb2.InvalidMethod(),
                message=
                    f"Method '{method}' not found"
            )
            yield  # Unreachable but necessary for mypy.

    async def react_mutate(
        self,
        headers: reboot.aio.headers.Headers,
        method: str,
        request_bytes: bytes,
    ) -> google.protobuf.message.Message:
        """Returns the response of calling 'method' given a message
        deserialized from the provided 'request_bytes'."""
        if method == 'Reset':
            request = reboot.memoize.v1.memoize_pb2.ResetRequest()
            request.ParseFromString(request_bytes)

            # NOTE: we automatically retry mutations that come through
            # React when we get a `grpc.StatusCode.UNAVAILABLE` to
            # match the retry logic we do in the React code generated
            # to handle lack/loss of connectivity.
            #
            # TODO(benh): revisit this decision if we ever see reason
            # to call `react_mutate()` from any place other than where
            # we're executing React (e.g., browser, next.js server
            # component, etc).
            call_backoff = reboot.aio.backoff.Backoff()
            while True:
                # We make a full-fledged gRPC call, so that if this traffic
                # was misrouted (i.e. this consensus is not authoritative
                # for the state), it will now go to the right place. The
                # receiving middleware will handle things like effect
                # validation and so forth.
                assert headers.application_id is not None  # Guaranteed by `Headers`.
                stub = reboot.memoize.v1.memoize_pb2_grpc.MemoizeMethodsStub(
                    self.channel_manager.get_channel_to(
                        self.placement_client.address_for_actor(
                            headers.application_id,
                            headers.state_ref,
                        )
                    )
                )
                call = stub.Reset(
                    request=request,
                    metadata=headers.to_grpc_metadata(),
                )
                try:
                    return await call
                except grpc.aio.AioRpcError as error:
                    if error.code() == grpc.StatusCode.UNAVAILABLE:
                        await call_backoff()
                        continue

                    # Reconstitute the error that the server threw, if it was a declared error.
                    status = await rpc_status_async.from_call(call)
                    if status is not None:
                        raise Memoize.ResetAborted.from_status(
                            status
                        ) from None
                    raise Memoize.ResetAborted.from_grpc_aio_rpc_error(
                        error
                     ) from None

        elif method == 'Start':
            request = reboot.memoize.v1.memoize_pb2.StartRequest()
            request.ParseFromString(request_bytes)

            # NOTE: we automatically retry mutations that come through
            # React when we get a `grpc.StatusCode.UNAVAILABLE` to
            # match the retry logic we do in the React code generated
            # to handle lack/loss of connectivity.
            #
            # TODO(benh): revisit this decision if we ever see reason
            # to call `react_mutate()` from any place other than where
            # we're executing React (e.g., browser, next.js server
            # component, etc).
            call_backoff = reboot.aio.backoff.Backoff()
            while True:
                # We make a full-fledged gRPC call, so that if this traffic
                # was misrouted (i.e. this consensus is not authoritative
                # for the state), it will now go to the right place. The
                # receiving middleware will handle things like effect
                # validation and so forth.
                assert headers.application_id is not None  # Guaranteed by `Headers`.
                stub = reboot.memoize.v1.memoize_pb2_grpc.MemoizeMethodsStub(
                    self.channel_manager.get_channel_to(
                        self.placement_client.address_for_actor(
                            headers.application_id,
                            headers.state_ref,
                        )
                    )
                )
                call = stub.Start(
                    request=request,
                    metadata=headers.to_grpc_metadata(),
                )
                try:
                    return await call
                except grpc.aio.AioRpcError as error:
                    if error.code() == grpc.StatusCode.UNAVAILABLE:
                        await call_backoff()
                        continue

                    # Reconstitute the error that the server threw, if it was a declared error.
                    status = await rpc_status_async.from_call(call)
                    if status is not None:
                        raise Memoize.StartAborted.from_status(
                            status
                        ) from None
                    raise Memoize.StartAborted.from_grpc_aio_rpc_error(
                        error
                     ) from None

        elif method == 'Store':
            request = reboot.memoize.v1.memoize_pb2.StoreRequest()
            request.ParseFromString(request_bytes)

            # NOTE: we automatically retry mutations that come through
            # React when we get a `grpc.StatusCode.UNAVAILABLE` to
            # match the retry logic we do in the React code generated
            # to handle lack/loss of connectivity.
            #
            # TODO(benh): revisit this decision if we ever see reason
            # to call `react_mutate()` from any place other than where
            # we're executing React (e.g., browser, next.js server
            # component, etc).
            call_backoff = reboot.aio.backoff.Backoff()
            while True:
                # We make a full-fledged gRPC call, so that if this traffic
                # was misrouted (i.e. this consensus is not authoritative
                # for the state), it will now go to the right place. The
                # receiving middleware will handle things like effect
                # validation and so forth.
                assert headers.application_id is not None  # Guaranteed by `Headers`.
                stub = reboot.memoize.v1.memoize_pb2_grpc.MemoizeMethodsStub(
                    self.channel_manager.get_channel_to(
                        self.placement_client.address_for_actor(
                            headers.application_id,
                            headers.state_ref,
                        )
                    )
                )
                call = stub.Store(
                    request=request,
                    metadata=headers.to_grpc_metadata(),
                )
                try:
                    return await call
                except grpc.aio.AioRpcError as error:
                    if error.code() == grpc.StatusCode.UNAVAILABLE:
                        await call_backoff()
                        continue

                    # Reconstitute the error that the server threw, if it was a declared error.
                    status = await rpc_status_async.from_call(call)
                    if status is not None:
                        raise Memoize.StoreAborted.from_status(
                            status
                        ) from None
                    raise Memoize.StoreAborted.from_grpc_aio_rpc_error(
                        error
                     ) from None

        elif method == 'Fail':
            request = reboot.memoize.v1.memoize_pb2.FailRequest()
            request.ParseFromString(request_bytes)

            # NOTE: we automatically retry mutations that come through
            # React when we get a `grpc.StatusCode.UNAVAILABLE` to
            # match the retry logic we do in the React code generated
            # to handle lack/loss of connectivity.
            #
            # TODO(benh): revisit this decision if we ever see reason
            # to call `react_mutate()` from any place other than where
            # we're executing React (e.g., browser, next.js server
            # component, etc).
            call_backoff = reboot.aio.backoff.Backoff()
            while True:
                # We make a full-fledged gRPC call, so that if this traffic
                # was misrouted (i.e. this consensus is not authoritative
                # for the state), it will now go to the right place. The
                # receiving middleware will handle things like effect
                # validation and so forth.
                assert headers.application_id is not None  # Guaranteed by `Headers`.
                stub = reboot.memoize.v1.memoize_pb2_grpc.MemoizeMethodsStub(
                    self.channel_manager.get_channel_to(
                        self.placement_client.address_for_actor(
                            headers.application_id,
                            headers.state_ref,
                        )
                    )
                )
                call = stub.Fail(
                    request=request,
                    metadata=headers.to_grpc_metadata(),
                )
                try:
                    return await call
                except grpc.aio.AioRpcError as error:
                    if error.code() == grpc.StatusCode.UNAVAILABLE:
                        await call_backoff()
                        continue

                    # Reconstitute the error that the server threw, if it was a declared error.
                    status = await rpc_status_async.from_call(call)
                    if status is not None:
                        raise Memoize.FailAborted.from_status(
                            status
                        ) from None
                    raise Memoize.FailAborted.from_grpc_aio_rpc_error(
                        error
                     ) from None

        elif method == 'Status':
            # Invariant here is that users should not have called this
            # directly but only through code generated React
            # components which should not have been generated except
            # for valid method candidates.
            logger.warning(
                "Got a react mutate request with an invalid method name: "
                "Method 'Status' is invalid for servicer Memoize."
                "\n"
                "Do you have an old browser tab still open for an older version "
                "of this application, or a different application all together?"
            )
            raise reboot.aio.aborted.SystemAborted(
                rbt.v1alpha1.errors_pb2.InvalidMethod(),
                message=f"Method '{method}' is invalid"
            )
        else:
            logger.warning(
                "Got a react mutate request with an invalid method name: "
                "Method '{method}' is invalid for servicer Memoize."
                "\n"
                "Do you have an old browser tab still open for an older version "
                "of this application, or a different application all together?"
            )
            raise reboot.aio.aborted.SystemAborted(
                rbt.v1alpha1.errors_pb2.InvalidMethod(),
                message=
                    f"Method '{method}' not found"
            )

    async def dispatch(
        self,
        task: reboot.aio.tasks.TaskEffect,
        *,
        only_validate: bool = False,
    ) -> reboot.aio.internals.tasks_dispatcher.TaskResponseOrError:
        """Dispatches the tasks to execute unless 'only_validate' is set to
        true, in which case just ensures that the task actually exists.
        Note that this function will be called *by* tasks_dispatcher; it will
        not itself call into tasks_dispatcher."""

        if 'Reset' == task.method_name:
            if only_validate:
                # TODO(benh): validate 'task.request' is correct type.
                return reboot.memoize.v1.memoize_pb2.ResetResponse()

            # Use an inline method to create a new scope, so that we can use
            # variable names like `context` and `effects` in multiple branches
            # in this code (notably when there are multiple task types) without
            # hitting a mypy error that the variable's type is not consistent.
            async def run_Reset(
                context: reboot.aio.contexts.WorkflowContext,
            ):
                async with self._state_manager.task_workflow(
                    context,
                ) as complete:
                    self.tasks_dispatcher.set_complete_task(complete)

                    try:
                        response = await (MemoizeWorkflowStub(
                            context=context,
                            state_ref=context._state_ref,
                        ).Reset(
                            typing.cast(reboot.memoize.v1.memoize_pb2.ResetRequest, task.request),
                            bearer_token=__internal_magic_token__,
                            idempotency=reboot.aio.idempotency.Idempotency(
                                alias=f'Task {task.task_id.task_uuid}',
                            ),
                        ))

                        await complete(task, (response, None))
                        return (response, None)

                    except asyncio.CancelledError:
                        # Check if the task was cancelled by a TasksServicer.
                        if self.tasks_dispatcher.is_task_cancelled(task.task_id.task_uuid):
                            # The running task was cancelled by a TasksServicer.
                            await complete(task, (None, tasks_pb2.TaskCancelledError()))
                            return (None, tasks_pb2.TaskCancelledError())
                        else:
                            raise
                    except reboot.aio.aborted.Aborted as aborted:
                        error_type = f'{aborted.error.__class__.__module__}.{aborted.error.__class__.__qualname__}'
                        # Do not retry a task if the error was specified in the
                        # proto file.
                        if error_type in self._specified_errors_by_service_method_name.get('reboot.memoize.v1.MemoizeMethods.Reset', []):
                            await complete(task, (None, aborted.error))
                            return (None, aborted.error)
                        raise


            return await run_Reset(
                self.create_context(
                    headers=reboot.aio.headers.Headers(
                        application_id=self.application_id,
                        state_ref=reboot.aio.types.StateRef(task.task_id.state_ref),
                    ),
                    state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    context_type=reboot.aio.contexts.WorkflowContext,
                    task=task,
                )
            )
        elif 'Start' == task.method_name:
            if only_validate:
                # TODO(benh): validate 'task.request' is correct type.
                return reboot.memoize.v1.memoize_pb2.StartResponse()

            # Use an inline method to create a new scope, so that we can use
            # variable names like `context` and `effects` in multiple branches
            # in this code (notably when there are multiple task types) without
            # hitting a mypy error that the variable's type is not consistent.
            async def run_Start(
                context: reboot.aio.contexts.WorkflowContext,
            ):
                async with self._state_manager.task_workflow(
                    context,
                ) as complete:
                    self.tasks_dispatcher.set_complete_task(complete)

                    try:
                        response = await (MemoizeWorkflowStub(
                            context=context,
                            state_ref=context._state_ref,
                        ).Start(
                            typing.cast(reboot.memoize.v1.memoize_pb2.StartRequest, task.request),
                            bearer_token=__internal_magic_token__,
                            idempotency=reboot.aio.idempotency.Idempotency(
                                alias=f'Task {task.task_id.task_uuid}',
                            ),
                        ))

                        await complete(task, (response, None))
                        return (response, None)

                    except asyncio.CancelledError:
                        # Check if the task was cancelled by a TasksServicer.
                        if self.tasks_dispatcher.is_task_cancelled(task.task_id.task_uuid):
                            # The running task was cancelled by a TasksServicer.
                            await complete(task, (None, tasks_pb2.TaskCancelledError()))
                            return (None, tasks_pb2.TaskCancelledError())
                        else:
                            raise
                    except reboot.aio.aborted.Aborted as aborted:
                        error_type = f'{aborted.error.__class__.__module__}.{aborted.error.__class__.__qualname__}'
                        # Do not retry a task if the error was specified in the
                        # proto file.
                        if error_type in self._specified_errors_by_service_method_name.get('reboot.memoize.v1.MemoizeMethods.Start', []):
                            await complete(task, (None, aborted.error))
                            return (None, aborted.error)
                        raise


            return await run_Start(
                self.create_context(
                    headers=reboot.aio.headers.Headers(
                        application_id=self.application_id,
                        state_ref=reboot.aio.types.StateRef(task.task_id.state_ref),
                    ),
                    state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    context_type=reboot.aio.contexts.WorkflowContext,
                    task=task,
                )
            )
        elif 'Store' == task.method_name:
            if only_validate:
                # TODO(benh): validate 'task.request' is correct type.
                return reboot.memoize.v1.memoize_pb2.StoreResponse()

            # Use an inline method to create a new scope, so that we can use
            # variable names like `context` and `effects` in multiple branches
            # in this code (notably when there are multiple task types) without
            # hitting a mypy error that the variable's type is not consistent.
            async def run_Store(
                context: reboot.aio.contexts.WorkflowContext,
            ):
                async with self._state_manager.task_workflow(
                    context,
                ) as complete:
                    self.tasks_dispatcher.set_complete_task(complete)

                    try:
                        response = await (MemoizeWorkflowStub(
                            context=context,
                            state_ref=context._state_ref,
                        ).Store(
                            typing.cast(reboot.memoize.v1.memoize_pb2.StoreRequest, task.request),
                            bearer_token=__internal_magic_token__,
                            idempotency=reboot.aio.idempotency.Idempotency(
                                alias=f'Task {task.task_id.task_uuid}',
                            ),
                        ))

                        await complete(task, (response, None))
                        return (response, None)

                    except asyncio.CancelledError:
                        # Check if the task was cancelled by a TasksServicer.
                        if self.tasks_dispatcher.is_task_cancelled(task.task_id.task_uuid):
                            # The running task was cancelled by a TasksServicer.
                            await complete(task, (None, tasks_pb2.TaskCancelledError()))
                            return (None, tasks_pb2.TaskCancelledError())
                        else:
                            raise
                    except reboot.aio.aborted.Aborted as aborted:
                        error_type = f'{aborted.error.__class__.__module__}.{aborted.error.__class__.__qualname__}'
                        # Do not retry a task if the error was specified in the
                        # proto file.
                        if error_type in self._specified_errors_by_service_method_name.get('reboot.memoize.v1.MemoizeMethods.Store', []):
                            await complete(task, (None, aborted.error))
                            return (None, aborted.error)
                        raise


            return await run_Store(
                self.create_context(
                    headers=reboot.aio.headers.Headers(
                        application_id=self.application_id,
                        state_ref=reboot.aio.types.StateRef(task.task_id.state_ref),
                    ),
                    state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    context_type=reboot.aio.contexts.WorkflowContext,
                    task=task,
                )
            )
        elif 'Fail' == task.method_name:
            if only_validate:
                # TODO(benh): validate 'task.request' is correct type.
                return reboot.memoize.v1.memoize_pb2.FailResponse()

            # Use an inline method to create a new scope, so that we can use
            # variable names like `context` and `effects` in multiple branches
            # in this code (notably when there are multiple task types) without
            # hitting a mypy error that the variable's type is not consistent.
            async def run_Fail(
                context: reboot.aio.contexts.WorkflowContext,
            ):
                async with self._state_manager.task_workflow(
                    context,
                ) as complete:
                    self.tasks_dispatcher.set_complete_task(complete)

                    try:
                        response = await (MemoizeWorkflowStub(
                            context=context,
                            state_ref=context._state_ref,
                        ).Fail(
                            typing.cast(reboot.memoize.v1.memoize_pb2.FailRequest, task.request),
                            bearer_token=__internal_magic_token__,
                            idempotency=reboot.aio.idempotency.Idempotency(
                                alias=f'Task {task.task_id.task_uuid}',
                            ),
                        ))

                        await complete(task, (response, None))
                        return (response, None)

                    except asyncio.CancelledError:
                        # Check if the task was cancelled by a TasksServicer.
                        if self.tasks_dispatcher.is_task_cancelled(task.task_id.task_uuid):
                            # The running task was cancelled by a TasksServicer.
                            await complete(task, (None, tasks_pb2.TaskCancelledError()))
                            return (None, tasks_pb2.TaskCancelledError())
                        else:
                            raise
                    except reboot.aio.aborted.Aborted as aborted:
                        error_type = f'{aborted.error.__class__.__module__}.{aborted.error.__class__.__qualname__}'
                        # Do not retry a task if the error was specified in the
                        # proto file.
                        if error_type in self._specified_errors_by_service_method_name.get('reboot.memoize.v1.MemoizeMethods.Fail', []):
                            await complete(task, (None, aborted.error))
                            return (None, aborted.error)
                        raise


            return await run_Fail(
                self.create_context(
                    headers=reboot.aio.headers.Headers(
                        application_id=self.application_id,
                        state_ref=reboot.aio.types.StateRef(task.task_id.state_ref),
                    ),
                    state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    context_type=reboot.aio.contexts.WorkflowContext,
                    task=task,
                )
            )
        elif 'Status' == task.method_name:
            if only_validate:
                # TODO(benh): validate 'task.request' is correct type.
                return reboot.memoize.v1.memoize_pb2.StatusResponse()

            # Use an inline method to create a new scope, so that we can use
            # variable names like `context` and `effects` in multiple branches
            # in this code (notably when there are multiple task types) without
            # hitting a mypy error that the variable's type is not consistent.
            async def run_Status(
                context: reboot.aio.contexts.WorkflowContext,
            ):
                async with self._state_manager.task_workflow(
                    context,
                ) as complete:
                    self.tasks_dispatcher.set_complete_task(complete)

                    try:
                        response = await (MemoizeWorkflowStub(
                            context=context,
                            state_ref=context._state_ref,
                        ).Status(
                            typing.cast(reboot.memoize.v1.memoize_pb2.StatusRequest, task.request),
                            bearer_token=__internal_magic_token__,
                        ))

                        await complete(task, (response, None))
                        return (response, None)

                    except asyncio.CancelledError:
                        # Check if the task was cancelled by a TasksServicer.
                        if self.tasks_dispatcher.is_task_cancelled(task.task_id.task_uuid):
                            # The running task was cancelled by a TasksServicer.
                            await complete(task, (None, tasks_pb2.TaskCancelledError()))
                            return (None, tasks_pb2.TaskCancelledError())
                        else:
                            raise
                    except reboot.aio.aborted.Aborted as aborted:
                        error_type = f'{aborted.error.__class__.__module__}.{aborted.error.__class__.__qualname__}'
                        # Do not retry a task if the error was specified in the
                        # proto file.
                        if error_type in self._specified_errors_by_service_method_name.get('reboot.memoize.v1.MemoizeMethods.Status', []):
                            await complete(task, (None, aborted.error))
                            return (None, aborted.error)
                        raise


            return await run_Status(
                self.create_context(
                    headers=reboot.aio.headers.Headers(
                        application_id=self.application_id,
                        state_ref=reboot.aio.types.StateRef(task.task_id.state_ref),
                    ),
                    state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    context_type=reboot.aio.contexts.WorkflowContext,
                    task=task,
                )
            )

        # There are no tasks for this service.
        start_or_validate = "start" if not only_validate else "validate"
        raise RuntimeError(
            f"Attempted to {start_or_validate} task '{task.method_name}' "
            f"on 'Memoize' which does not exist"
        )

    # Memoize specific methods:
    async def __Reset(
        self,
        context: reboot.aio.contexts.WriterContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.ResetRequest,
        *,
        validating_effects: bool,
    ) -> Memoize.ResetEffects:
        try:
            response = (
                await self._servicer.Reset(
                    context=context,
                    state=state,
                    request=request
                )
            )
            assert_type(
                response,
                [
                    reboot.memoize.v1.memoize_pb2.ResetResponse,
                ],
            )
            # TODO: retrying a control loop might cause an effect
            # validation retry to either "hang" or "do more
            # work". It's not clear that this is always a bug, i.e.,
            # the intent of effect validation for a `workflow` method
            # is to ensure it can handle a failure and the developer
            # might have written the code to handle failures and still
            # run into the "hang" or "do more work" due to effect
            # validation. So for now, we don't bother doing effect
            # validation for loops since we'll be re-running it again.
            if not isinstance(response, reboot.aio.tasks.Loop):
                self.maybe_raise_effect_validation_retry(
                    logger=logger,
                    idempotency_manager=context,
                    method_name='Memoize.Reset',
                    validating_effects=validating_effects,
                    context=context,
                )
            return Memoize.ResetEffects(
                state=state,
                response=response,
                tasks=context._tasks,
                _colocated_upserts=context._colocated_upserts,
            )
        except reboot.aio.contexts.RetryReactively:
            # Retrying reactively, just let this propagate.
            raise
        except reboot.aio.contexts.EffectValidationRetry:
            # Doing effect validation, just let this propagate.
            raise
        except reboot.aio.aborted.Aborted as aborted:
            # Log any _unhandled_ abort stack traces to make it
            # easier for debugging.
            #
            # NOTE: we don't log if we're a task as it will be logged
            # in `reboot/aio/internals/tasks_dispatcher.py` instead.
            aborted_type: typing.Optional[type] = None
            aborted_type = Memoize.ResetAborted
            if isinstance(aborted, reboot.aio.aborted.SystemAborted):
                # Not logging when within `node` as we already log there.
                if not NODEJS:
                    logger.warning(
                        f"Unhandled (in 'reboot.memoize.v1.Memoize.Reset') {aborted}; propagating as 'Unknown'\n" +
                        ''.join(traceback.format_exception(aborted))
                    )
                raise reboot.aio.aborted.SystemAborted(
                    rbt.v1alpha1.errors_pb2.Unknown(),
                    # TODO(benh): consider whether or not we want to
                    # include the 'package.service.method' which may
                    # get concatenated together forming a kind of
                    # "stack trace"; while it's super helpful for
                    # debugging, it does expose implementation
                    # information.
                    message=f"unhandled (in 'reboot.memoize.v1.Memoize.Reset') {aborted}"
                )
            else:
                if (
                    aborted_type is not None and
                    not isinstance(aborted, aborted_type) and
                    aborted_type.is_declared_error(aborted.error)
                ):
                    if context.task is None:
                        logger.warning(
                            f"Propagating unhandled (in 'reboot.memoize.v1.Memoize.Reset') {aborted}"
                        )
                elif (
                    aborted_type is None or
                    not isinstance(aborted, aborted_type)
                ):
                    # Not logging when within `node` as we already log there.
                    if not NODEJS:
                        logger.warning(
                            f"Unhandled (in 'reboot.memoize.v1.Memoize.Reset') {aborted}; propagating as 'Unknown'\n" +
                            ''.join(traceback.format_exception(aborted))
                        )
                    raise reboot.aio.aborted.SystemAborted(
                        rbt.v1alpha1.errors_pb2.Unknown(),
                        # TODO(benh): consider whether or not we want to
                        # include the 'package.service.method' which may
                        # get concatenated together forming a kind of
                        # "stack trace"; while it's super helpful for
                        # debugging, it does expose implementation
                        # information.
                        message=f"unhandled (in 'reboot.memoize.v1.Memoize.Reset') {aborted}"
                    )

            raise
        except asyncio.CancelledError:
            # It's pretty normal for an RPC to be cancelled; it's not useful to
            # print a stack trace.
            raise
        except BaseException as exception:
            # Not logging when within `node` as we already log there.
            if not NODEJS:
                logger.warning(
                    f"Unhandled (in 'reboot.memoize.v1.Memoize.Reset') {type(exception).__name__}: {exception}; propagating as 'Unknown'\n" +
                    ''.join(traceback.format_exception(exception))
                )
            raise reboot.aio.aborted.SystemAborted(
                rbt.v1alpha1.errors_pb2.Unknown(),
                # TODO(benh): consider whether or not we want to
                # include the 'package.service.method' which may
                # get concatenated together forming a kind of
                # "stack trace"; while it's super helpful for
                # debugging, it does expose implementation
                # information.
                message=f"unhandled (in 'reboot.memoize.v1.Memoize.Reset') {type(exception).__name__}: {exception}"
            )

    @reboot.aio.tracing.function_span(
        # We expect an `EffectValidationRetry` exception; that's not an error.
        set_status_on_exception=False
    )
    async def _Reset(
        self,
        request: reboot.memoize.v1.memoize_pb2.ResetRequest,
        context: reboot.aio.contexts.WriterContext,
        *,
        validating_effects: bool,
        grpc_context: typing.Optional[grpc.aio.ServicerContext] = None,
    ) -> reboot.memoize.v1.memoize_pb2.ResetResponse:
        # Try to verify the token if a token verifier exists.
        context.auth = await self._maybe_verify_token(context._headers)

        # Check if we already have performed this mutation!
        #
        # We do this _before_ calling 'transactionally()' because
        # if this call is for a transaction method _and_ we've
        # already performed the transaction then we don't want to
        # become a transaction participant (again) we just want to
        # return the transaction's response.
        idempotent_mutation = self._state_manager.check_for_idempotent_mutation(
            context
        )

        if idempotent_mutation is not None:
            response = reboot.memoize.v1.memoize_pb2.ResetResponse()
            response.ParseFromString(idempotent_mutation.response)
            return response

        async with self._state_manager.transactionally(
            context, self.tasks_dispatcher
        ) as transaction:
            if transaction is not None:
                context.participants.add(
                    self._servicer.__state_type_name__, context._state_ref
                )
            async with self._state_manager.writer(
                context,
                self._servicer.__state_type__,
                self.tasks_dispatcher,
                authorize=self._maybe_authorize(
                    method_name='reboot.memoize.v1.MemoizeMethods.Reset',
                    headers=context._headers,
                    auth=context.auth,
                    request=request,
                ),
                transaction=transaction,
                from_constructor=False,
                requires_constructor=False,
            ) as (state, writer):

                effects = await self.__Reset(
                    context,
                    state,
                    request,
                    validating_effects=validating_effects,
                )

                await writer.complete(effects)

                # TODO: We need a single `Effects` superclass for all methods, so we
                # would need to make it "partially" generic (with per-method subclasses
                # filling out the rest of the generic parameters) in order to fix this.
                return effects.response  # type: ignore[return-value]

    async def _schedule_Reset(
        self,
        *,
        request: reboot.memoize.v1.memoize_pb2.ResetRequest,
        headers: reboot.aio.headers.Headers,
        grpc_context: grpc.aio.ServicerContext,
    ) -> tuple[reboot.aio.contexts.WriterContext, reboot.memoize.v1.memoize_pb2.ResetResponse]:
        context: reboot.aio.contexts.WriterContext = self.create_context(
            headers=headers,
            state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            context_type=reboot.aio.contexts.WriterContext,
        )
        response = reboot.memoize.v1.memoize_pb2.ResetResponse()

        # Check if we already have performed this mutation!
        #
        # We do this _before_ calling 'transactionally()' because
        # if this call is for a transaction method _and_ we've
        # already performed the transaction then we don't want to
        # become a transaction participant (again) we just want to
        # return the transaction's response.
        idempotent_mutation = self._state_manager.check_for_idempotent_mutation(
            context
        )

        if idempotent_mutation is not None:
            response.ParseFromString(idempotent_mutation.response)

            # We should have only scheduled a single task!
            assert len(idempotent_mutation.task_ids) == 1
            assert grpc_context is not None
            grpc_context.set_trailing_metadata(
                grpc_context.trailing_metadata() +
                (
                    (
                        reboot.aio.headers.TASK_ID_UUID,
                        str(uuid.UUID(bytes=idempotent_mutation.task_ids[0].task_uuid))
                    ),
                )
            )

            return context, response

        async with self._state_manager.transactionally(
            context, self.tasks_dispatcher
        ) as transaction:
            if transaction is not None:
                context.participants.add(
                    self._servicer.__state_type_name__, context._state_ref
                )

            # Try to verify the token if a token verifier exists.
            context.auth = await self._maybe_verify_token(headers)

            async with self._state_manager.writer(
                context,
                self._servicer.__state_type__,
                self.tasks_dispatcher,
                transaction=transaction,
                authorize=self._maybe_authorize(
                    method_name='reboot.memoize.v1.MemoizeMethods.Reset',
                    headers=context._headers,
                    auth=context.auth,
                    request=request,
                ),
                from_constructor=False,
                requires_constructor=False
            ) as (state, writer):

                task = MemoizeServicerTasksStub(
                    context=context,
                    state_ref=context._state_ref,
                ).Reset(
                    request,
                    schedule=context._headers.task_schedule,
                )

                effects = reboot.aio.state_managers.Effects(
                    response=response,
                    state=state,
                    tasks=[task],
                )

                assert effects.tasks is not None

                await writer.complete(effects)

                assert grpc_context is not None

                grpc_context.set_trailing_metadata(
                    grpc_context.trailing_metadata() +
                    (
                        (
                            reboot.aio.headers.TASK_ID_UUID,
                            str(uuid.UUID(bytes=task.task_id.task_uuid))
                        ),
                    )
                )

                return context, response

        return context, response


    # Entrypoint for non-reactive network calls (i.e. typical gRPC calls).
    async def Reset(
        self,
        request: reboot.memoize.v1.memoize_pb2.ResetRequest,
        grpc_context: grpc.aio.ServicerContext,
    ) -> reboot.memoize.v1.memoize_pb2.ResetResponse:
        headers = reboot.aio.headers.Headers.from_grpc_context(grpc_context)
        assert headers.application_id is not None  # Guaranteed by `Headers`.

        # Confirm whether this is the right consensus to be serving this
        # request.
        authoritative_consensus = self.placement_client.consensus_for_actor(
            headers.application_id,
            headers.state_ref,
        )
        if authoritative_consensus != self.consensus_id:
            # This is NOT the correct consensus. Fail.
            await grpc_context.abort(
                grpc.StatusCode.UNAVAILABLE,
                f"Consensus '{self.consensus_id}' is not authoritative for this "
                f"request; consensus '{authoritative_consensus}' is.",
            )
            raise  # Unreachable but necessary for mypy.

        @maybe_run_function_twice_to_validate_effects
        async def _run(
            validating_effects: bool,
        ) -> reboot.memoize.v1.memoize_pb2.ResetResponse:
            context: typing.Optional[reboot.aio.contexts.Context] = None
            try:
                if headers.task_schedule is not None:
                    context, response = await self._schedule_Reset(
                        headers=headers,
                        request=request,
                        grpc_context=grpc_context,
                    )
                    return response

                context = self.create_context(
                    headers=headers,
                    state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    context_type=reboot.aio.contexts.WriterContext,
                )
                assert context is not None

                return await self._Reset(
                    request,
                    context,
                    validating_effects=validating_effects,
                    grpc_context=grpc_context,
                )
            except reboot.aio.contexts.EffectValidationRetry:
                # Doing effect validation, just let this propagate.
                raise
            except reboot.aio.aborted.Aborted as aborted:
                await grpc_context.abort_with_status(
                    rpc_status_sync.to_status(aborted.to_status())
                )
                raise  # Unreachable but necessary for mypy.
            except asyncio.CancelledError:
                # It's pretty normal for an RPC to be cancelled; it's not useful to
                # print a stack trace.
                raise
            except BaseException as exception:
                # Print the exception stack trace for easier debugging. Note
                # that we don't include the stack trace in an error message
                # for the same reason that gRPC doesn't do so by default,
                # see https://github.com/grpc/grpc/issues/14897, but since this
                # should only get logged on the server side it is safe.
                logger.warning(
                    'Unhandled exception\n' +
                    ''.join(traceback.format_exc() if not NODEJS else [f"{type(exception).__name__}: {exception}"])
                )

                # Re-raise the exception for gRPC to handle!
                raise
            finally:
                if context is not None and context.transaction_id is not None:
                    # Propagate transaction participants.
                    grpc_context.set_trailing_metadata(
                        grpc_context.trailing_metadata() +
                        context.participants.to_grpc_metadata()
                    )

        return await _run()

    async def __Start(
        self,
        context: reboot.aio.contexts.WriterContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.StartRequest,
        *,
        validating_effects: bool,
    ) -> Memoize.StartEffects:
        try:
            response = (
                await self._servicer.Start(
                    context=context,
                    state=state,
                    request=request
                )
            )
            assert_type(
                response,
                [
                    reboot.memoize.v1.memoize_pb2.StartResponse,
                ],
            )
            # TODO: retrying a control loop might cause an effect
            # validation retry to either "hang" or "do more
            # work". It's not clear that this is always a bug, i.e.,
            # the intent of effect validation for a `workflow` method
            # is to ensure it can handle a failure and the developer
            # might have written the code to handle failures and still
            # run into the "hang" or "do more work" due to effect
            # validation. So for now, we don't bother doing effect
            # validation for loops since we'll be re-running it again.
            if not isinstance(response, reboot.aio.tasks.Loop):
                self.maybe_raise_effect_validation_retry(
                    logger=logger,
                    idempotency_manager=context,
                    method_name='Memoize.Start',
                    validating_effects=validating_effects,
                    context=context,
                )
            return Memoize.StartEffects(
                state=state,
                response=response,
                tasks=context._tasks,
                _colocated_upserts=context._colocated_upserts,
            )
        except reboot.aio.contexts.RetryReactively:
            # Retrying reactively, just let this propagate.
            raise
        except reboot.aio.contexts.EffectValidationRetry:
            # Doing effect validation, just let this propagate.
            raise
        except reboot.aio.aborted.Aborted as aborted:
            # Log any _unhandled_ abort stack traces to make it
            # easier for debugging.
            #
            # NOTE: we don't log if we're a task as it will be logged
            # in `reboot/aio/internals/tasks_dispatcher.py` instead.
            aborted_type: typing.Optional[type] = None
            aborted_type = Memoize.StartAborted
            if isinstance(aborted, reboot.aio.aborted.SystemAborted):
                # Not logging when within `node` as we already log there.
                if not NODEJS:
                    logger.warning(
                        f"Unhandled (in 'reboot.memoize.v1.Memoize.Start') {aborted}; propagating as 'Unknown'\n" +
                        ''.join(traceback.format_exception(aborted))
                    )
                raise reboot.aio.aborted.SystemAborted(
                    rbt.v1alpha1.errors_pb2.Unknown(),
                    # TODO(benh): consider whether or not we want to
                    # include the 'package.service.method' which may
                    # get concatenated together forming a kind of
                    # "stack trace"; while it's super helpful for
                    # debugging, it does expose implementation
                    # information.
                    message=f"unhandled (in 'reboot.memoize.v1.Memoize.Start') {aborted}"
                )
            else:
                if (
                    aborted_type is not None and
                    not isinstance(aborted, aborted_type) and
                    aborted_type.is_declared_error(aborted.error)
                ):
                    if context.task is None:
                        logger.warning(
                            f"Propagating unhandled (in 'reboot.memoize.v1.Memoize.Start') {aborted}"
                        )
                elif (
                    aborted_type is None or
                    not isinstance(aborted, aborted_type)
                ):
                    # Not logging when within `node` as we already log there.
                    if not NODEJS:
                        logger.warning(
                            f"Unhandled (in 'reboot.memoize.v1.Memoize.Start') {aborted}; propagating as 'Unknown'\n" +
                            ''.join(traceback.format_exception(aborted))
                        )
                    raise reboot.aio.aborted.SystemAborted(
                        rbt.v1alpha1.errors_pb2.Unknown(),
                        # TODO(benh): consider whether or not we want to
                        # include the 'package.service.method' which may
                        # get concatenated together forming a kind of
                        # "stack trace"; while it's super helpful for
                        # debugging, it does expose implementation
                        # information.
                        message=f"unhandled (in 'reboot.memoize.v1.Memoize.Start') {aborted}"
                    )

            raise
        except asyncio.CancelledError:
            # It's pretty normal for an RPC to be cancelled; it's not useful to
            # print a stack trace.
            raise
        except BaseException as exception:
            # Not logging when within `node` as we already log there.
            if not NODEJS:
                logger.warning(
                    f"Unhandled (in 'reboot.memoize.v1.Memoize.Start') {type(exception).__name__}: {exception}; propagating as 'Unknown'\n" +
                    ''.join(traceback.format_exception(exception))
                )
            raise reboot.aio.aborted.SystemAborted(
                rbt.v1alpha1.errors_pb2.Unknown(),
                # TODO(benh): consider whether or not we want to
                # include the 'package.service.method' which may
                # get concatenated together forming a kind of
                # "stack trace"; while it's super helpful for
                # debugging, it does expose implementation
                # information.
                message=f"unhandled (in 'reboot.memoize.v1.Memoize.Start') {type(exception).__name__}: {exception}"
            )

    @reboot.aio.tracing.function_span(
        # We expect an `EffectValidationRetry` exception; that's not an error.
        set_status_on_exception=False
    )
    async def _Start(
        self,
        request: reboot.memoize.v1.memoize_pb2.StartRequest,
        context: reboot.aio.contexts.WriterContext,
        *,
        validating_effects: bool,
        grpc_context: typing.Optional[grpc.aio.ServicerContext] = None,
    ) -> reboot.memoize.v1.memoize_pb2.StartResponse:
        # Try to verify the token if a token verifier exists.
        context.auth = await self._maybe_verify_token(context._headers)

        # Check if we already have performed this mutation!
        #
        # We do this _before_ calling 'transactionally()' because
        # if this call is for a transaction method _and_ we've
        # already performed the transaction then we don't want to
        # become a transaction participant (again) we just want to
        # return the transaction's response.
        idempotent_mutation = self._state_manager.check_for_idempotent_mutation(
            context
        )

        if idempotent_mutation is not None:
            response = reboot.memoize.v1.memoize_pb2.StartResponse()
            response.ParseFromString(idempotent_mutation.response)
            return response

        async with self._state_manager.transactionally(
            context, self.tasks_dispatcher
        ) as transaction:
            if transaction is not None:
                context.participants.add(
                    self._servicer.__state_type_name__, context._state_ref
                )
            async with self._state_manager.writer(
                context,
                self._servicer.__state_type__,
                self.tasks_dispatcher,
                authorize=self._maybe_authorize(
                    method_name='reboot.memoize.v1.MemoizeMethods.Start',
                    headers=context._headers,
                    auth=context.auth,
                    request=request,
                ),
                transaction=transaction,
                from_constructor=False,
                requires_constructor=False,
            ) as (state, writer):

                effects = await self.__Start(
                    context,
                    state,
                    request,
                    validating_effects=validating_effects,
                )

                await writer.complete(effects)

                # TODO: We need a single `Effects` superclass for all methods, so we
                # would need to make it "partially" generic (with per-method subclasses
                # filling out the rest of the generic parameters) in order to fix this.
                return effects.response  # type: ignore[return-value]

    async def _schedule_Start(
        self,
        *,
        request: reboot.memoize.v1.memoize_pb2.StartRequest,
        headers: reboot.aio.headers.Headers,
        grpc_context: grpc.aio.ServicerContext,
    ) -> tuple[reboot.aio.contexts.WriterContext, reboot.memoize.v1.memoize_pb2.StartResponse]:
        context: reboot.aio.contexts.WriterContext = self.create_context(
            headers=headers,
            state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            context_type=reboot.aio.contexts.WriterContext,
        )
        response = reboot.memoize.v1.memoize_pb2.StartResponse()

        # Check if we already have performed this mutation!
        #
        # We do this _before_ calling 'transactionally()' because
        # if this call is for a transaction method _and_ we've
        # already performed the transaction then we don't want to
        # become a transaction participant (again) we just want to
        # return the transaction's response.
        idempotent_mutation = self._state_manager.check_for_idempotent_mutation(
            context
        )

        if idempotent_mutation is not None:
            response.ParseFromString(idempotent_mutation.response)

            # We should have only scheduled a single task!
            assert len(idempotent_mutation.task_ids) == 1
            assert grpc_context is not None
            grpc_context.set_trailing_metadata(
                grpc_context.trailing_metadata() +
                (
                    (
                        reboot.aio.headers.TASK_ID_UUID,
                        str(uuid.UUID(bytes=idempotent_mutation.task_ids[0].task_uuid))
                    ),
                )
            )

            return context, response

        async with self._state_manager.transactionally(
            context, self.tasks_dispatcher
        ) as transaction:
            if transaction is not None:
                context.participants.add(
                    self._servicer.__state_type_name__, context._state_ref
                )

            # Try to verify the token if a token verifier exists.
            context.auth = await self._maybe_verify_token(headers)

            async with self._state_manager.writer(
                context,
                self._servicer.__state_type__,
                self.tasks_dispatcher,
                transaction=transaction,
                authorize=self._maybe_authorize(
                    method_name='reboot.memoize.v1.MemoizeMethods.Start',
                    headers=context._headers,
                    auth=context.auth,
                    request=request,
                ),
                from_constructor=False,
                requires_constructor=False
            ) as (state, writer):

                task = MemoizeServicerTasksStub(
                    context=context,
                    state_ref=context._state_ref,
                ).Start(
                    request,
                    schedule=context._headers.task_schedule,
                )

                effects = reboot.aio.state_managers.Effects(
                    response=response,
                    state=state,
                    tasks=[task],
                )

                assert effects.tasks is not None

                await writer.complete(effects)

                assert grpc_context is not None

                grpc_context.set_trailing_metadata(
                    grpc_context.trailing_metadata() +
                    (
                        (
                            reboot.aio.headers.TASK_ID_UUID,
                            str(uuid.UUID(bytes=task.task_id.task_uuid))
                        ),
                    )
                )

                return context, response

        return context, response


    # Entrypoint for non-reactive network calls (i.e. typical gRPC calls).
    async def Start(
        self,
        request: reboot.memoize.v1.memoize_pb2.StartRequest,
        grpc_context: grpc.aio.ServicerContext,
    ) -> reboot.memoize.v1.memoize_pb2.StartResponse:
        headers = reboot.aio.headers.Headers.from_grpc_context(grpc_context)
        assert headers.application_id is not None  # Guaranteed by `Headers`.

        # Confirm whether this is the right consensus to be serving this
        # request.
        authoritative_consensus = self.placement_client.consensus_for_actor(
            headers.application_id,
            headers.state_ref,
        )
        if authoritative_consensus != self.consensus_id:
            # This is NOT the correct consensus. Fail.
            await grpc_context.abort(
                grpc.StatusCode.UNAVAILABLE,
                f"Consensus '{self.consensus_id}' is not authoritative for this "
                f"request; consensus '{authoritative_consensus}' is.",
            )
            raise  # Unreachable but necessary for mypy.

        @maybe_run_function_twice_to_validate_effects
        async def _run(
            validating_effects: bool,
        ) -> reboot.memoize.v1.memoize_pb2.StartResponse:
            context: typing.Optional[reboot.aio.contexts.Context] = None
            try:
                if headers.task_schedule is not None:
                    context, response = await self._schedule_Start(
                        headers=headers,
                        request=request,
                        grpc_context=grpc_context,
                    )
                    return response

                context = self.create_context(
                    headers=headers,
                    state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    context_type=reboot.aio.contexts.WriterContext,
                )
                assert context is not None

                return await self._Start(
                    request,
                    context,
                    validating_effects=validating_effects,
                    grpc_context=grpc_context,
                )
            except reboot.aio.contexts.EffectValidationRetry:
                # Doing effect validation, just let this propagate.
                raise
            except reboot.aio.aborted.Aborted as aborted:
                await grpc_context.abort_with_status(
                    rpc_status_sync.to_status(aborted.to_status())
                )
                raise  # Unreachable but necessary for mypy.
            except asyncio.CancelledError:
                # It's pretty normal for an RPC to be cancelled; it's not useful to
                # print a stack trace.
                raise
            except BaseException as exception:
                # Print the exception stack trace for easier debugging. Note
                # that we don't include the stack trace in an error message
                # for the same reason that gRPC doesn't do so by default,
                # see https://github.com/grpc/grpc/issues/14897, but since this
                # should only get logged on the server side it is safe.
                logger.warning(
                    'Unhandled exception\n' +
                    ''.join(traceback.format_exc() if not NODEJS else [f"{type(exception).__name__}: {exception}"])
                )

                # Re-raise the exception for gRPC to handle!
                raise
            finally:
                if context is not None and context.transaction_id is not None:
                    # Propagate transaction participants.
                    grpc_context.set_trailing_metadata(
                        grpc_context.trailing_metadata() +
                        context.participants.to_grpc_metadata()
                    )

        return await _run()

    async def __Store(
        self,
        context: reboot.aio.contexts.WriterContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.StoreRequest,
        *,
        validating_effects: bool,
    ) -> Memoize.StoreEffects:
        try:
            response = (
                await self._servicer.Store(
                    context=context,
                    state=state,
                    request=request
                )
            )
            assert_type(
                response,
                [
                    reboot.memoize.v1.memoize_pb2.StoreResponse,
                ],
            )
            # TODO: retrying a control loop might cause an effect
            # validation retry to either "hang" or "do more
            # work". It's not clear that this is always a bug, i.e.,
            # the intent of effect validation for a `workflow` method
            # is to ensure it can handle a failure and the developer
            # might have written the code to handle failures and still
            # run into the "hang" or "do more work" due to effect
            # validation. So for now, we don't bother doing effect
            # validation for loops since we'll be re-running it again.
            if not isinstance(response, reboot.aio.tasks.Loop):
                self.maybe_raise_effect_validation_retry(
                    logger=logger,
                    idempotency_manager=context,
                    method_name='Memoize.Store',
                    validating_effects=validating_effects,
                    context=context,
                )
            return Memoize.StoreEffects(
                state=state,
                response=response,
                tasks=context._tasks,
                _colocated_upserts=context._colocated_upserts,
            )
        except reboot.aio.contexts.RetryReactively:
            # Retrying reactively, just let this propagate.
            raise
        except reboot.aio.contexts.EffectValidationRetry:
            # Doing effect validation, just let this propagate.
            raise
        except reboot.aio.aborted.Aborted as aborted:
            # Log any _unhandled_ abort stack traces to make it
            # easier for debugging.
            #
            # NOTE: we don't log if we're a task as it will be logged
            # in `reboot/aio/internals/tasks_dispatcher.py` instead.
            aborted_type: typing.Optional[type] = None
            aborted_type = Memoize.StoreAborted
            if isinstance(aborted, reboot.aio.aborted.SystemAborted):
                # Not logging when within `node` as we already log there.
                if not NODEJS:
                    logger.warning(
                        f"Unhandled (in 'reboot.memoize.v1.Memoize.Store') {aborted}; propagating as 'Unknown'\n" +
                        ''.join(traceback.format_exception(aborted))
                    )
                raise reboot.aio.aborted.SystemAborted(
                    rbt.v1alpha1.errors_pb2.Unknown(),
                    # TODO(benh): consider whether or not we want to
                    # include the 'package.service.method' which may
                    # get concatenated together forming a kind of
                    # "stack trace"; while it's super helpful for
                    # debugging, it does expose implementation
                    # information.
                    message=f"unhandled (in 'reboot.memoize.v1.Memoize.Store') {aborted}"
                )
            else:
                if (
                    aborted_type is not None and
                    not isinstance(aborted, aborted_type) and
                    aborted_type.is_declared_error(aborted.error)
                ):
                    if context.task is None:
                        logger.warning(
                            f"Propagating unhandled (in 'reboot.memoize.v1.Memoize.Store') {aborted}"
                        )
                elif (
                    aborted_type is None or
                    not isinstance(aborted, aborted_type)
                ):
                    # Not logging when within `node` as we already log there.
                    if not NODEJS:
                        logger.warning(
                            f"Unhandled (in 'reboot.memoize.v1.Memoize.Store') {aborted}; propagating as 'Unknown'\n" +
                            ''.join(traceback.format_exception(aborted))
                        )
                    raise reboot.aio.aborted.SystemAborted(
                        rbt.v1alpha1.errors_pb2.Unknown(),
                        # TODO(benh): consider whether or not we want to
                        # include the 'package.service.method' which may
                        # get concatenated together forming a kind of
                        # "stack trace"; while it's super helpful for
                        # debugging, it does expose implementation
                        # information.
                        message=f"unhandled (in 'reboot.memoize.v1.Memoize.Store') {aborted}"
                    )

            raise
        except asyncio.CancelledError:
            # It's pretty normal for an RPC to be cancelled; it's not useful to
            # print a stack trace.
            raise
        except BaseException as exception:
            # Not logging when within `node` as we already log there.
            if not NODEJS:
                logger.warning(
                    f"Unhandled (in 'reboot.memoize.v1.Memoize.Store') {type(exception).__name__}: {exception}; propagating as 'Unknown'\n" +
                    ''.join(traceback.format_exception(exception))
                )
            raise reboot.aio.aborted.SystemAborted(
                rbt.v1alpha1.errors_pb2.Unknown(),
                # TODO(benh): consider whether or not we want to
                # include the 'package.service.method' which may
                # get concatenated together forming a kind of
                # "stack trace"; while it's super helpful for
                # debugging, it does expose implementation
                # information.
                message=f"unhandled (in 'reboot.memoize.v1.Memoize.Store') {type(exception).__name__}: {exception}"
            )

    @reboot.aio.tracing.function_span(
        # We expect an `EffectValidationRetry` exception; that's not an error.
        set_status_on_exception=False
    )
    async def _Store(
        self,
        request: reboot.memoize.v1.memoize_pb2.StoreRequest,
        context: reboot.aio.contexts.WriterContext,
        *,
        validating_effects: bool,
        grpc_context: typing.Optional[grpc.aio.ServicerContext] = None,
    ) -> reboot.memoize.v1.memoize_pb2.StoreResponse:
        # Try to verify the token if a token verifier exists.
        context.auth = await self._maybe_verify_token(context._headers)

        # Check if we already have performed this mutation!
        #
        # We do this _before_ calling 'transactionally()' because
        # if this call is for a transaction method _and_ we've
        # already performed the transaction then we don't want to
        # become a transaction participant (again) we just want to
        # return the transaction's response.
        idempotent_mutation = self._state_manager.check_for_idempotent_mutation(
            context
        )

        if idempotent_mutation is not None:
            response = reboot.memoize.v1.memoize_pb2.StoreResponse()
            response.ParseFromString(idempotent_mutation.response)
            return response

        async with self._state_manager.transactionally(
            context, self.tasks_dispatcher
        ) as transaction:
            if transaction is not None:
                context.participants.add(
                    self._servicer.__state_type_name__, context._state_ref
                )
            async with self._state_manager.writer(
                context,
                self._servicer.__state_type__,
                self.tasks_dispatcher,
                authorize=self._maybe_authorize(
                    method_name='reboot.memoize.v1.MemoizeMethods.Store',
                    headers=context._headers,
                    auth=context.auth,
                    request=request,
                ),
                transaction=transaction,
                from_constructor=False,
                requires_constructor=False,
            ) as (state, writer):

                effects = await self.__Store(
                    context,
                    state,
                    request,
                    validating_effects=validating_effects,
                )

                await writer.complete(effects)

                # TODO: We need a single `Effects` superclass for all methods, so we
                # would need to make it "partially" generic (with per-method subclasses
                # filling out the rest of the generic parameters) in order to fix this.
                return effects.response  # type: ignore[return-value]

    async def _schedule_Store(
        self,
        *,
        request: reboot.memoize.v1.memoize_pb2.StoreRequest,
        headers: reboot.aio.headers.Headers,
        grpc_context: grpc.aio.ServicerContext,
    ) -> tuple[reboot.aio.contexts.WriterContext, reboot.memoize.v1.memoize_pb2.StoreResponse]:
        context: reboot.aio.contexts.WriterContext = self.create_context(
            headers=headers,
            state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            context_type=reboot.aio.contexts.WriterContext,
        )
        response = reboot.memoize.v1.memoize_pb2.StoreResponse()

        # Check if we already have performed this mutation!
        #
        # We do this _before_ calling 'transactionally()' because
        # if this call is for a transaction method _and_ we've
        # already performed the transaction then we don't want to
        # become a transaction participant (again) we just want to
        # return the transaction's response.
        idempotent_mutation = self._state_manager.check_for_idempotent_mutation(
            context
        )

        if idempotent_mutation is not None:
            response.ParseFromString(idempotent_mutation.response)

            # We should have only scheduled a single task!
            assert len(idempotent_mutation.task_ids) == 1
            assert grpc_context is not None
            grpc_context.set_trailing_metadata(
                grpc_context.trailing_metadata() +
                (
                    (
                        reboot.aio.headers.TASK_ID_UUID,
                        str(uuid.UUID(bytes=idempotent_mutation.task_ids[0].task_uuid))
                    ),
                )
            )

            return context, response

        async with self._state_manager.transactionally(
            context, self.tasks_dispatcher
        ) as transaction:
            if transaction is not None:
                context.participants.add(
                    self._servicer.__state_type_name__, context._state_ref
                )

            # Try to verify the token if a token verifier exists.
            context.auth = await self._maybe_verify_token(headers)

            async with self._state_manager.writer(
                context,
                self._servicer.__state_type__,
                self.tasks_dispatcher,
                transaction=transaction,
                authorize=self._maybe_authorize(
                    method_name='reboot.memoize.v1.MemoizeMethods.Store',
                    headers=context._headers,
                    auth=context.auth,
                    request=request,
                ),
                from_constructor=False,
                requires_constructor=False
            ) as (state, writer):

                task = MemoizeServicerTasksStub(
                    context=context,
                    state_ref=context._state_ref,
                ).Store(
                    request,
                    schedule=context._headers.task_schedule,
                )

                effects = reboot.aio.state_managers.Effects(
                    response=response,
                    state=state,
                    tasks=[task],
                )

                assert effects.tasks is not None

                await writer.complete(effects)

                assert grpc_context is not None

                grpc_context.set_trailing_metadata(
                    grpc_context.trailing_metadata() +
                    (
                        (
                            reboot.aio.headers.TASK_ID_UUID,
                            str(uuid.UUID(bytes=task.task_id.task_uuid))
                        ),
                    )
                )

                return context, response

        return context, response


    # Entrypoint for non-reactive network calls (i.e. typical gRPC calls).
    async def Store(
        self,
        request: reboot.memoize.v1.memoize_pb2.StoreRequest,
        grpc_context: grpc.aio.ServicerContext,
    ) -> reboot.memoize.v1.memoize_pb2.StoreResponse:
        headers = reboot.aio.headers.Headers.from_grpc_context(grpc_context)
        assert headers.application_id is not None  # Guaranteed by `Headers`.

        # Confirm whether this is the right consensus to be serving this
        # request.
        authoritative_consensus = self.placement_client.consensus_for_actor(
            headers.application_id,
            headers.state_ref,
        )
        if authoritative_consensus != self.consensus_id:
            # This is NOT the correct consensus. Fail.
            await grpc_context.abort(
                grpc.StatusCode.UNAVAILABLE,
                f"Consensus '{self.consensus_id}' is not authoritative for this "
                f"request; consensus '{authoritative_consensus}' is.",
            )
            raise  # Unreachable but necessary for mypy.

        @maybe_run_function_twice_to_validate_effects
        async def _run(
            validating_effects: bool,
        ) -> reboot.memoize.v1.memoize_pb2.StoreResponse:
            context: typing.Optional[reboot.aio.contexts.Context] = None
            try:
                if headers.task_schedule is not None:
                    context, response = await self._schedule_Store(
                        headers=headers,
                        request=request,
                        grpc_context=grpc_context,
                    )
                    return response

                context = self.create_context(
                    headers=headers,
                    state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    context_type=reboot.aio.contexts.WriterContext,
                )
                assert context is not None

                return await self._Store(
                    request,
                    context,
                    validating_effects=validating_effects,
                    grpc_context=grpc_context,
                )
            except reboot.aio.contexts.EffectValidationRetry:
                # Doing effect validation, just let this propagate.
                raise
            except reboot.aio.aborted.Aborted as aborted:
                await grpc_context.abort_with_status(
                    rpc_status_sync.to_status(aborted.to_status())
                )
                raise  # Unreachable but necessary for mypy.
            except asyncio.CancelledError:
                # It's pretty normal for an RPC to be cancelled; it's not useful to
                # print a stack trace.
                raise
            except BaseException as exception:
                # Print the exception stack trace for easier debugging. Note
                # that we don't include the stack trace in an error message
                # for the same reason that gRPC doesn't do so by default,
                # see https://github.com/grpc/grpc/issues/14897, but since this
                # should only get logged on the server side it is safe.
                logger.warning(
                    'Unhandled exception\n' +
                    ''.join(traceback.format_exc() if not NODEJS else [f"{type(exception).__name__}: {exception}"])
                )

                # Re-raise the exception for gRPC to handle!
                raise
            finally:
                if context is not None and context.transaction_id is not None:
                    # Propagate transaction participants.
                    grpc_context.set_trailing_metadata(
                        grpc_context.trailing_metadata() +
                        context.participants.to_grpc_metadata()
                    )

        return await _run()

    async def __Fail(
        self,
        context: reboot.aio.contexts.WriterContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.FailRequest,
        *,
        validating_effects: bool,
    ) -> Memoize.FailEffects:
        try:
            response = (
                await self._servicer.Fail(
                    context=context,
                    state=state,
                    request=request
                )
            )
            assert_type(
                response,
                [
                    reboot.memoize.v1.memoize_pb2.FailResponse,
                ],
            )
            # TODO: retrying a control loop might cause an effect
            # validation retry to either "hang" or "do more
            # work". It's not clear that this is always a bug, i.e.,
            # the intent of effect validation for a `workflow` method
            # is to ensure it can handle a failure and the developer
            # might have written the code to handle failures and still
            # run into the "hang" or "do more work" due to effect
            # validation. So for now, we don't bother doing effect
            # validation for loops since we'll be re-running it again.
            if not isinstance(response, reboot.aio.tasks.Loop):
                self.maybe_raise_effect_validation_retry(
                    logger=logger,
                    idempotency_manager=context,
                    method_name='Memoize.Fail',
                    validating_effects=validating_effects,
                    context=context,
                )
            return Memoize.FailEffects(
                state=state,
                response=response,
                tasks=context._tasks,
                _colocated_upserts=context._colocated_upserts,
            )
        except reboot.aio.contexts.RetryReactively:
            # Retrying reactively, just let this propagate.
            raise
        except reboot.aio.contexts.EffectValidationRetry:
            # Doing effect validation, just let this propagate.
            raise
        except reboot.aio.aborted.Aborted as aborted:
            # Log any _unhandled_ abort stack traces to make it
            # easier for debugging.
            #
            # NOTE: we don't log if we're a task as it will be logged
            # in `reboot/aio/internals/tasks_dispatcher.py` instead.
            aborted_type: typing.Optional[type] = None
            aborted_type = Memoize.FailAborted
            if isinstance(aborted, reboot.aio.aborted.SystemAborted):
                # Not logging when within `node` as we already log there.
                if not NODEJS:
                    logger.warning(
                        f"Unhandled (in 'reboot.memoize.v1.Memoize.Fail') {aborted}; propagating as 'Unknown'\n" +
                        ''.join(traceback.format_exception(aborted))
                    )
                raise reboot.aio.aborted.SystemAborted(
                    rbt.v1alpha1.errors_pb2.Unknown(),
                    # TODO(benh): consider whether or not we want to
                    # include the 'package.service.method' which may
                    # get concatenated together forming a kind of
                    # "stack trace"; while it's super helpful for
                    # debugging, it does expose implementation
                    # information.
                    message=f"unhandled (in 'reboot.memoize.v1.Memoize.Fail') {aborted}"
                )
            else:
                if (
                    aborted_type is not None and
                    not isinstance(aborted, aborted_type) and
                    aborted_type.is_declared_error(aborted.error)
                ):
                    if context.task is None:
                        logger.warning(
                            f"Propagating unhandled (in 'reboot.memoize.v1.Memoize.Fail') {aborted}"
                        )
                elif (
                    aborted_type is None or
                    not isinstance(aborted, aborted_type)
                ):
                    # Not logging when within `node` as we already log there.
                    if not NODEJS:
                        logger.warning(
                            f"Unhandled (in 'reboot.memoize.v1.Memoize.Fail') {aborted}; propagating as 'Unknown'\n" +
                            ''.join(traceback.format_exception(aborted))
                        )
                    raise reboot.aio.aborted.SystemAborted(
                        rbt.v1alpha1.errors_pb2.Unknown(),
                        # TODO(benh): consider whether or not we want to
                        # include the 'package.service.method' which may
                        # get concatenated together forming a kind of
                        # "stack trace"; while it's super helpful for
                        # debugging, it does expose implementation
                        # information.
                        message=f"unhandled (in 'reboot.memoize.v1.Memoize.Fail') {aborted}"
                    )

            raise
        except asyncio.CancelledError:
            # It's pretty normal for an RPC to be cancelled; it's not useful to
            # print a stack trace.
            raise
        except BaseException as exception:
            # Not logging when within `node` as we already log there.
            if not NODEJS:
                logger.warning(
                    f"Unhandled (in 'reboot.memoize.v1.Memoize.Fail') {type(exception).__name__}: {exception}; propagating as 'Unknown'\n" +
                    ''.join(traceback.format_exception(exception))
                )
            raise reboot.aio.aborted.SystemAborted(
                rbt.v1alpha1.errors_pb2.Unknown(),
                # TODO(benh): consider whether or not we want to
                # include the 'package.service.method' which may
                # get concatenated together forming a kind of
                # "stack trace"; while it's super helpful for
                # debugging, it does expose implementation
                # information.
                message=f"unhandled (in 'reboot.memoize.v1.Memoize.Fail') {type(exception).__name__}: {exception}"
            )

    @reboot.aio.tracing.function_span(
        # We expect an `EffectValidationRetry` exception; that's not an error.
        set_status_on_exception=False
    )
    async def _Fail(
        self,
        request: reboot.memoize.v1.memoize_pb2.FailRequest,
        context: reboot.aio.contexts.WriterContext,
        *,
        validating_effects: bool,
        grpc_context: typing.Optional[grpc.aio.ServicerContext] = None,
    ) -> reboot.memoize.v1.memoize_pb2.FailResponse:
        # Try to verify the token if a token verifier exists.
        context.auth = await self._maybe_verify_token(context._headers)

        # Check if we already have performed this mutation!
        #
        # We do this _before_ calling 'transactionally()' because
        # if this call is for a transaction method _and_ we've
        # already performed the transaction then we don't want to
        # become a transaction participant (again) we just want to
        # return the transaction's response.
        idempotent_mutation = self._state_manager.check_for_idempotent_mutation(
            context
        )

        if idempotent_mutation is not None:
            response = reboot.memoize.v1.memoize_pb2.FailResponse()
            response.ParseFromString(idempotent_mutation.response)
            return response

        async with self._state_manager.transactionally(
            context, self.tasks_dispatcher
        ) as transaction:
            if transaction is not None:
                context.participants.add(
                    self._servicer.__state_type_name__, context._state_ref
                )
            async with self._state_manager.writer(
                context,
                self._servicer.__state_type__,
                self.tasks_dispatcher,
                authorize=self._maybe_authorize(
                    method_name='reboot.memoize.v1.MemoizeMethods.Fail',
                    headers=context._headers,
                    auth=context.auth,
                    request=request,
                ),
                transaction=transaction,
                from_constructor=False,
                requires_constructor=False,
            ) as (state, writer):

                effects = await self.__Fail(
                    context,
                    state,
                    request,
                    validating_effects=validating_effects,
                )

                await writer.complete(effects)

                # TODO: We need a single `Effects` superclass for all methods, so we
                # would need to make it "partially" generic (with per-method subclasses
                # filling out the rest of the generic parameters) in order to fix this.
                return effects.response  # type: ignore[return-value]

    async def _schedule_Fail(
        self,
        *,
        request: reboot.memoize.v1.memoize_pb2.FailRequest,
        headers: reboot.aio.headers.Headers,
        grpc_context: grpc.aio.ServicerContext,
    ) -> tuple[reboot.aio.contexts.WriterContext, reboot.memoize.v1.memoize_pb2.FailResponse]:
        context: reboot.aio.contexts.WriterContext = self.create_context(
            headers=headers,
            state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            context_type=reboot.aio.contexts.WriterContext,
        )
        response = reboot.memoize.v1.memoize_pb2.FailResponse()

        # Check if we already have performed this mutation!
        #
        # We do this _before_ calling 'transactionally()' because
        # if this call is for a transaction method _and_ we've
        # already performed the transaction then we don't want to
        # become a transaction participant (again) we just want to
        # return the transaction's response.
        idempotent_mutation = self._state_manager.check_for_idempotent_mutation(
            context
        )

        if idempotent_mutation is not None:
            response.ParseFromString(idempotent_mutation.response)

            # We should have only scheduled a single task!
            assert len(idempotent_mutation.task_ids) == 1
            assert grpc_context is not None
            grpc_context.set_trailing_metadata(
                grpc_context.trailing_metadata() +
                (
                    (
                        reboot.aio.headers.TASK_ID_UUID,
                        str(uuid.UUID(bytes=idempotent_mutation.task_ids[0].task_uuid))
                    ),
                )
            )

            return context, response

        async with self._state_manager.transactionally(
            context, self.tasks_dispatcher
        ) as transaction:
            if transaction is not None:
                context.participants.add(
                    self._servicer.__state_type_name__, context._state_ref
                )

            # Try to verify the token if a token verifier exists.
            context.auth = await self._maybe_verify_token(headers)

            async with self._state_manager.writer(
                context,
                self._servicer.__state_type__,
                self.tasks_dispatcher,
                transaction=transaction,
                authorize=self._maybe_authorize(
                    method_name='reboot.memoize.v1.MemoizeMethods.Fail',
                    headers=context._headers,
                    auth=context.auth,
                    request=request,
                ),
                from_constructor=False,
                requires_constructor=False
            ) as (state, writer):

                task = MemoizeServicerTasksStub(
                    context=context,
                    state_ref=context._state_ref,
                ).Fail(
                    request,
                    schedule=context._headers.task_schedule,
                )

                effects = reboot.aio.state_managers.Effects(
                    response=response,
                    state=state,
                    tasks=[task],
                )

                assert effects.tasks is not None

                await writer.complete(effects)

                assert grpc_context is not None

                grpc_context.set_trailing_metadata(
                    grpc_context.trailing_metadata() +
                    (
                        (
                            reboot.aio.headers.TASK_ID_UUID,
                            str(uuid.UUID(bytes=task.task_id.task_uuid))
                        ),
                    )
                )

                return context, response

        return context, response


    # Entrypoint for non-reactive network calls (i.e. typical gRPC calls).
    async def Fail(
        self,
        request: reboot.memoize.v1.memoize_pb2.FailRequest,
        grpc_context: grpc.aio.ServicerContext,
    ) -> reboot.memoize.v1.memoize_pb2.FailResponse:
        headers = reboot.aio.headers.Headers.from_grpc_context(grpc_context)
        assert headers.application_id is not None  # Guaranteed by `Headers`.

        # Confirm whether this is the right consensus to be serving this
        # request.
        authoritative_consensus = self.placement_client.consensus_for_actor(
            headers.application_id,
            headers.state_ref,
        )
        if authoritative_consensus != self.consensus_id:
            # This is NOT the correct consensus. Fail.
            await grpc_context.abort(
                grpc.StatusCode.UNAVAILABLE,
                f"Consensus '{self.consensus_id}' is not authoritative for this "
                f"request; consensus '{authoritative_consensus}' is.",
            )
            raise  # Unreachable but necessary for mypy.

        @maybe_run_function_twice_to_validate_effects
        async def _run(
            validating_effects: bool,
        ) -> reboot.memoize.v1.memoize_pb2.FailResponse:
            context: typing.Optional[reboot.aio.contexts.Context] = None
            try:
                if headers.task_schedule is not None:
                    context, response = await self._schedule_Fail(
                        headers=headers,
                        request=request,
                        grpc_context=grpc_context,
                    )
                    return response

                context = self.create_context(
                    headers=headers,
                    state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    context_type=reboot.aio.contexts.WriterContext,
                )
                assert context is not None

                return await self._Fail(
                    request,
                    context,
                    validating_effects=validating_effects,
                    grpc_context=grpc_context,
                )
            except reboot.aio.contexts.EffectValidationRetry:
                # Doing effect validation, just let this propagate.
                raise
            except reboot.aio.aborted.Aborted as aborted:
                await grpc_context.abort_with_status(
                    rpc_status_sync.to_status(aborted.to_status())
                )
                raise  # Unreachable but necessary for mypy.
            except asyncio.CancelledError:
                # It's pretty normal for an RPC to be cancelled; it's not useful to
                # print a stack trace.
                raise
            except BaseException as exception:
                # Print the exception stack trace for easier debugging. Note
                # that we don't include the stack trace in an error message
                # for the same reason that gRPC doesn't do so by default,
                # see https://github.com/grpc/grpc/issues/14897, but since this
                # should only get logged on the server side it is safe.
                logger.warning(
                    'Unhandled exception\n' +
                    ''.join(traceback.format_exc() if not NODEJS else [f"{type(exception).__name__}: {exception}"])
                )

                # Re-raise the exception for gRPC to handle!
                raise
            finally:
                if context is not None and context.transaction_id is not None:
                    # Propagate transaction participants.
                    grpc_context.set_trailing_metadata(
                        grpc_context.trailing_metadata() +
                        context.participants.to_grpc_metadata()
                    )

        return await _run()

    async def __Status(
        self,
        context: reboot.aio.contexts.ReaderContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.StatusRequest,
        *,
        validating_effects: bool,
    ) -> reboot.memoize.v1.memoize_pb2.StatusResponse:
        try:
            response = (
                await self._servicer.Status(
                    context=context,
                    state=state,
                    request=request
                )
            )
            assert_type(
                response,
                [
                    reboot.memoize.v1.memoize_pb2.StatusResponse,
                ],
            )
            # TODO: retrying a control loop might cause an effect
            # validation retry to either "hang" or "do more
            # work". It's not clear that this is always a bug, i.e.,
            # the intent of effect validation for a `workflow` method
            # is to ensure it can handle a failure and the developer
            # might have written the code to handle failures and still
            # run into the "hang" or "do more work" due to effect
            # validation. So for now, we don't bother doing effect
            # validation for loops since we'll be re-running it again.
            if not isinstance(response, reboot.aio.tasks.Loop):
                self.maybe_raise_effect_validation_retry(
                    logger=logger,
                    idempotency_manager=context,
                    method_name='Memoize.Status',
                    validating_effects=validating_effects,
                    context=context,
                )
            return response
        except reboot.aio.contexts.RetryReactively:
            # Retrying reactively, just let this propagate.
            raise
        except reboot.aio.contexts.EffectValidationRetry:
            # Doing effect validation, just let this propagate.
            raise
        except reboot.aio.aborted.Aborted as aborted:
            # Log any _unhandled_ abort stack traces to make it
            # easier for debugging.
            #
            # NOTE: we don't log if we're a task as it will be logged
            # in `reboot/aio/internals/tasks_dispatcher.py` instead.
            aborted_type: typing.Optional[type] = None
            aborted_type = Memoize.StatusAborted
            if isinstance(aborted, reboot.aio.aborted.SystemAborted):
                # Not logging when within `node` as we already log there.
                if not NODEJS:
                    logger.warning(
                        f"Unhandled (in 'reboot.memoize.v1.Memoize.Status') {aborted}; propagating as 'Unknown'\n" +
                        ''.join(traceback.format_exception(aborted))
                    )
                raise reboot.aio.aborted.SystemAborted(
                    rbt.v1alpha1.errors_pb2.Unknown(),
                    # TODO(benh): consider whether or not we want to
                    # include the 'package.service.method' which may
                    # get concatenated together forming a kind of
                    # "stack trace"; while it's super helpful for
                    # debugging, it does expose implementation
                    # information.
                    message=f"unhandled (in 'reboot.memoize.v1.Memoize.Status') {aborted}"
                )
            else:
                if (
                    aborted_type is not None and
                    not isinstance(aborted, aborted_type) and
                    aborted_type.is_declared_error(aborted.error)
                ):
                    if context.task is None:
                        logger.warning(
                            f"Propagating unhandled (in 'reboot.memoize.v1.Memoize.Status') {aborted}"
                        )
                elif (
                    aborted_type is None or
                    not isinstance(aborted, aborted_type)
                ):
                    # Not logging when within `node` as we already log there.
                    if not NODEJS:
                        logger.warning(
                            f"Unhandled (in 'reboot.memoize.v1.Memoize.Status') {aborted}; propagating as 'Unknown'\n" +
                            ''.join(traceback.format_exception(aborted))
                        )
                    raise reboot.aio.aborted.SystemAborted(
                        rbt.v1alpha1.errors_pb2.Unknown(),
                        # TODO(benh): consider whether or not we want to
                        # include the 'package.service.method' which may
                        # get concatenated together forming a kind of
                        # "stack trace"; while it's super helpful for
                        # debugging, it does expose implementation
                        # information.
                        message=f"unhandled (in 'reboot.memoize.v1.Memoize.Status') {aborted}"
                    )

            raise
        except asyncio.CancelledError:
            # It's pretty normal for an RPC to be cancelled; it's not useful to
            # print a stack trace.
            raise
        except BaseException as exception:
            # Not logging when within `node` as we already log there.
            if not NODEJS:
                logger.warning(
                    f"Unhandled (in 'reboot.memoize.v1.Memoize.Status') {type(exception).__name__}: {exception}; propagating as 'Unknown'\n" +
                    ''.join(traceback.format_exception(exception))
                )
            raise reboot.aio.aborted.SystemAborted(
                rbt.v1alpha1.errors_pb2.Unknown(),
                # TODO(benh): consider whether or not we want to
                # include the 'package.service.method' which may
                # get concatenated together forming a kind of
                # "stack trace"; while it's super helpful for
                # debugging, it does expose implementation
                # information.
                message=f"unhandled (in 'reboot.memoize.v1.Memoize.Status') {type(exception).__name__}: {exception}"
            )

    @reboot.aio.tracing.function_span(
        # We expect an `EffectValidationRetry` exception; that's not an error.
        set_status_on_exception=False
    )
    async def _Status(
        self,
        request: reboot.memoize.v1.memoize_pb2.StatusRequest,
        context: reboot.aio.contexts.ReaderContext,
        *,
        validating_effects: bool,
        grpc_context: typing.Optional[grpc.aio.ServicerContext] = None,
    ) -> reboot.memoize.v1.memoize_pb2.StatusResponse:
        # Try to verify the token if a token verifier exists.
        context.auth = await self._maybe_verify_token(context._headers)


        async with self._state_manager.transactionally(
            context, self.tasks_dispatcher
        ) as transaction:
            if transaction is not None:
                context.participants.add(
                    self._servicer.__state_type_name__, context._state_ref
                )
            authorizer = self._maybe_authorize(
                method_name='reboot.memoize.v1.MemoizeMethods.Status',
                headers=context._headers,
                auth=context.auth,
                request=request,
            )
            async with self._state_manager.reader(
                context,
                self._servicer.__state_type__,
                authorize=authorizer,
            ) as state:
                if transaction is not None:
                    # We need the transaction to be stored _before_ sending a
                    # response to the user; otherwise they may read two
                    # different states if we crash. Storing the transaction
                    # before even performing the read covers an edge-case:
                    # `StateManager.colocated_read()`, which may be called from
                    # this reader, will read from RocksDB, and will want to use
                    # the transaction.
                    await self._state_manager.transaction_participant_store(
                        transaction
                    )
                response = await self.__Status(
                    context,
                    state,
                    request,
                    validating_effects=validating_effects,
                )
                return response

    async def _schedule_Status(
        self,
        *,
        request: reboot.memoize.v1.memoize_pb2.StatusRequest,
        headers: reboot.aio.headers.Headers,
        grpc_context: grpc.aio.ServicerContext,
    ) -> tuple[reboot.aio.contexts.WriterContext, reboot.memoize.v1.memoize_pb2.StatusResponse]:
        context: reboot.aio.contexts.WriterContext = self.create_context(
            headers=headers,
            state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            context_type=reboot.aio.contexts.WriterContext,
        )
        response = reboot.memoize.v1.memoize_pb2.StatusResponse()


        async with self._state_manager.transactionally(
            context, self.tasks_dispatcher
        ) as transaction:
            if transaction is not None:
                context.participants.add(
                    self._servicer.__state_type_name__, context._state_ref
                )

            # Try to verify the token if a token verifier exists.
            context.auth = await self._maybe_verify_token(headers)

            async with self._state_manager.writer(
                context,
                self._servicer.__state_type__,
                self.tasks_dispatcher,
                transaction=transaction,
                authorize=self._maybe_authorize(
                    method_name='reboot.memoize.v1.MemoizeMethods.Status',
                    headers=context._headers,
                    auth=context.auth,
                    request=request,
                ),
                from_constructor=False,
                requires_constructor=False
            ) as (state, writer):

                task = MemoizeServicerTasksStub(
                    context=context,
                    state_ref=context._state_ref,
                ).Status(
                    request,
                    schedule=context._headers.task_schedule,
                )

                effects = reboot.aio.state_managers.Effects(
                    response=response,
                    state=state,
                    tasks=[task],
                )

                assert effects.tasks is not None

                await writer.complete(effects)

                assert grpc_context is not None

                grpc_context.set_trailing_metadata(
                    grpc_context.trailing_metadata() +
                    (
                        (
                            reboot.aio.headers.TASK_ID_UUID,
                            str(uuid.UUID(bytes=task.task_id.task_uuid))
                        ),
                    )
                )

                return context, response

        return context, response


    # Entrypoint for non-reactive network calls (i.e. typical gRPC calls).
    async def Status(
        self,
        request: reboot.memoize.v1.memoize_pb2.StatusRequest,
        grpc_context: grpc.aio.ServicerContext,
    ) -> reboot.memoize.v1.memoize_pb2.StatusResponse:
        headers = reboot.aio.headers.Headers.from_grpc_context(grpc_context)
        assert headers.application_id is not None  # Guaranteed by `Headers`.

        # Confirm whether this is the right consensus to be serving this
        # request.
        authoritative_consensus = self.placement_client.consensus_for_actor(
            headers.application_id,
            headers.state_ref,
        )
        if authoritative_consensus != self.consensus_id:
            # This is NOT the correct consensus. Fail.
            await grpc_context.abort(
                grpc.StatusCode.UNAVAILABLE,
                f"Consensus '{self.consensus_id}' is not authoritative for this "
                f"request; consensus '{authoritative_consensus}' is.",
            )
            raise  # Unreachable but necessary for mypy.

        @maybe_run_function_twice_to_validate_effects
        async def _run(
            validating_effects: bool,
        ) -> reboot.memoize.v1.memoize_pb2.StatusResponse:
            context: typing.Optional[reboot.aio.contexts.Context] = None
            try:
                if headers.task_schedule is not None:
                    context, response = await self._schedule_Status(
                        headers=headers,
                        request=request,
                        grpc_context=grpc_context,
                    )
                    return response

                context = self.create_context(
                    headers=headers,
                    state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    context_type=reboot.aio.contexts.ReaderContext,
                )
                assert context is not None

                return await self._Status(
                    request,
                    context,
                    validating_effects=validating_effects,
                    grpc_context=grpc_context,
                )
            except reboot.aio.contexts.EffectValidationRetry:
                # Doing effect validation, just let this propagate.
                raise
            except reboot.aio.aborted.Aborted as aborted:
                await grpc_context.abort_with_status(
                    rpc_status_sync.to_status(aborted.to_status())
                )
                raise  # Unreachable but necessary for mypy.
            except asyncio.CancelledError:
                # It's pretty normal for an RPC to be cancelled; it's not useful to
                # print a stack trace.
                raise
            except BaseException as exception:
                # Print the exception stack trace for easier debugging. Note
                # that we don't include the stack trace in an error message
                # for the same reason that gRPC doesn't do so by default,
                # see https://github.com/grpc/grpc/issues/14897, but since this
                # should only get logged on the server side it is safe.
                logger.warning(
                    'Unhandled exception\n' +
                    ''.join(traceback.format_exc() if not NODEJS else [f"{type(exception).__name__}: {exception}"])
                )

                # Re-raise the exception for gRPC to handle!
                raise
            finally:
                if context is not None and context.transaction_id is not None:
                    # Propagate transaction participants.
                    grpc_context.set_trailing_metadata(
                        grpc_context.trailing_metadata() +
                        context.participants.to_grpc_metadata()
                    )

        return await _run()

    def _maybe_authorize(
        self,
        *,
        method_name: str,
        headers: reboot.aio.headers.Headers,
        auth: typing.Optional[reboot.aio.auth.Auth],
        request: typing.Optional[MemoizeRequestTypes] = None,
    ) -> typing.Optional[typing.Callable[[typing.Optional[MemoizeStateType]], typing.Awaitable[None]]]:
        """Returns a function to check authorization for the given method.

        Raises `PermissionDenied` in case Authorizer is present but the request
        is not authorized.
        """
        # To authorize internal calls, we use an internal magic token.
        if headers.bearer_token == __internal_magic_token__:
            return None

        if self._authorizer is None:
            return None

        async def authorize(state: typing.Optional[MemoizeStateType]) -> None:
            # Mypy does not know (and technically neither do we!) that the
            # authorizer property is immutable.
            assert self._authorizer is not None

            # Create context for the authorizer. This is a `ReaderContext`
            # independently of the calling context.
            with self.use_context(
                headers=(
                    # Get headers suitable for doing authorization.
                    headers.copy_for_token_verification_and_authorization()
                ),
                state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                context_type=reboot.aio.contexts.ReaderContext,
            ) as context:
                context.auth = auth

                # Get the authorizer decision.
                authorization_decision = await self._authorizer.authorize(
                    method_name=method_name,
                    context=context,
                    state=state,
                    request=request,
                )

            # Enforce correct authorizer decision type.
            try:
                assert_type(
                    authorization_decision,
                    [
                        rbt.v1alpha1.errors_pb2.Ok,
                        rbt.v1alpha1.errors_pb2.Unauthenticated,
                        rbt.v1alpha1.errors_pb2.PermissionDenied,
                    ]
                )
            except TypeError as e:
                # Retyping.cast the exception to provide more context.
                authorizer_type = f"{type(self._authorizer).__module__}.{type(self._authorizer).__name__}"
                raise TypeError(
                    f"Authorizer '{authorizer_type}' "
                    f"returned unexpected type '{type(authorization_decision).__name__}' "
                    f"for method '{method_name}' on "
                    f"`reboot.memoize.v1.Memoize('{headers.state_ref.id}')`"
                ) from e

            # If the decision is not `True`, raise a `SystemAborted` with either a
            # `PermissionDenied` error (in case of `False`) or an `Unauthenticated`
            # error.
            if not isinstance(authorization_decision, rbt.v1alpha1.errors_pb2.Ok):
                if isinstance(authorization_decision, rbt.v1alpha1.errors_pb2.Unauthenticated):
                    logger.warning(
                        f"Unauthenticated call to '{method_name}' on "
                        f"`reboot.memoize.v1.Memoize('{headers.state_ref.id}')`"
                    )

                raise reboot.aio.aborted.SystemAborted(
                    authorization_decision,
                    message=
                    f"You are not authorized to call '{method_name}' on "
                    f"`reboot.memoize.v1.Memoize('{headers.state_ref.id}')`"
                )

        return authorize

    async def _maybe_verify_token(self, headers: reboot.aio.headers.Headers) -> typing.Optional[reboot.aio.auth.Auth]:
        """Verify the bearer token and if a token verifier is present.

        Returns the (optional) `reboot.aio.auth.Auth` object
        produced by the token verifier if the token can be verified.
        """
        auth: typing.Optional[reboot.aio.auth.Auth] = None

        if self._token_verifier is not None and headers.bearer_token is not None:
            if headers.bearer_token == __internal_magic_token__:
                return auth

            with self.use_context(
                headers=(
                    # Get headers suitable for doing token verification.
                    headers.copy_for_token_verification_and_authorization()
                ),
                state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                context_type=reboot.aio.contexts.ReaderContext,
            ) as context:
                auth = await self._token_verifier.verify_token(
                    context=context,
                    token=headers.bearer_token,
                )

        return auth


############################ Client Stubs ############################
# This section is relevant for clients accessing a Reboot service. Since
# servicers are themselves often clients also, this code is generated for
# them also.


class _MemoizeStub(reboot.aio.stubs.Stub):

    __state_type_name__ = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize')

    def __init__(
        self,
        *,
        context: reboot.aio.contexts.Context | reboot.aio.external.ExternalContext,
        state_ref: reboot.aio.types.StateRef,
        bearer_token: typing.Optional[str] = None,
    ):
        # ISSUE(https://github.com/reboot-dev/mono/issues/2258) For
        # now we do not explicitly pass on the bearer token unless it
        # is from an `ExternalContext`, as it might have security
        # implications to just pass on the token to any service we are
        # calling.
        if isinstance(context, reboot.aio.external.ExternalContext):
            bearer_token = context.bearer_token

        super().__init__(
            channel_manager=context.channel_manager,
            idempotency_manager=context,
            state_ref=state_ref,
            context=context if isinstance(context, reboot.aio.contexts.Context) else None,
            bearer_token=bearer_token,
        )

        # All the channels for all services of this state will go to the same
        # place, so we can just get a single channel and share it across all
        # stubs.
        channel = self._channel_manager.get_channel_to_state(
            self.__state_type_name__, state_ref
        )
        self._reboot_memoize_v1_memoizemethods_stub = reboot.memoize.v1.memoize_pb2_grpc.MemoizeMethodsStub(channel)


class MemoizeReaderStub(_MemoizeStub):

    def __init__(
        self,
        context: reboot.aio.contexts.ReaderContext | reboot.aio.contexts.WriterContext | reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        *,
        state_ref: reboot.aio.types.StateRef,
        bearer_token: typing.Optional[str] = None,
    ):
        assert_type(context, [reboot.aio.contexts.ReaderContext, reboot.aio.contexts.WriterContext, reboot.aio.contexts.TransactionContext, reboot.aio.contexts.WorkflowContext, reboot.aio.external.ExternalContext])
        super().__init__(
            context=context,
            state_ref=state_ref,
            bearer_token=bearer_token,
        )

    # Memoize specific methods:




    async def Status(
        self,
        request: reboot.memoize.v1.memoize_pb2.StatusRequest,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> reboot.memoize.v1.memoize_pb2.StatusResponse:
        async with self._call(
            reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            'Status',
            self._reboot_memoize_v1_memoizemethods_stub.Status,
            request,
            unary=True,
            reader=True,
            response_type=reboot.memoize.v1.memoize_pb2.StatusResponse,
            aborted_type=Memoize.StatusAborted,
            metadata=metadata,
            bearer_token=bearer_token,
        ) as call:
            assert isinstance(call, typing.Awaitable)
            return await call



class MemoizeWriterStub(_MemoizeStub):

    def __init__(
        self,
        context: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        *,
        state_ref: reboot.aio.types.StateRef,
        bearer_token: typing.Optional[str] = None,
    ):
        assert_type(context, [reboot.aio.contexts.TransactionContext, reboot.aio.contexts.WorkflowContext, reboot.aio.external.ExternalContext])
        super().__init__(
            context=context,
            state_ref=state_ref,
            bearer_token=bearer_token,
        )

    # Memoize specific methods:
    async def Reset(
        self,
        request: reboot.memoize.v1.memoize_pb2.ResetRequest,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> reboot.memoize.v1.memoize_pb2.ResetResponse:
        with self._idempotency_manager.idempotently(
            state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            method='Reset',
            request=request,
            metadata=metadata,
            idempotency=idempotency,
        ) as idempotency_key:
            async with self._call(
                reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                'Reset',
                self._reboot_memoize_v1_memoizemethods_stub.Reset,
                request,
                unary=True,
                reader=False,
                response_type=reboot.memoize.v1.memoize_pb2.ResetResponse,
                aborted_type=Memoize.ResetAborted,
                metadata=metadata,
                idempotency_key=idempotency_key,
                bearer_token=bearer_token,
            ) as call:
                assert isinstance(call, typing.Awaitable)
                return await call

    async def Start(
        self,
        request: reboot.memoize.v1.memoize_pb2.StartRequest,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> reboot.memoize.v1.memoize_pb2.StartResponse:
        with self._idempotency_manager.idempotently(
            state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            method='Start',
            request=request,
            metadata=metadata,
            idempotency=idempotency,
        ) as idempotency_key:
            async with self._call(
                reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                'Start',
                self._reboot_memoize_v1_memoizemethods_stub.Start,
                request,
                unary=True,
                reader=False,
                response_type=reboot.memoize.v1.memoize_pb2.StartResponse,
                aborted_type=Memoize.StartAborted,
                metadata=metadata,
                idempotency_key=idempotency_key,
                bearer_token=bearer_token,
            ) as call:
                assert isinstance(call, typing.Awaitable)
                return await call

    async def Store(
        self,
        request: reboot.memoize.v1.memoize_pb2.StoreRequest,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> reboot.memoize.v1.memoize_pb2.StoreResponse:
        with self._idempotency_manager.idempotently(
            state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            method='Store',
            request=request,
            metadata=metadata,
            idempotency=idempotency,
        ) as idempotency_key:
            async with self._call(
                reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                'Store',
                self._reboot_memoize_v1_memoizemethods_stub.Store,
                request,
                unary=True,
                reader=False,
                response_type=reboot.memoize.v1.memoize_pb2.StoreResponse,
                aborted_type=Memoize.StoreAborted,
                metadata=metadata,
                idempotency_key=idempotency_key,
                bearer_token=bearer_token,
            ) as call:
                assert isinstance(call, typing.Awaitable)
                return await call

    async def Fail(
        self,
        request: reboot.memoize.v1.memoize_pb2.FailRequest,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> reboot.memoize.v1.memoize_pb2.FailResponse:
        with self._idempotency_manager.idempotently(
            state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            method='Fail',
            request=request,
            metadata=metadata,
            idempotency=idempotency,
        ) as idempotency_key:
            async with self._call(
                reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                'Fail',
                self._reboot_memoize_v1_memoizemethods_stub.Fail,
                request,
                unary=True,
                reader=False,
                response_type=reboot.memoize.v1.memoize_pb2.FailResponse,
                aborted_type=Memoize.FailAborted,
                metadata=metadata,
                idempotency_key=idempotency_key,
                bearer_token=bearer_token,
            ) as call:
                assert isinstance(call, typing.Awaitable)
                return await call

    async def Status(
        self,
        request: reboot.memoize.v1.memoize_pb2.StatusRequest,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> reboot.memoize.v1.memoize_pb2.StatusResponse:
        async with self._call(
            reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            'Status',
            self._reboot_memoize_v1_memoizemethods_stub.Status,
            request,
            unary=True,
            reader=True,
            response_type=reboot.memoize.v1.memoize_pb2.StatusResponse,
            aborted_type=Memoize.StatusAborted,
            metadata=metadata,
            bearer_token=bearer_token,
        ) as call:
            assert isinstance(call, typing.Awaitable)
            return await call


class MemoizeWorkflowStub(_MemoizeStub):

    def __init__(
        self,
        *,
        context: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        state_ref: reboot.aio.types.StateRef,
        bearer_token: typing.Optional[str] = None,
    ):
        assert_type(context, [reboot.aio.contexts.TransactionContext, reboot.aio.contexts.WorkflowContext, reboot.aio.external.ExternalContext])
        super().__init__(
            context=context,
            state_ref=state_ref,
            bearer_token=bearer_token,
        )

    # Memoize specific methods:
    async def Reset(
        self,
        request: reboot.memoize.v1.memoize_pb2.ResetRequest,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> reboot.memoize.v1.memoize_pb2.ResetResponse:
        idempotency_key: typing.Optional[uuid.UUID]
        with self._idempotency_manager.idempotently(
            state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            method='Reset',
            request=request,
            metadata=metadata,
            idempotency=idempotency,
        ) as idempotency_key:
            async with self._call(
                reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                'Reset',
                self._reboot_memoize_v1_memoizemethods_stub.Reset,
                request,
                unary=True,
                reader=False,
                response_type=reboot.memoize.v1.memoize_pb2.ResetResponse,
                aborted_type=Memoize.ResetAborted,
                metadata=metadata,
                idempotency_key=idempotency_key,
                bearer_token=bearer_token,
            ) as call:
                assert isinstance(call, typing.Awaitable)
                return await call

    async def Start(
        self,
        request: reboot.memoize.v1.memoize_pb2.StartRequest,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> reboot.memoize.v1.memoize_pb2.StartResponse:
        idempotency_key: typing.Optional[uuid.UUID]
        with self._idempotency_manager.idempotently(
            state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            method='Start',
            request=request,
            metadata=metadata,
            idempotency=idempotency,
        ) as idempotency_key:
            async with self._call(
                reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                'Start',
                self._reboot_memoize_v1_memoizemethods_stub.Start,
                request,
                unary=True,
                reader=False,
                response_type=reboot.memoize.v1.memoize_pb2.StartResponse,
                aborted_type=Memoize.StartAborted,
                metadata=metadata,
                idempotency_key=idempotency_key,
                bearer_token=bearer_token,
            ) as call:
                assert isinstance(call, typing.Awaitable)
                return await call

    async def Store(
        self,
        request: reboot.memoize.v1.memoize_pb2.StoreRequest,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> reboot.memoize.v1.memoize_pb2.StoreResponse:
        idempotency_key: typing.Optional[uuid.UUID]
        with self._idempotency_manager.idempotently(
            state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            method='Store',
            request=request,
            metadata=metadata,
            idempotency=idempotency,
        ) as idempotency_key:
            async with self._call(
                reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                'Store',
                self._reboot_memoize_v1_memoizemethods_stub.Store,
                request,
                unary=True,
                reader=False,
                response_type=reboot.memoize.v1.memoize_pb2.StoreResponse,
                aborted_type=Memoize.StoreAborted,
                metadata=metadata,
                idempotency_key=idempotency_key,
                bearer_token=bearer_token,
            ) as call:
                assert isinstance(call, typing.Awaitable)
                return await call

    async def Fail(
        self,
        request: reboot.memoize.v1.memoize_pb2.FailRequest,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> reboot.memoize.v1.memoize_pb2.FailResponse:
        idempotency_key: typing.Optional[uuid.UUID]
        with self._idempotency_manager.idempotently(
            state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            method='Fail',
            request=request,
            metadata=metadata,
            idempotency=idempotency,
        ) as idempotency_key:
            async with self._call(
                reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                'Fail',
                self._reboot_memoize_v1_memoizemethods_stub.Fail,
                request,
                unary=True,
                reader=False,
                response_type=reboot.memoize.v1.memoize_pb2.FailResponse,
                aborted_type=Memoize.FailAborted,
                metadata=metadata,
                idempotency_key=idempotency_key,
                bearer_token=bearer_token,
            ) as call:
                assert isinstance(call, typing.Awaitable)
                return await call

    async def Status(
        self,
        request: reboot.memoize.v1.memoize_pb2.StatusRequest,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> reboot.memoize.v1.memoize_pb2.StatusResponse:
        async with self._call(
            reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            'Status',
            self._reboot_memoize_v1_memoizemethods_stub.Status,
            request,
            unary=True,
            reader=True,
            response_type=reboot.memoize.v1.memoize_pb2.StatusResponse,
            aborted_type=Memoize.StatusAborted,
            metadata=metadata,
            bearer_token=bearer_token,
        ) as call:
            assert isinstance(call, typing.Awaitable)
            return await call



class MemoizeTasksStub(_MemoizeStub):

    def __init__(
        self,
        context: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        *,
        state_ref: reboot.aio.types.StateRef,
        bearer_token: typing.Optional[str] = None,
    ):
        assert_type(context, [reboot.aio.contexts.TransactionContext, reboot.aio.contexts.WorkflowContext, reboot.aio.external.ExternalContext])
        super().__init__(
            context=context,
            state_ref=state_ref,
            bearer_token=bearer_token,
        )

    # Memoize specific methods:
    async def Reset(
        self,
        request: reboot.memoize.v1.memoize_pb2.ResetRequest,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> tasks_pb2.TaskId:
        idempotency_key: typing.Optional[uuid.UUID]
        with self._idempotency_manager.idempotently(
            state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            method='Reset',
            request=request,
            metadata=metadata,
            idempotency=idempotency,
        ) as idempotency_key:
            async with self._call(
                reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                'Reset',
                self._reboot_memoize_v1_memoizemethods_stub.Reset,
                request,
                unary=True,
                reader=False,
                response_type=reboot.memoize.v1.memoize_pb2.ResetResponse,
                aborted_type=Memoize.ResetAborted,
                metadata=metadata,
                idempotency_key=idempotency_key,
                bearer_token=bearer_token,
            ) as call:
                assert isinstance(call, typing.Awaitable)
                await call
                for (key, value) in await call.trailing_metadata():  # type: ignore[attr-defined]
                    if key == reboot.aio.headers.TASK_ID_UUID:
                        return tasks_pb2.TaskId(
                            state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                            state_ref=self._headers.state_ref.to_str(),
                            task_uuid=uuid.UUID(value).bytes,
                        )
                raise reboot.aio.aborted.SystemAborted(
                    rbt.v1alpha1.errors_pb2.Internal(),
                    message='Trailing metadata missing for task schedule',
                )
    async def Start(
        self,
        request: reboot.memoize.v1.memoize_pb2.StartRequest,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> tasks_pb2.TaskId:
        idempotency_key: typing.Optional[uuid.UUID]
        with self._idempotency_manager.idempotently(
            state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            method='Start',
            request=request,
            metadata=metadata,
            idempotency=idempotency,
        ) as idempotency_key:
            async with self._call(
                reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                'Start',
                self._reboot_memoize_v1_memoizemethods_stub.Start,
                request,
                unary=True,
                reader=False,
                response_type=reboot.memoize.v1.memoize_pb2.StartResponse,
                aborted_type=Memoize.StartAborted,
                metadata=metadata,
                idempotency_key=idempotency_key,
                bearer_token=bearer_token,
            ) as call:
                assert isinstance(call, typing.Awaitable)
                await call
                for (key, value) in await call.trailing_metadata():  # type: ignore[attr-defined]
                    if key == reboot.aio.headers.TASK_ID_UUID:
                        return tasks_pb2.TaskId(
                            state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                            state_ref=self._headers.state_ref.to_str(),
                            task_uuid=uuid.UUID(value).bytes,
                        )
                raise reboot.aio.aborted.SystemAborted(
                    rbt.v1alpha1.errors_pb2.Internal(),
                    message='Trailing metadata missing for task schedule',
                )
    async def Store(
        self,
        request: reboot.memoize.v1.memoize_pb2.StoreRequest,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> tasks_pb2.TaskId:
        idempotency_key: typing.Optional[uuid.UUID]
        with self._idempotency_manager.idempotently(
            state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            method='Store',
            request=request,
            metadata=metadata,
            idempotency=idempotency,
        ) as idempotency_key:
            async with self._call(
                reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                'Store',
                self._reboot_memoize_v1_memoizemethods_stub.Store,
                request,
                unary=True,
                reader=False,
                response_type=reboot.memoize.v1.memoize_pb2.StoreResponse,
                aborted_type=Memoize.StoreAborted,
                metadata=metadata,
                idempotency_key=idempotency_key,
                bearer_token=bearer_token,
            ) as call:
                assert isinstance(call, typing.Awaitable)
                await call
                for (key, value) in await call.trailing_metadata():  # type: ignore[attr-defined]
                    if key == reboot.aio.headers.TASK_ID_UUID:
                        return tasks_pb2.TaskId(
                            state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                            state_ref=self._headers.state_ref.to_str(),
                            task_uuid=uuid.UUID(value).bytes,
                        )
                raise reboot.aio.aborted.SystemAborted(
                    rbt.v1alpha1.errors_pb2.Internal(),
                    message='Trailing metadata missing for task schedule',
                )
    async def Fail(
        self,
        request: reboot.memoize.v1.memoize_pb2.FailRequest,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> tasks_pb2.TaskId:
        idempotency_key: typing.Optional[uuid.UUID]
        with self._idempotency_manager.idempotently(
            state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            method='Fail',
            request=request,
            metadata=metadata,
            idempotency=idempotency,
        ) as idempotency_key:
            async with self._call(
                reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                'Fail',
                self._reboot_memoize_v1_memoizemethods_stub.Fail,
                request,
                unary=True,
                reader=False,
                response_type=reboot.memoize.v1.memoize_pb2.FailResponse,
                aborted_type=Memoize.FailAborted,
                metadata=metadata,
                idempotency_key=idempotency_key,
                bearer_token=bearer_token,
            ) as call:
                assert isinstance(call, typing.Awaitable)
                await call
                for (key, value) in await call.trailing_metadata():  # type: ignore[attr-defined]
                    if key == reboot.aio.headers.TASK_ID_UUID:
                        return tasks_pb2.TaskId(
                            state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                            state_ref=self._headers.state_ref.to_str(),
                            task_uuid=uuid.UUID(value).bytes,
                        )
                raise reboot.aio.aborted.SystemAborted(
                    rbt.v1alpha1.errors_pb2.Internal(),
                    message='Trailing metadata missing for task schedule',
                )
    async def Status(
        self,
        request: reboot.memoize.v1.memoize_pb2.StatusRequest,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        *,
        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> tasks_pb2.TaskId:
        idempotency_key: typing.Optional[uuid.UUID]
        with self._idempotency_manager.idempotently(
            state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
            method='Status',
            request=request,
            metadata=metadata,
            idempotency=idempotency,
        ) as idempotency_key:
            async with self._call(
                reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                'Status',
                self._reboot_memoize_v1_memoizemethods_stub.Status,
                request,
                unary=True,
                reader=False,
                response_type=reboot.memoize.v1.memoize_pb2.StatusResponse,
                aborted_type=Memoize.StatusAborted,
                metadata=metadata,
                idempotency_key=idempotency_key,
                bearer_token=bearer_token,
            ) as call:
                assert isinstance(call, typing.Awaitable)
                await call
                for (key, value) in await call.trailing_metadata():  # type: ignore[attr-defined]
                    if key == reboot.aio.headers.TASK_ID_UUID:
                        return tasks_pb2.TaskId(
                            state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                            state_ref=self._headers.state_ref.to_str(),
                            task_uuid=uuid.UUID(value).bytes,
                        )
                raise reboot.aio.aborted.SystemAborted(
                    rbt.v1alpha1.errors_pb2.Internal(),
                    message='Trailing metadata missing for task schedule',
                )


class MemoizeServicerTasksStub(_MemoizeStub):

    _context: reboot.aio.contexts.WriterContext

    def __init__(
        self,
        context: reboot.aio.contexts.WriterContext,
        *,
        state_ref: reboot.aio.types.StateRef,
        bearer_token: typing.Optional[str] = None,
    ):
        assert_type(context, [reboot.aio.contexts.WriterContext])
        super().__init__(
            context=context,
            state_ref=state_ref,
            bearer_token=bearer_token,
        )

        self._context = context

    # Memoize specific methods:
    def Reset(
        self,
        request: reboot.memoize.v1.memoize_pb2.ResetRequest,
        *,
        schedule: typing.Optional[datetime | timedelta] = None,
    ) -> reboot.aio.tasks.TaskEffect:
        task = reboot.aio.tasks.TaskEffect(
            state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            method_name='Reset',
            request=request,
            schedule=(datetime.now() + schedule) if isinstance(
                schedule, timedelta
            ) else schedule,
        )

        self._context._tasks.append(task)

        return task

    def Start(
        self,
        request: reboot.memoize.v1.memoize_pb2.StartRequest,
        *,
        schedule: typing.Optional[datetime | timedelta] = None,
    ) -> reboot.aio.tasks.TaskEffect:
        task = reboot.aio.tasks.TaskEffect(
            state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            method_name='Start',
            request=request,
            schedule=(datetime.now() + schedule) if isinstance(
                schedule, timedelta
            ) else schedule,
        )

        self._context._tasks.append(task)

        return task

    def Store(
        self,
        request: reboot.memoize.v1.memoize_pb2.StoreRequest,
        *,
        schedule: typing.Optional[datetime | timedelta] = None,
    ) -> reboot.aio.tasks.TaskEffect:
        task = reboot.aio.tasks.TaskEffect(
            state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            method_name='Store',
            request=request,
            schedule=(datetime.now() + schedule) if isinstance(
                schedule, timedelta
            ) else schedule,
        )

        self._context._tasks.append(task)

        return task

    def Fail(
        self,
        request: reboot.memoize.v1.memoize_pb2.FailRequest,
        *,
        schedule: typing.Optional[datetime | timedelta] = None,
    ) -> reboot.aio.tasks.TaskEffect:
        task = reboot.aio.tasks.TaskEffect(
            state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            method_name='Fail',
            request=request,
            schedule=(datetime.now() + schedule) if isinstance(
                schedule, timedelta
            ) else schedule,
        )

        self._context._tasks.append(task)

        return task

    def Status(
        self,
        request: reboot.memoize.v1.memoize_pb2.StatusRequest,
        *,
        schedule: typing.Optional[datetime | timedelta] = None,
    ) -> reboot.aio.tasks.TaskEffect:
        task = reboot.aio.tasks.TaskEffect(
            state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
            state_ref=self._headers.state_ref,
            method_name='Status',
            request=request,
            schedule=(datetime.now() + schedule) if isinstance(
                schedule, timedelta
            ) else schedule,
        )

        self._context._tasks.append(task)

        return task



############################ Authorizers ############################
# Relevant to servicers; irrelevant to clients.

MemoizeStateType: typing.TypeAlias = reboot.memoize.v1.memoize_pb2.Memoize
MemoizeRequestTypes: typing.TypeAlias = \
        reboot.memoize.v1.memoize_pb2.ResetRequest \
        | reboot.memoize.v1.memoize_pb2.StartRequest \
        | reboot.memoize.v1.memoize_pb2.StoreRequest \
        | reboot.memoize.v1.memoize_pb2.FailRequest \
        | reboot.memoize.v1.memoize_pb2.StatusRequest

class MemoizeAuthorizer(
    reboot.aio.auth.authorizers.Authorizer[MemoizeStateType, MemoizeRequestTypes],
):
    StateType: typing.TypeAlias = MemoizeStateType
    RequestTypes: typing.TypeAlias = MemoizeRequestTypes

    async def authorize(
        self,
        *,
        method_name: str,
        context: reboot.aio.contexts.ReaderContext,
        state: typing.Optional[MemoizeStateType] = None,
        request: typing.Optional[MemoizeRequestTypes] = None,
    ) -> reboot.aio.auth.authorizers.Authorizer.Decision:
        if method_name == 'reboot.memoize.v1.MemoizeMethods.Reset':
            return await self.Reset(
                context,
                typing.cast(reboot.memoize.v1.memoize_pb2.Memoize, state),
                typing.cast(reboot.memoize.v1.memoize_pb2.ResetRequest, request),
            )
        elif method_name == 'reboot.memoize.v1.MemoizeMethods.Start':
            return await self.Start(
                context,
                typing.cast(reboot.memoize.v1.memoize_pb2.Memoize, state),
                typing.cast(reboot.memoize.v1.memoize_pb2.StartRequest, request),
            )
        elif method_name == 'reboot.memoize.v1.MemoizeMethods.Store':
            return await self.Store(
                context,
                typing.cast(reboot.memoize.v1.memoize_pb2.Memoize, state),
                typing.cast(reboot.memoize.v1.memoize_pb2.StoreRequest, request),
            )
        elif method_name == 'reboot.memoize.v1.MemoizeMethods.Fail':
            return await self.Fail(
                context,
                typing.cast(reboot.memoize.v1.memoize_pb2.Memoize, state),
                typing.cast(reboot.memoize.v1.memoize_pb2.FailRequest, request),
            )
        elif method_name == 'reboot.memoize.v1.MemoizeMethods.Status':
            return await self.Status(
                context,
                typing.cast(reboot.memoize.v1.memoize_pb2.Memoize, state),
                typing.cast(reboot.memoize.v1.memoize_pb2.StatusRequest, request),
            )
        else:
            return rbt.v1alpha1.errors_pb2.PermissionDenied()

    # For 'reboot.memoize.v1.MemoizeMethods.Reset'.
    async def Reset(
        self,
        context: reboot.aio.contexts.ReaderContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.ResetRequest,
    ) -> reboot.aio.auth.authorizers.Authorizer.Decision:
        return rbt.v1alpha1.errors_pb2.PermissionDenied()

    # For 'reboot.memoize.v1.MemoizeMethods.Start'.
    async def Start(
        self,
        context: reboot.aio.contexts.ReaderContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.StartRequest,
    ) -> reboot.aio.auth.authorizers.Authorizer.Decision:
        return rbt.v1alpha1.errors_pb2.PermissionDenied()

    # For 'reboot.memoize.v1.MemoizeMethods.Store'.
    async def Store(
        self,
        context: reboot.aio.contexts.ReaderContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.StoreRequest,
    ) -> reboot.aio.auth.authorizers.Authorizer.Decision:
        return rbt.v1alpha1.errors_pb2.PermissionDenied()

    # For 'reboot.memoize.v1.MemoizeMethods.Fail'.
    async def Fail(
        self,
        context: reboot.aio.contexts.ReaderContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.FailRequest,
    ) -> reboot.aio.auth.authorizers.Authorizer.Decision:
        return rbt.v1alpha1.errors_pb2.PermissionDenied()

    # For 'reboot.memoize.v1.MemoizeMethods.Status'.
    async def Status(
        self,
        context: reboot.aio.contexts.ReaderContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.StatusRequest,
    ) -> reboot.aio.auth.authorizers.Authorizer.Decision:
        return rbt.v1alpha1.errors_pb2.PermissionDenied()



############################ Reboot Servicers ############################
# Base classes for server-side implementations of Reboot servicers.
# Irrelevant to clients.

class MemoizeServicer(reboot.aio.servicers.Servicer):
    Authorizer: typing.TypeAlias = MemoizeAuthorizer

    __service_names__ = [
        reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
    ]
    __state_type_name__ = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize')
    __state_type__ = reboot.memoize.v1.memoize_pb2.Memoize
    __file_descriptor__ = reboot.memoize.v1.memoize_pb2.DESCRIPTOR

    def __init__(self):
        super().__init__()
        # NOTE: need to hold on to the middleware so we can do inline
        # writes (see 'self.write(...)').
        #
        # Because '_middleware' is not really private this does mean
        # users may do possibly dangerous things, but this is no more
        # likely given they could have already overridden
        # 'create_middleware()'.
        self._middleware: typing.Optional[MemoizeServicerMiddleware] = None

    def create_middleware(
        self,
        *,
        application_id: reboot.aio.types.ApplicationId,
        consensus_id: reboot.aio.types.ConsensusId,
        state_manager: reboot.aio.state_managers.StateManager,
        placement_client: reboot.aio.placement.PlacementClient,
        channel_manager: reboot.aio.internals.channel_manager._ChannelManager,
        tasks_cache: reboot.aio.internals.tasks_cache.TasksCache,
        token_verifier: typing.Optional[reboot.aio.auth.token_verifiers.TokenVerifier],
        effect_validation: reboot.aio.contexts.EffectValidation,
        app_internal_api_key_secret: str,
        ready: asyncio.Event,
    ) -> MemoizeServicerMiddleware:
        self._middleware = MemoizeServicerMiddleware(
            servicer=self,
            application_id=application_id,
            consensus_id=consensus_id,
            state_manager=state_manager,
            placement_client=placement_client,
            channel_manager=channel_manager,
            tasks_cache=tasks_cache,
            token_verifier=token_verifier,
            effect_validation=effect_validation,
            app_internal_api_key_secret=app_internal_api_key_secret,
            ready=ready,
        )
        return self._middleware

    def authorizer(self) -> typing.Optional[reboot.aio.auth.authorizers.Authorizer]:
        return None

    def token_verifier(self) -> typing.Optional[reboot.aio.auth.token_verifiers.TokenVerifier]:
        return None

    def lookup(
        self,
        *,
        bearer_token: typing.Optional[str] = None,
    ) -> Memoize.WeakReference[Memoize.WeakReference._WriterSchedule]:
        # TODO(benh): it's still possible that the `bearer_token` from
        # the context will not be sufficient for making a
        # call/schedule due to a user defined authorizer; consider
        # creating a "per middleware" bearer token that always works
        # for calls from `self.lookup()`.
        context = reboot.aio.contexts.Context.get()

        if context is None:
            raise RuntimeError(
                'Missing asyncio context variable `context`; '
                'are you using this class without Reboot?'
            )

        return Memoize.WeakReference(
            state_id=context._state_ref.id,
            schedule_type=Memoize.WeakReference._WriterSchedule,
            bearer_token=bearer_token or context.bearer_token,
        )

    class Effects(reboot.aio.state_managers.Effects):
        def __init__(
            self,
            *,
            state: reboot.memoize.v1.memoize_pb2.Memoize,
            response: typing.Optional[google.protobuf.message.Message] = None,
            tasks: typing.Optional[list[reboot.aio.tasks.TaskEffect]] = None,
            _colocated_upserts: typing.Optional[list[tuple[str, typing.Optional[bytes]]]] = None,
        ):
            assert_type(state, [reboot.memoize.v1.memoize_pb2.Memoize])

            super().__init__(state=state, response=response, tasks=tasks, _colocated_upserts=_colocated_upserts)

    # For 'reboot.memoize.v1.MemoizeMethods.Reset'.
    class ResetEffects(Effects):
        def __init__(
            self,
            *,
            state: reboot.memoize.v1.memoize_pb2.Memoize,
            response: reboot.memoize.v1.memoize_pb2.ResetResponse,
            tasks: typing.Optional[list[reboot.aio.tasks.TaskEffect]] = None,
            _colocated_upserts: typing.Optional[list[tuple[str, typing.Optional[bytes]]]] = None,
        ):
            assert_type(state, [reboot.memoize.v1.memoize_pb2.Memoize])
            assert_type(response, [reboot.memoize.v1.memoize_pb2.ResetResponse])

            super().__init__(state=state, response=response, tasks=tasks, _colocated_upserts=_colocated_upserts)


    # For 'reboot.memoize.v1.MemoizeMethods.Start'.
    class StartEffects(Effects):
        def __init__(
            self,
            *,
            state: reboot.memoize.v1.memoize_pb2.Memoize,
            response: reboot.memoize.v1.memoize_pb2.StartResponse,
            tasks: typing.Optional[list[reboot.aio.tasks.TaskEffect]] = None,
            _colocated_upserts: typing.Optional[list[tuple[str, typing.Optional[bytes]]]] = None,
        ):
            assert_type(state, [reboot.memoize.v1.memoize_pb2.Memoize])
            assert_type(response, [reboot.memoize.v1.memoize_pb2.StartResponse])

            super().__init__(state=state, response=response, tasks=tasks, _colocated_upserts=_colocated_upserts)


    # For 'reboot.memoize.v1.MemoizeMethods.Store'.
    class StoreEffects(Effects):
        def __init__(
            self,
            *,
            state: reboot.memoize.v1.memoize_pb2.Memoize,
            response: reboot.memoize.v1.memoize_pb2.StoreResponse,
            tasks: typing.Optional[list[reboot.aio.tasks.TaskEffect]] = None,
            _colocated_upserts: typing.Optional[list[tuple[str, typing.Optional[bytes]]]] = None,
        ):
            assert_type(state, [reboot.memoize.v1.memoize_pb2.Memoize])
            assert_type(response, [reboot.memoize.v1.memoize_pb2.StoreResponse])

            super().__init__(state=state, response=response, tasks=tasks, _colocated_upserts=_colocated_upserts)


    # For 'reboot.memoize.v1.MemoizeMethods.Fail'.
    class FailEffects(Effects):
        def __init__(
            self,
            *,
            state: reboot.memoize.v1.memoize_pb2.Memoize,
            response: reboot.memoize.v1.memoize_pb2.FailResponse,
            tasks: typing.Optional[list[reboot.aio.tasks.TaskEffect]] = None,
            _colocated_upserts: typing.Optional[list[tuple[str, typing.Optional[bytes]]]] = None,
        ):
            assert_type(state, [reboot.memoize.v1.memoize_pb2.Memoize])
            assert_type(response, [reboot.memoize.v1.memoize_pb2.FailResponse])

            super().__init__(state=state, response=response, tasks=tasks, _colocated_upserts=_colocated_upserts)




    InlineWriterCallableResult = typing.TypeVar('InlineWriterCallableResult', covariant=True)

    class InlineWriterCallable(typing.Protocol[InlineWriterCallableResult]):
        async def __call__(
            self,
            state: reboot.memoize.v1.memoize_pb2.Memoize
        ) -> MemoizeServicer.InlineWriterCallableResult:
            ...

    class _State:

        def __init__(
            self,
            servicer,
        ):
            self._servicer = servicer

        async def read(
            self, context: reboot.aio.contexts.WorkflowContext
        ) -> reboot.memoize.v1.memoize_pb2.Memoize:
            """Read the current state within a workflow."""

            assert_type(context, [reboot.aio.contexts.WorkflowContext])

            if self._servicer._middleware is None:
                raise RuntimeError(
                    'Reboot middleware was not created; '
                    'are you using this class without Reboot?'
                )

            return await self._servicer._middleware._state_manager.read(
                context, self._servicer.__state_type__
            )

        @typing.overload
        async def write(
            self,
            idempotency_alias: str,
            context: reboot.aio.contexts.WorkflowContext,
            writer: MemoizeServicer.InlineWriterCallable[None],
            __options__: reboot.aio.call.Options = reboot.aio.call.Options(),
            *,
            type: type = type(None),
        ) -> None:
            ...

        @typing.overload
        async def write(
            self,
            idempotency_alias: str,
            context: reboot.aio.contexts.WorkflowContext,
            writer: MemoizeServicer.InlineWriterCallable[MemoizeServicer.InlineWriterCallableResult],
            __options__: reboot.aio.call.Options = reboot.aio.call.Options(),
            *,
            type: type[MemoizeServicer.InlineWriterCallableResult],
        ) -> MemoizeServicer.InlineWriterCallableResult:
            ...

        async def write(
            self,
            idempotency_alias: str,
            context: reboot.aio.contexts.WorkflowContext,
            writer: MemoizeServicer.InlineWriterCallable[MemoizeServicer.InlineWriterCallableResult],
            __options__: reboot.aio.call.Options = reboot.aio.call.Options(),
            *,
            type: type = type(None),
        ) -> MemoizeServicer.InlineWriterCallableResult:
            """Perform an "inline write" within a workflow."""
            return await self.idempotently(idempotency_alias).write(
                context, writer, __options__, type=type
            )

        class _Idempotently:

            def __init__(
                self,
                *,
                servicer: MemoizeServicer,
                idempotency: reboot.aio.idempotency.Idempotency,
            ):
                self._servicer = servicer
                self._idempotency = idempotency

            @typing.overload
            async def write(
                self,
                context: reboot.aio.contexts.WorkflowContext,
                writer: MemoizeServicer.InlineWriterCallable[None],
                __options__: reboot.aio.call.Options = reboot.aio.call.Options(),
                *,
                type: type = type(None),
                check_type: bool = True,
            ) -> None:
                ...

            @typing.overload
            async def write(
                self,
                context: reboot.aio.contexts.WorkflowContext,
                writer: MemoizeServicer.InlineWriterCallable[MemoizeServicer.InlineWriterCallableResult],
                __options__: reboot.aio.call.Options = reboot.aio.call.Options(),
                *,
                type: type[MemoizeServicer.InlineWriterCallableResult],
                check_type: bool = True,
            ) -> MemoizeServicer.InlineWriterCallableResult:
                ...

            async def write(
                self,
                context: reboot.aio.contexts.WorkflowContext,
                writer: MemoizeServicer.InlineWriterCallable[MemoizeServicer.InlineWriterCallableResult],
                __options__: reboot.aio.call.Options = reboot.aio.call.Options(),
                *,
                type: type = type(None),
                check_type: bool = True,
            ) -> MemoizeServicer.InlineWriterCallableResult:
                return await self._write(
                    context,
                    writer,
                    __options__,
                    type_result=type,
                    check_type=check_type,
                    unidempotently=False,
                )

            async def _write(
                self,
                context: reboot.aio.contexts.WorkflowContext,
                writer: MemoizeServicer.InlineWriterCallable[MemoizeServicer.InlineWriterCallableResult],
                __options__: reboot.aio.call.Options = reboot.aio.call.Options(),
                *,
                type_result: type,
                check_type: bool,
                unidempotently: bool,
            ) -> MemoizeServicer.InlineWriterCallableResult:
                return await self._write_validating_effects(
                    self._servicer,
                    self._idempotency,
                    context,
                    writer,
                    __options__,
                    type_result=type_result,
                    check_type=check_type,
                    unidempotently=unidempotently,
                )

            @staticmethod
            @maybe_run_function_twice_to_validate_effects
            async def _write_validating_effects(
                validating_effects: bool,
                servicer: MemoizeServicer,
                idempotency: reboot.aio.idempotency.Idempotency,
                context: reboot.aio.contexts.WorkflowContext,
                writer: MemoizeServicer.InlineWriterCallable[MemoizeServicer.InlineWriterCallableResult],
                __options__: reboot.aio.call.Options = reboot.aio.call.Options(),
                *,
                type_result: type,
                check_type: bool,
                unidempotently: bool,
            ) -> MemoizeServicer.InlineWriterCallableResult:
                if __options__.idempotency is not None:
                    raise RuntimeError(
                        'Found redundant idempotency in `Options`'
                    )

                assert not idempotency.generate, (
                    "Inline writers are always required to specify either an "
                    "idempotency alias or an idempotency key"
                )

                assert_type(context, [reboot.aio.contexts.WorkflowContext])

                if servicer._middleware is None:
                    raise RuntimeError(
                        'Reboot middleware was not created; '
                        'are you using this class without Reboot?'
                    )

                metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None

                if __options__ is not None:
                    if __options__.metadata is not None:
                        metadata = __options__.metadata

                if metadata is None:
                    metadata = ()

                headers = reboot.aio.headers.Headers(
                    application_id=context.application_id,
                    state_ref=context._state_ref,
                )

                metadata += headers.to_grpc_metadata()

                idempotency_key: typing.Optional[uuid.UUID]
                with context.idempotently(
                    state_type_name=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    state_ref=context._state_ref,
                    service_name=None,  # Indicates an inline writer.
                    method=None,  # Indicates an inline writer.
                    request=None,
                    metadata=metadata,
                    idempotency=idempotency,
                ) as idempotency_key:

                    if any(t[0] == reboot.aio.headers.IDEMPOTENCY_KEY_HEADER for t in metadata):
                        raise ValueError(
                            f"Do not set '{reboot.aio.headers.IDEMPOTENCY_KEY_HEADER}' metadata yourself"
                        )

                    if idempotency_key is not None:
                        metadata += (
                            (reboot.aio.headers.IDEMPOTENCY_KEY_HEADER, str(idempotency_key)),
                        )

                    with servicer._middleware.use_context(
                        headers=reboot.aio.headers.Headers.from_grpc_metadata(metadata),
                        state_type_name = reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                        context_type=reboot.aio.contexts.WriterContext,
                    ) as writer_context:
                        # Check if we already have performed this mutation!
                        #
                        # We do this _before_ calling 'transactionally()' because
                        # if this call is for a transaction method _and_ we've
                        # already performed the transaction then we don't want to
                        # become a transaction participant (again) we just want to
                        # return the transaction's response.
                        idempotent_mutation = (
                            servicer._middleware._state_manager.check_for_idempotent_mutation(
                                writer_context
                            )
                        )

                        if idempotent_mutation is not None:
                            assert len(idempotent_mutation.response) != 0
                            response = wrappers_pb2.BytesValue()
                            response.ParseFromString(idempotent_mutation.response)
                            result: MemoizeServicer.InlineWriterCallableResult = pickle.loads(response.value)

                            if check_type and type(result) is not type_result:
                                raise TypeError(
                                    f"Stored result of type '{type(result).__name__}' from 'writer' "
                                    f"is not of expected type '{type_result.__name__}'; have you changed "
                                    "the 'type' that you expect after having stored a result?"
                                )

                            return result

                        async with servicer._middleware._state_manager.transactionally(
                            writer_context, servicer._middleware.tasks_dispatcher
                        ) as transaction:
                            async with servicer._middleware._state_manager.writer(
                                writer_context,
                                servicer.__state_type__,
                                servicer._middleware.tasks_dispatcher,
                                # TODO: Decide if we want to do any kind of authorization for inline
                                # writers otherwise passing `None` here is fine.
                                authorize=None,
                                transaction=transaction,
                            ) as (state, state_manager_writer):
                                result = await writer(state=state)

                                if check_type and type(result) is not type_result:
                                    raise TypeError(
                                        f"Result of type '{type(result).__name__}' from 'writer' is "
                                        f"not of expected type '{type_result.__name__}'; "
                                        "did you specify an incorrect 'type'?"
                                    )

                                effects = MemoizeServicer.Effects(
                                    state=state,
                                    tasks=context._tasks,
                                    response=wrappers_pb2.BytesValue(
                                        value=pickle.dumps(result)
                                    ),
                                )

                                task: typing.Optional[reboot.aio.tasks.TaskEffect] = context.task

                                assert task is not None, (
                                    "Should always have a task when running a `workflow`"
                                )

                                method_name = f"Memoize.{task.method_name} "

                                if unidempotently:
                                    method_name += "unidempotent inline writer"
                                elif idempotency.alias is not None:
                                    method_name += "inline writer with idempotency alias '" + idempotency.alias + "'"
                                else:
                                    assert idempotency.key is not None
                                    method_name += "inline writer with idempotency key=" + str(idempotency.key)

                                servicer._middleware.maybe_raise_effect_validation_retry(
                                    logger=logger,
                                    idempotency_manager=context,
                                    method_name=method_name,
                                    validating_effects=validating_effects,
                                    context=context,
                                )

                                await state_manager_writer.complete(effects)

                                return result

        @typing.overload
        def idempotently(self, alias: str, *, each_iteration: bool = False) -> MemoizeServicer._State._Idempotently:
            ...

        @typing.overload
        def idempotently(self, *, key: uuid.UUID) -> MemoizeServicer._State._Idempotently:
            ...

        def idempotently(
            self,
            alias: typing.Optional[str] = None,
            *,
            key: typing.Optional[uuid.UUID] = None,
            each_iteration: typing.Optional[bool] = None,
        ) -> MemoizeServicer._State._Idempotently:
            if alias is None and key is None:
                raise ValueError(
                    'Inline writers require either an idempotency alias or key'
                )
            return MemoizeServicer._State._Idempotently(
                servicer=self._servicer,
                idempotency=reboot.aio.contexts.Context.idempotency(
                    key=key, alias=alias, each_iteration=each_iteration
                ),
            )

        class _Unidempotently:

            def __init__(
                self,
                *,
                servicer: MemoizeServicer,
            ):
                self._servicer = servicer

            async def write(
                self,
                context: reboot.aio.contexts.WorkflowContext,
                writer: MemoizeServicer.InlineWriterCallable[MemoizeServicer.InlineWriterCallableResult],
                __options__: reboot.aio.call.Options = reboot.aio.call.Options(),
            ) -> MemoizeServicer.InlineWriterCallableResult:
                return await MemoizeServicer._State._Idempotently(
                    servicer=self._servicer,
                    idempotency=reboot.aio.contexts.Context.idempotency(
                        key=uuid.uuid4()
                    ),
                )._write(
                    context,
                    writer,
                    __options__,
                    type_result=type(None),
                    check_type=False,
                    unidempotently=True,
                )

        def unidempotently(self):
            return MemoizeServicer._State._Unidempotently(
                servicer=self._servicer,
            )

    @property
    def state(self):
        return MemoizeServicer._State(
            servicer=self
        )

    # For 'reboot.memoize.v1.MemoizeMethods.Reset'.
    @abstractmethod
    async def Reset(
        self,
        context: reboot.aio.contexts.WriterContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.ResetRequest,
    ) -> reboot.memoize.v1.memoize_pb2.ResetResponse:
        raise NotImplementedError

    # For 'reboot.memoize.v1.MemoizeMethods.Start'.
    @abstractmethod
    async def Start(
        self,
        context: reboot.aio.contexts.WriterContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.StartRequest,
    ) -> reboot.memoize.v1.memoize_pb2.StartResponse:
        raise NotImplementedError

    # For 'reboot.memoize.v1.MemoizeMethods.Store'.
    @abstractmethod
    async def Store(
        self,
        context: reboot.aio.contexts.WriterContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.StoreRequest,
    ) -> reboot.memoize.v1.memoize_pb2.StoreResponse:
        raise NotImplementedError

    # For 'reboot.memoize.v1.MemoizeMethods.Fail'.
    @abstractmethod
    async def Fail(
        self,
        context: reboot.aio.contexts.WriterContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.FailRequest,
    ) -> reboot.memoize.v1.memoize_pb2.FailResponse:
        raise NotImplementedError

    # For 'reboot.memoize.v1.MemoizeMethods.Status'.
    @abstractmethod
    async def Status(
        self,
        context: reboot.aio.contexts.ReaderContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.StatusRequest,
    ) -> reboot.memoize.v1.memoize_pb2.StatusResponse:
        raise NotImplementedError



############################ Clients ############################
# The main developer-facing entrypoints for any Reboot type. Relevant to both
# clients and servicers (who use it to find the right servicer base types, as well
# as often being clients themselves).

Memoize_ScheduleTypeVar = typing.TypeVar('Memoize_ScheduleTypeVar', 'Memoize.WeakReference._Schedule', 'Memoize.WeakReference._WriterSchedule')
Memoize_IdempotentlyScheduleTypeVar = typing.TypeVar('Memoize_IdempotentlyScheduleTypeVar', 'Memoize.WeakReference._Schedule', 'Memoize.WeakReference._WriterSchedule')

class Memoize:

    Servicer: typing.TypeAlias = MemoizeServicer

    Effects: typing.TypeAlias = MemoizeServicer.Effects

    Authorizer: typing.TypeAlias = MemoizeAuthorizer

    State: typing.TypeAlias = reboot.memoize.v1.memoize_pb2.Memoize

    __state_type_name__ = reboot.aio.types.StateTypeName("reboot.memoize.v1.Memoize")

    class ResetFuture:
        """Represents a future corresponding to a task running for the
        state. Note that this is not a coroutine because we are trying
        to convey the semantics that the task is already running (or
        will soon be) and thus we are just giving you a (distributed)
        future to it.
        """

        def __init__(
            self,
            context: reboot.aio.contexts.Context | reboot.aio.external.ExternalContext,
            *,
            task_id: tasks_pb2.TaskId,
        ) -> None:
            self._channel_manager = context.channel_manager
            self._task_id = task_id

        @property
        def task_id(self) -> tasks_pb2.TaskId:
            return self._task_id

        def __await__(self) -> typing.Generator[None, None, reboot.memoize.v1.memoize_pb2.ResetResponse]:
            """Awaits for task to finish and returns it's response."""

            async def wait_for_task() -> reboot.memoize.v1.memoize_pb2.ResetResponse:
                channel = self._channel_manager.get_channel_to_state(
                    self._task_id.state_type,
                    reboot.aio.types.StateRef(self._task_id.state_ref),
                )

                stub = tasks_pb2_grpc.TasksStub(channel)

                try:
                    wait_for_task_response = await stub.Wait(
                        tasks_pb2.WaitRequest(task_id=self._task_id),
                        metadata=reboot.aio.headers.Headers(
                            state_ref=reboot.aio.types.StateRef(self._task_id.state_ref),
                            # TODO(benh): will eventually be necessary to
                            # disambiguate between applications.
                            application_id=None,
                        ).to_grpc_metadata(),
                    )
                except grpc.aio.AioRpcError as error:
                    if error.code() == grpc.StatusCode.NOT_FOUND:
                        raise reboot.aio.aborted.SystemAborted(
                            rbt.v1alpha1.errors_pb2.UnknownTask()
                        ) from None

                    raise reboot.aio.aborted.SystemAborted.from_grpc_aio_rpc_error(
                        error
                    ) from None
                else:
                    response_or_error: typing.Optional[google.protobuf.message.Message] = None
                    is_error = False

                    if wait_for_task_response.response_or_error.WhichOneof("response_or_error") == "response":
                        response_or_error = wait_for_task_response.response_or_error.response
                    else:
                        is_error = True
                        response_or_error = wait_for_task_response.response_or_error.error

                    response = reboot.memoize.v1.memoize_pb2.ResetResponse()
                    if (
                        not is_error and response_or_error.TypeName() != response.DESCRIPTOR.full_name
                    ):
                        raise reboot.aio.aborted.SystemAborted(
                            rbt.v1alpha1.errors_pb2.InvalidArgument(),
                            message=
                            f"task with UUID {str(uuid.UUID(bytes=self._task_id.task_uuid))} "
                            f"has a response of type '{response_or_error.TypeName()}' "
                            "but expecting type 'reboot.memoize.v1.memoize_pb2.ResetResponse'; "
                            "are you waiting on a task of the correct method?",
                        ) from None

                    if is_error:
                        # Currently only cancelled error is supported.
                        raise asyncio.CancelledError("Task was cancelled by a TasksServicer")
                    else:
                        response_or_error.Unpack(response)
                        return response

            return wait_for_task().__await__()

    ResetEffects: typing.TypeAlias = Servicer.ResetEffects

    class ResetAborted(reboot.aio.aborted.Aborted):


        Error = typing.Union[
            reboot.aio.aborted.GrpcError,
            reboot.aio.aborted.RebootError,
        ]

        METHOD_ERROR_TYPES: list[type[Error]] = [
        ]

        ERROR_TYPES: list[type[Error]] = (
            METHOD_ERROR_TYPES +
            reboot.aio.aborted.GRPC_ERROR_TYPES +
            reboot.aio.aborted.REBOOT_ERROR_TYPES
        )

        _error: Error
        _code: grpc.StatusCode
        _message: typing.Optional[str]

        def __init__(
            self,
            error:  reboot.aio.aborted.GrpcError,
            *,
            message: typing.Optional[str] = None,
            # Do not set this value when constructing in order to
            # raise. This is only used internally when constructing
            # from aborted calls.
            error_types: list[type[Error]] = (
                METHOD_ERROR_TYPES + reboot.aio.aborted.GRPC_ERROR_TYPES
            ),
        ):
            super().__init__()

            assert_type(error, error_types)

            self._error = error

            code = self.grpc_status_code_from_error(self._error)

            if code is None:
                # Must be a Reboot specific or declared method error.
                code = grpc.StatusCode.ABORTED

            self._code = code

            self._message = message

        @property
        def error(self) -> Error:
            return self._error

        @property
        def code(self) -> grpc.StatusCode:
            return self._code

        @property
        def message(self) -> typing.Optional[str]:
            return self._message

        @classmethod
        def from_status(cls, status: status_pb2.Status):
            error = cls.error_from_google_rpc_status_details(
                status,
                cls.ERROR_TYPES,
            )

            message = status.message if len(status.message) > 0 else None

            if error is not None:
                return cls(error, message=message, error_types=cls.ERROR_TYPES)

            error = cls.error_from_google_rpc_status_code(status)

            assert error is not None

            # TODO(benh): also consider getting the type names from
            # `status.details` and including that in `message` to make
            # debugging easier.

            return cls(error, message=message)

        @classmethod
        def from_grpc_aio_rpc_error(cls, aio_rpc_error: grpc.aio.AioRpcError):
            return cls(
                cls.error_from_grpc_aio_rpc_error(aio_rpc_error),
                message=aio_rpc_error.details(),
            )

        @classmethod
        def is_declared_error(cls, message: google.protobuf.message.Message) -> bool:
            return False

    class StartFuture:
        """Represents a future corresponding to a task running for the
        state. Note that this is not a coroutine because we are trying
        to convey the semantics that the task is already running (or
        will soon be) and thus we are just giving you a (distributed)
        future to it.
        """

        def __init__(
            self,
            context: reboot.aio.contexts.Context | reboot.aio.external.ExternalContext,
            *,
            task_id: tasks_pb2.TaskId,
        ) -> None:
            self._channel_manager = context.channel_manager
            self._task_id = task_id

        @property
        def task_id(self) -> tasks_pb2.TaskId:
            return self._task_id

        def __await__(self) -> typing.Generator[None, None, reboot.memoize.v1.memoize_pb2.StartResponse]:
            """Awaits for task to finish and returns it's response."""

            async def wait_for_task() -> reboot.memoize.v1.memoize_pb2.StartResponse:
                channel = self._channel_manager.get_channel_to_state(
                    self._task_id.state_type,
                    reboot.aio.types.StateRef(self._task_id.state_ref),
                )

                stub = tasks_pb2_grpc.TasksStub(channel)

                try:
                    wait_for_task_response = await stub.Wait(
                        tasks_pb2.WaitRequest(task_id=self._task_id),
                        metadata=reboot.aio.headers.Headers(
                            state_ref=reboot.aio.types.StateRef(self._task_id.state_ref),
                            # TODO(benh): will eventually be necessary to
                            # disambiguate between applications.
                            application_id=None,
                        ).to_grpc_metadata(),
                    )
                except grpc.aio.AioRpcError as error:
                    if error.code() == grpc.StatusCode.NOT_FOUND:
                        raise reboot.aio.aborted.SystemAborted(
                            rbt.v1alpha1.errors_pb2.UnknownTask()
                        ) from None

                    raise reboot.aio.aborted.SystemAborted.from_grpc_aio_rpc_error(
                        error
                    ) from None
                else:
                    response_or_error: typing.Optional[google.protobuf.message.Message] = None
                    is_error = False

                    if wait_for_task_response.response_or_error.WhichOneof("response_or_error") == "response":
                        response_or_error = wait_for_task_response.response_or_error.response
                    else:
                        is_error = True
                        response_or_error = wait_for_task_response.response_or_error.error

                    response = reboot.memoize.v1.memoize_pb2.StartResponse()
                    if (
                        not is_error and response_or_error.TypeName() != response.DESCRIPTOR.full_name
                    ):
                        raise reboot.aio.aborted.SystemAborted(
                            rbt.v1alpha1.errors_pb2.InvalidArgument(),
                            message=
                            f"task with UUID {str(uuid.UUID(bytes=self._task_id.task_uuid))} "
                            f"has a response of type '{response_or_error.TypeName()}' "
                            "but expecting type 'reboot.memoize.v1.memoize_pb2.StartResponse'; "
                            "are you waiting on a task of the correct method?",
                        ) from None

                    if is_error:
                        # Currently only cancelled error is supported.
                        raise asyncio.CancelledError("Task was cancelled by a TasksServicer")
                    else:
                        response_or_error.Unpack(response)
                        return response

            return wait_for_task().__await__()

    StartEffects: typing.TypeAlias = Servicer.StartEffects

    class StartAborted(reboot.aio.aborted.Aborted):


        Error = typing.Union[
            reboot.aio.aborted.GrpcError,
            reboot.aio.aborted.RebootError,
        ]

        METHOD_ERROR_TYPES: list[type[Error]] = [
        ]

        ERROR_TYPES: list[type[Error]] = (
            METHOD_ERROR_TYPES +
            reboot.aio.aborted.GRPC_ERROR_TYPES +
            reboot.aio.aborted.REBOOT_ERROR_TYPES
        )

        _error: Error
        _code: grpc.StatusCode
        _message: typing.Optional[str]

        def __init__(
            self,
            error:  reboot.aio.aborted.GrpcError,
            *,
            message: typing.Optional[str] = None,
            # Do not set this value when constructing in order to
            # raise. This is only used internally when constructing
            # from aborted calls.
            error_types: list[type[Error]] = (
                METHOD_ERROR_TYPES + reboot.aio.aborted.GRPC_ERROR_TYPES
            ),
        ):
            super().__init__()

            assert_type(error, error_types)

            self._error = error

            code = self.grpc_status_code_from_error(self._error)

            if code is None:
                # Must be a Reboot specific or declared method error.
                code = grpc.StatusCode.ABORTED

            self._code = code

            self._message = message

        @property
        def error(self) -> Error:
            return self._error

        @property
        def code(self) -> grpc.StatusCode:
            return self._code

        @property
        def message(self) -> typing.Optional[str]:
            return self._message

        @classmethod
        def from_status(cls, status: status_pb2.Status):
            error = cls.error_from_google_rpc_status_details(
                status,
                cls.ERROR_TYPES,
            )

            message = status.message if len(status.message) > 0 else None

            if error is not None:
                return cls(error, message=message, error_types=cls.ERROR_TYPES)

            error = cls.error_from_google_rpc_status_code(status)

            assert error is not None

            # TODO(benh): also consider getting the type names from
            # `status.details` and including that in `message` to make
            # debugging easier.

            return cls(error, message=message)

        @classmethod
        def from_grpc_aio_rpc_error(cls, aio_rpc_error: grpc.aio.AioRpcError):
            return cls(
                cls.error_from_grpc_aio_rpc_error(aio_rpc_error),
                message=aio_rpc_error.details(),
            )

        @classmethod
        def is_declared_error(cls, message: google.protobuf.message.Message) -> bool:
            return False

    class StoreFuture:
        """Represents a future corresponding to a task running for the
        state. Note that this is not a coroutine because we are trying
        to convey the semantics that the task is already running (or
        will soon be) and thus we are just giving you a (distributed)
        future to it.
        """

        def __init__(
            self,
            context: reboot.aio.contexts.Context | reboot.aio.external.ExternalContext,
            *,
            task_id: tasks_pb2.TaskId,
        ) -> None:
            self._channel_manager = context.channel_manager
            self._task_id = task_id

        @property
        def task_id(self) -> tasks_pb2.TaskId:
            return self._task_id

        def __await__(self) -> typing.Generator[None, None, reboot.memoize.v1.memoize_pb2.StoreResponse]:
            """Awaits for task to finish and returns it's response."""

            async def wait_for_task() -> reboot.memoize.v1.memoize_pb2.StoreResponse:
                channel = self._channel_manager.get_channel_to_state(
                    self._task_id.state_type,
                    reboot.aio.types.StateRef(self._task_id.state_ref),
                )

                stub = tasks_pb2_grpc.TasksStub(channel)

                try:
                    wait_for_task_response = await stub.Wait(
                        tasks_pb2.WaitRequest(task_id=self._task_id),
                        metadata=reboot.aio.headers.Headers(
                            state_ref=reboot.aio.types.StateRef(self._task_id.state_ref),
                            # TODO(benh): will eventually be necessary to
                            # disambiguate between applications.
                            application_id=None,
                        ).to_grpc_metadata(),
                    )
                except grpc.aio.AioRpcError as error:
                    if error.code() == grpc.StatusCode.NOT_FOUND:
                        raise reboot.aio.aborted.SystemAborted(
                            rbt.v1alpha1.errors_pb2.UnknownTask()
                        ) from None

                    raise reboot.aio.aborted.SystemAborted.from_grpc_aio_rpc_error(
                        error
                    ) from None
                else:
                    response_or_error: typing.Optional[google.protobuf.message.Message] = None
                    is_error = False

                    if wait_for_task_response.response_or_error.WhichOneof("response_or_error") == "response":
                        response_or_error = wait_for_task_response.response_or_error.response
                    else:
                        is_error = True
                        response_or_error = wait_for_task_response.response_or_error.error

                    response = reboot.memoize.v1.memoize_pb2.StoreResponse()
                    if (
                        not is_error and response_or_error.TypeName() != response.DESCRIPTOR.full_name
                    ):
                        raise reboot.aio.aborted.SystemAborted(
                            rbt.v1alpha1.errors_pb2.InvalidArgument(),
                            message=
                            f"task with UUID {str(uuid.UUID(bytes=self._task_id.task_uuid))} "
                            f"has a response of type '{response_or_error.TypeName()}' "
                            "but expecting type 'reboot.memoize.v1.memoize_pb2.StoreResponse'; "
                            "are you waiting on a task of the correct method?",
                        ) from None

                    if is_error:
                        # Currently only cancelled error is supported.
                        raise asyncio.CancelledError("Task was cancelled by a TasksServicer")
                    else:
                        response_or_error.Unpack(response)
                        return response

            return wait_for_task().__await__()

    StoreEffects: typing.TypeAlias = Servicer.StoreEffects

    class StoreAborted(reboot.aio.aborted.Aborted):


        Error = typing.Union[
            reboot.aio.aborted.GrpcError,
            reboot.aio.aborted.RebootError,
        ]

        METHOD_ERROR_TYPES: list[type[Error]] = [
        ]

        ERROR_TYPES: list[type[Error]] = (
            METHOD_ERROR_TYPES +
            reboot.aio.aborted.GRPC_ERROR_TYPES +
            reboot.aio.aborted.REBOOT_ERROR_TYPES
        )

        _error: Error
        _code: grpc.StatusCode
        _message: typing.Optional[str]

        def __init__(
            self,
            error:  reboot.aio.aborted.GrpcError,
            *,
            message: typing.Optional[str] = None,
            # Do not set this value when constructing in order to
            # raise. This is only used internally when constructing
            # from aborted calls.
            error_types: list[type[Error]] = (
                METHOD_ERROR_TYPES + reboot.aio.aborted.GRPC_ERROR_TYPES
            ),
        ):
            super().__init__()

            assert_type(error, error_types)

            self._error = error

            code = self.grpc_status_code_from_error(self._error)

            if code is None:
                # Must be a Reboot specific or declared method error.
                code = grpc.StatusCode.ABORTED

            self._code = code

            self._message = message

        @property
        def error(self) -> Error:
            return self._error

        @property
        def code(self) -> grpc.StatusCode:
            return self._code

        @property
        def message(self) -> typing.Optional[str]:
            return self._message

        @classmethod
        def from_status(cls, status: status_pb2.Status):
            error = cls.error_from_google_rpc_status_details(
                status,
                cls.ERROR_TYPES,
            )

            message = status.message if len(status.message) > 0 else None

            if error is not None:
                return cls(error, message=message, error_types=cls.ERROR_TYPES)

            error = cls.error_from_google_rpc_status_code(status)

            assert error is not None

            # TODO(benh): also consider getting the type names from
            # `status.details` and including that in `message` to make
            # debugging easier.

            return cls(error, message=message)

        @classmethod
        def from_grpc_aio_rpc_error(cls, aio_rpc_error: grpc.aio.AioRpcError):
            return cls(
                cls.error_from_grpc_aio_rpc_error(aio_rpc_error),
                message=aio_rpc_error.details(),
            )

        @classmethod
        def is_declared_error(cls, message: google.protobuf.message.Message) -> bool:
            return False

    class FailFuture:
        """Represents a future corresponding to a task running for the
        state. Note that this is not a coroutine because we are trying
        to convey the semantics that the task is already running (or
        will soon be) and thus we are just giving you a (distributed)
        future to it.
        """

        def __init__(
            self,
            context: reboot.aio.contexts.Context | reboot.aio.external.ExternalContext,
            *,
            task_id: tasks_pb2.TaskId,
        ) -> None:
            self._channel_manager = context.channel_manager
            self._task_id = task_id

        @property
        def task_id(self) -> tasks_pb2.TaskId:
            return self._task_id

        def __await__(self) -> typing.Generator[None, None, reboot.memoize.v1.memoize_pb2.FailResponse]:
            """Awaits for task to finish and returns it's response."""

            async def wait_for_task() -> reboot.memoize.v1.memoize_pb2.FailResponse:
                channel = self._channel_manager.get_channel_to_state(
                    self._task_id.state_type,
                    reboot.aio.types.StateRef(self._task_id.state_ref),
                )

                stub = tasks_pb2_grpc.TasksStub(channel)

                try:
                    wait_for_task_response = await stub.Wait(
                        tasks_pb2.WaitRequest(task_id=self._task_id),
                        metadata=reboot.aio.headers.Headers(
                            state_ref=reboot.aio.types.StateRef(self._task_id.state_ref),
                            # TODO(benh): will eventually be necessary to
                            # disambiguate between applications.
                            application_id=None,
                        ).to_grpc_metadata(),
                    )
                except grpc.aio.AioRpcError as error:
                    if error.code() == grpc.StatusCode.NOT_FOUND:
                        raise reboot.aio.aborted.SystemAborted(
                            rbt.v1alpha1.errors_pb2.UnknownTask()
                        ) from None

                    raise reboot.aio.aborted.SystemAborted.from_grpc_aio_rpc_error(
                        error
                    ) from None
                else:
                    response_or_error: typing.Optional[google.protobuf.message.Message] = None
                    is_error = False

                    if wait_for_task_response.response_or_error.WhichOneof("response_or_error") == "response":
                        response_or_error = wait_for_task_response.response_or_error.response
                    else:
                        is_error = True
                        response_or_error = wait_for_task_response.response_or_error.error

                    response = reboot.memoize.v1.memoize_pb2.FailResponse()
                    if (
                        not is_error and response_or_error.TypeName() != response.DESCRIPTOR.full_name
                    ):
                        raise reboot.aio.aborted.SystemAborted(
                            rbt.v1alpha1.errors_pb2.InvalidArgument(),
                            message=
                            f"task with UUID {str(uuid.UUID(bytes=self._task_id.task_uuid))} "
                            f"has a response of type '{response_or_error.TypeName()}' "
                            "but expecting type 'reboot.memoize.v1.memoize_pb2.FailResponse'; "
                            "are you waiting on a task of the correct method?",
                        ) from None

                    if is_error:
                        # Currently only cancelled error is supported.
                        raise asyncio.CancelledError("Task was cancelled by a TasksServicer")
                    else:
                        response_or_error.Unpack(response)
                        return response

            return wait_for_task().__await__()

    FailEffects: typing.TypeAlias = Servicer.FailEffects

    class FailAborted(reboot.aio.aborted.Aborted):


        Error = typing.Union[
            reboot.aio.aborted.GrpcError,
            reboot.aio.aborted.RebootError,
        ]

        METHOD_ERROR_TYPES: list[type[Error]] = [
        ]

        ERROR_TYPES: list[type[Error]] = (
            METHOD_ERROR_TYPES +
            reboot.aio.aborted.GRPC_ERROR_TYPES +
            reboot.aio.aborted.REBOOT_ERROR_TYPES
        )

        _error: Error
        _code: grpc.StatusCode
        _message: typing.Optional[str]

        def __init__(
            self,
            error:  reboot.aio.aborted.GrpcError,
            *,
            message: typing.Optional[str] = None,
            # Do not set this value when constructing in order to
            # raise. This is only used internally when constructing
            # from aborted calls.
            error_types: list[type[Error]] = (
                METHOD_ERROR_TYPES + reboot.aio.aborted.GRPC_ERROR_TYPES
            ),
        ):
            super().__init__()

            assert_type(error, error_types)

            self._error = error

            code = self.grpc_status_code_from_error(self._error)

            if code is None:
                # Must be a Reboot specific or declared method error.
                code = grpc.StatusCode.ABORTED

            self._code = code

            self._message = message

        @property
        def error(self) -> Error:
            return self._error

        @property
        def code(self) -> grpc.StatusCode:
            return self._code

        @property
        def message(self) -> typing.Optional[str]:
            return self._message

        @classmethod
        def from_status(cls, status: status_pb2.Status):
            error = cls.error_from_google_rpc_status_details(
                status,
                cls.ERROR_TYPES,
            )

            message = status.message if len(status.message) > 0 else None

            if error is not None:
                return cls(error, message=message, error_types=cls.ERROR_TYPES)

            error = cls.error_from_google_rpc_status_code(status)

            assert error is not None

            # TODO(benh): also consider getting the type names from
            # `status.details` and including that in `message` to make
            # debugging easier.

            return cls(error, message=message)

        @classmethod
        def from_grpc_aio_rpc_error(cls, aio_rpc_error: grpc.aio.AioRpcError):
            return cls(
                cls.error_from_grpc_aio_rpc_error(aio_rpc_error),
                message=aio_rpc_error.details(),
            )

        @classmethod
        def is_declared_error(cls, message: google.protobuf.message.Message) -> bool:
            return False

    class StatusFuture:
        """Represents a future corresponding to a task running for the
        state. Note that this is not a coroutine because we are trying
        to convey the semantics that the task is already running (or
        will soon be) and thus we are just giving you a (distributed)
        future to it.
        """

        def __init__(
            self,
            context: reboot.aio.contexts.Context | reboot.aio.external.ExternalContext,
            *,
            task_id: tasks_pb2.TaskId,
        ) -> None:
            self._channel_manager = context.channel_manager
            self._task_id = task_id

        @property
        def task_id(self) -> tasks_pb2.TaskId:
            return self._task_id

        def __await__(self) -> typing.Generator[None, None, reboot.memoize.v1.memoize_pb2.StatusResponse]:
            """Awaits for task to finish and returns it's response."""

            async def wait_for_task() -> reboot.memoize.v1.memoize_pb2.StatusResponse:
                channel = self._channel_manager.get_channel_to_state(
                    self._task_id.state_type,
                    reboot.aio.types.StateRef(self._task_id.state_ref),
                )

                stub = tasks_pb2_grpc.TasksStub(channel)

                try:
                    wait_for_task_response = await stub.Wait(
                        tasks_pb2.WaitRequest(task_id=self._task_id),
                        metadata=reboot.aio.headers.Headers(
                            state_ref=reboot.aio.types.StateRef(self._task_id.state_ref),
                            # TODO(benh): will eventually be necessary to
                            # disambiguate between applications.
                            application_id=None,
                        ).to_grpc_metadata(),
                    )
                except grpc.aio.AioRpcError as error:
                    if error.code() == grpc.StatusCode.NOT_FOUND:
                        raise reboot.aio.aborted.SystemAborted(
                            rbt.v1alpha1.errors_pb2.UnknownTask()
                        ) from None

                    raise reboot.aio.aborted.SystemAborted.from_grpc_aio_rpc_error(
                        error
                    ) from None
                else:
                    response_or_error: typing.Optional[google.protobuf.message.Message] = None
                    is_error = False

                    if wait_for_task_response.response_or_error.WhichOneof("response_or_error") == "response":
                        response_or_error = wait_for_task_response.response_or_error.response
                    else:
                        is_error = True
                        response_or_error = wait_for_task_response.response_or_error.error

                    response = reboot.memoize.v1.memoize_pb2.StatusResponse()
                    if (
                        not is_error and response_or_error.TypeName() != response.DESCRIPTOR.full_name
                    ):
                        raise reboot.aio.aborted.SystemAborted(
                            rbt.v1alpha1.errors_pb2.InvalidArgument(),
                            message=
                            f"task with UUID {str(uuid.UUID(bytes=self._task_id.task_uuid))} "
                            f"has a response of type '{response_or_error.TypeName()}' "
                            "but expecting type 'reboot.memoize.v1.memoize_pb2.StatusResponse'; "
                            "are you waiting on a task of the correct method?",
                        ) from None

                    if is_error:
                        # Currently only cancelled error is supported.
                        raise asyncio.CancelledError("Task was cancelled by a TasksServicer")
                    else:
                        response_or_error.Unpack(response)
                        return response

            return wait_for_task().__await__()


    class StatusAborted(reboot.aio.aborted.Aborted):


        Error = typing.Union[
            reboot.aio.aborted.GrpcError,
            reboot.aio.aborted.RebootError,
        ]

        METHOD_ERROR_TYPES: list[type[Error]] = [
        ]

        ERROR_TYPES: list[type[Error]] = (
            METHOD_ERROR_TYPES +
            reboot.aio.aborted.GRPC_ERROR_TYPES +
            reboot.aio.aborted.REBOOT_ERROR_TYPES
        )

        _error: Error
        _code: grpc.StatusCode
        _message: typing.Optional[str]

        def __init__(
            self,
            error:  reboot.aio.aborted.GrpcError,
            *,
            message: typing.Optional[str] = None,
            # Do not set this value when constructing in order to
            # raise. This is only used internally when constructing
            # from aborted calls.
            error_types: list[type[Error]] = (
                METHOD_ERROR_TYPES + reboot.aio.aborted.GRPC_ERROR_TYPES
            ),
        ):
            super().__init__()

            assert_type(error, error_types)

            self._error = error

            code = self.grpc_status_code_from_error(self._error)

            if code is None:
                # Must be a Reboot specific or declared method error.
                code = grpc.StatusCode.ABORTED

            self._code = code

            self._message = message

        @property
        def error(self) -> Error:
            return self._error

        @property
        def code(self) -> grpc.StatusCode:
            return self._code

        @property
        def message(self) -> typing.Optional[str]:
            return self._message

        @classmethod
        def from_status(cls, status: status_pb2.Status):
            error = cls.error_from_google_rpc_status_details(
                status,
                cls.ERROR_TYPES,
            )

            message = status.message if len(status.message) > 0 else None

            if error is not None:
                return cls(error, message=message, error_types=cls.ERROR_TYPES)

            error = cls.error_from_google_rpc_status_code(status)

            assert error is not None

            # TODO(benh): also consider getting the type names from
            # `status.details` and including that in `message` to make
            # debugging easier.

            return cls(error, message=message)

        @classmethod
        def from_grpc_aio_rpc_error(cls, aio_rpc_error: grpc.aio.AioRpcError):
            return cls(
                cls.error_from_grpc_aio_rpc_error(aio_rpc_error),
                message=aio_rpc_error.details(),
            )

        @classmethod
        def is_declared_error(cls, message: google.protobuf.message.Message) -> bool:
            return False


    class WeakReference(typing.Generic[Memoize_ScheduleTypeVar]):

        _schedule_type: type[Memoize_ScheduleTypeVar]

        def __init__(
            self,
            state_id: reboot.aio.types.StateId,
            *,
            schedule_type: type[Memoize_ScheduleTypeVar],
            bearer_token: typing.Optional[str] = None,
        ):
            self._state_ref = reboot.aio.types.StateRef.from_id(
              Memoize.__state_type_name__,
              state_id,
            )
            self._schedule_type = schedule_type
            self._idempotency_manager: typing.Optional[reboot.aio.idempotency.IdempotencyManager] = None
            self._reader_stub: typing.Optional[MemoizeReaderStub] = None
            self._writer_stub: typing.Optional[MemoizeWriterStub] = None
            self._workflow_stub: typing.Optional[MemoizeWorkflowStub] = None
            self._tasks_stub: typing.Optional[MemoizeTasksStub] = None
            self._bearer_token = bearer_token

        @property
        def state_id(self) -> reboot.aio.types.StateId:
            return self._state_ref.id

        def _reader(
            self,
            context: reboot.aio.contexts.ReaderContext | reboot.aio.contexts.WriterContext | reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        ) -> MemoizeReaderStub:
            if self._reader_stub is None:
                self._reader_stub = MemoizeReaderStub(
                    context=context,
                    state_ref=self._state_ref,
                    bearer_token=self._bearer_token,
                )
            assert self._reader_stub is not None
            if self._idempotency_manager is None:
                self._idempotency_manager = context
            elif self._idempotency_manager != context:
                raise reboot.aio.call.MixedContextsError(
                    "This `WeakReference` for `Memoize` with ID "
                    f"'{self.state_id}' has previously been used by a "
                    "different `Context`. That is not allowed. "
                    "Instead create a new `WeakReference` for every `Context` by calling "
                    f"`Memoize.lookup('{self.state_id}')`."
                )
            return self._reader_stub

        def _writer(
            self,
            context: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        ) -> MemoizeWriterStub:
            if self._writer_stub is None:
                self._writer_stub = MemoizeWriterStub(
                    context=context,
                    state_ref=self._state_ref,
                    bearer_token=self._bearer_token,
                )
            assert self._writer_stub is not None
            if self._idempotency_manager is None:
                self._idempotency_manager = context
            elif self._idempotency_manager != context:
                raise reboot.aio.call.MixedContextsError(
                    "This `WeakReference` for `Memoize` with ID "
                    f"'{self.state_id}' has previously been used by a "
                    "different `Context`. That is not allowed. "
                    "Instead create a new `WeakReference` for every `Context` by calling "
                    f"`Memoize.lookup('{self.state_id}')`."
                )
            return self._writer_stub

        def _workflow(
            self,
            context: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        ) -> MemoizeWorkflowStub:
            if self._workflow_stub is None:
                self._workflow_stub = MemoizeWorkflowStub(
                    context=context,
                    state_ref=self._state_ref,
                    bearer_token=self._bearer_token,
                )
            assert self._workflow_stub is not None
            if self._idempotency_manager is None:
                self._idempotency_manager = context
            elif self._idempotency_manager != context:
                raise reboot.aio.call.MixedContextsError(
                    "This `WeakReference` for `Memoize` with ID "
                    f"'{self.state_id}' has previously been used by a "
                    "different `Context`. That is not allowed. "
                    "Instead create a new `WeakReference` for every `Context` by calling "
                    f"`Memoize.lookup('{self.state_id}')`."
                )
            return self._workflow_stub

        def _tasks(
            self,
            context: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        ) -> MemoizeTasksStub:
            if self._tasks_stub is None:
                self._tasks_stub = MemoizeTasksStub(
                    context=context,
                    state_ref=self._state_ref,
                    bearer_token=self._bearer_token,
                )
            assert self._tasks_stub is not None
            if self._idempotency_manager is None:
                self._idempotency_manager = context
            elif self._idempotency_manager != context:
                raise reboot.aio.call.MixedContextsError(
                    "This `WeakReference` for `Memoize` with ID "
                    f"'{self.state_id}' has previously been used by a "
                    "different `Context`. That is not allowed. "
                    "Instead create a new `WeakReference` for every `Context` by calling "
                    f"`Memoize.lookup('{self.state_id}')`."
                )
            return self._tasks_stub

        class _Reactively:

            def __init__(
                self,
                *,
                state_ref: reboot.aio.types.StateRef,
                bearer_token: typing.Optional[str] = None,
            ):
                self._state_ref = state_ref
                self._bearer_token = bearer_token

            async def Status(
                self,
                context: reboot.aio.external.ExternalContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
            ) -> typing.AsyncIterator[reboot.memoize.v1.memoize_pb2.StatusResponse]:

                assert_type(context, [reboot.aio.external.ExternalContext])

                # TODO: mypy-protobuf declares that
                # `google.protobuf.message.Message` constructor arguments are
                # always non-None, when in reality they are optional.
                request = reboot.memoize.v1.memoize_pb2.StatusRequest(
                )

                metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
                bearer_token: typing.Optional[str] = None

                if __options__ is not None:
                    if __options__.metadata is not None:
                        metadata = __options__.metadata
                    if __options__.bearer_token is not None:
                        bearer_token = __options__.bearer_token

                if bearer_token is None:
                    bearer_token = self._bearer_token

                if metadata is None:
                    metadata = ()

                headers = reboot.aio.headers.Headers(
                    bearer_token=bearer_token,
                    state_ref=self._state_ref,
                    # TODO(benh): will eventually be necessary to
                    # disambiguate between applications.
                    application_id=None,
                )

                metadata += headers.to_grpc_metadata()

                query_backoff = reboot.aio.backoff.Backoff()
                while True:
                    try:
                        async with context.channel_manager.get_channel_to_state(
                            reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                            self._state_ref,
                        ) as channel:

                            call = rbt.v1alpha1.react_pb2_grpc.ReactStub(
                                channel
                            ).Query(
                                rbt.v1alpha1.react_pb2.QueryRequest(
                                    method='Status',
                                    request=request.SerializeToString(),
                                ),
                                metadata=metadata,
                            )

                            async for query_response in call:
                                # Clear the backoff so we don't wait
                                # as long the next time we get
                                # disconnected.
                                query_backoff.clear()

                                # The backend may have sent us this query
                                # response only to let us know that a new
                                # idempotency key has been recorded; there may
                                # not be a new response. Python callers don't
                                # (currently) care about such an event, so we
                                # simply ignore it.
                                if not query_response.HasField("response"):
                                    continue

                                response = reboot.memoize.v1.memoize_pb2.StatusResponse()
                                response.ParseFromString(query_response.response)
                                yield response

                    except BaseException as exception:
                        # We expect to get disconnected from the placement
                        # planner from time to time, e.g., when it is
                        # being updated, but we don't want that error to
                        # propagate, we just want to retry.
                        if reboot.aio.aborted.is_grpc_retryable_exception(exception):
                            await query_backoff()
                            continue
                        raise


        def reactively(self):
            return Memoize.WeakReference._Reactively(
                state_ref=self._state_ref,
                bearer_token=self._bearer_token,
            )

        class _Idempotently(typing.Generic[Memoize_IdempotentlyScheduleTypeVar]):

            _weak_reference: Memoize.WeakReference[Memoize_IdempotentlyScheduleTypeVar]

            def __init__(
                self,
                *,
                weak_reference: Memoize.WeakReference[Memoize_IdempotentlyScheduleTypeVar],
                idempotency: reboot.aio.idempotency.Idempotency,
            ):
                self._weak_reference = weak_reference
                self._idempotency = idempotency

            def schedule(
                self,
                *,
                when: typing.Optional[datetime | timedelta] = None,
            ) -> Memoize_IdempotentlyScheduleTypeVar:
                return self._weak_reference._schedule_type(
                    self._weak_reference._tasks,
                    when=when,
                    idempotency=self._idempotency,
                )

            async def Reset(
                self,
                __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: reboot.aio.call.Options = reboot.aio.call.Options(),
            ) -> reboot.memoize.v1.memoize_pb2.ResetResponse:
                if __options__.idempotency is not None:
                    raise RuntimeError(
                        'Found redundant idempotency in `Options`'
                    )

                __options__ = dataclasses.replace(
                    __options__,
                    idempotency_key=self._idempotency.key,
                    idempotency_alias=self._idempotency.alias,
                    generate_idempotency=self._idempotency.generate,
                )

                return await self._weak_reference.Reset(
                    __context__,
                    __options__,
                )

            async def Start(
                self,
                __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: reboot.aio.call.Options = reboot.aio.call.Options(),
            ) -> reboot.memoize.v1.memoize_pb2.StartResponse:
                if __options__.idempotency is not None:
                    raise RuntimeError(
                        'Found redundant idempotency in `Options`'
                    )

                __options__ = dataclasses.replace(
                    __options__,
                    idempotency_key=self._idempotency.key,
                    idempotency_alias=self._idempotency.alias,
                    generate_idempotency=self._idempotency.generate,
                )

                return await self._weak_reference.Start(
                    __context__,
                    __options__,
                )

            async def Store(
                self,
                __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: reboot.aio.call.Options = reboot.aio.call.Options(),
                *,
                data: typing.Optional[bytes] = None,
            ) -> reboot.memoize.v1.memoize_pb2.StoreResponse:
                if __options__.idempotency is not None:
                    raise RuntimeError(
                        'Found redundant idempotency in `Options`'
                    )

                __options__ = dataclasses.replace(
                    __options__,
                    idempotency_key=self._idempotency.key,
                    idempotency_alias=self._idempotency.alias,
                    generate_idempotency=self._idempotency.generate,
                )

                return await self._weak_reference.Store(
                    __context__,
                    __options__,
                    data=data,
                )

            async def Fail(
                self,
                __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: reboot.aio.call.Options = reboot.aio.call.Options(),
                *,
                failure: typing.Optional[str] = None,
            ) -> reboot.memoize.v1.memoize_pb2.FailResponse:
                if __options__.idempotency is not None:
                    raise RuntimeError(
                        'Found redundant idempotency in `Options`'
                    )

                __options__ = dataclasses.replace(
                    __options__,
                    idempotency_key=self._idempotency.key,
                    idempotency_alias=self._idempotency.alias,
                    generate_idempotency=self._idempotency.generate,
                )

                return await self._weak_reference.Fail(
                    __context__,
                    __options__,
                    failure=failure,
                )


        def idempotently(
            self,
            alias: typing.Optional[str] = None,
            *,
            key: typing.Optional[uuid.UUID] = None,
            each_iteration: typing.Optional[bool] = None,
        ) -> Memoize.WeakReference._Idempotently[Memoize_ScheduleTypeVar]:
            return Memoize.WeakReference._Idempotently(
                weak_reference=self,
                idempotency=reboot.aio.contexts.Context.idempotency(
                    key=key, alias=alias, each_iteration=each_iteration
                )
            )

        def unidempotently(self):
            return self.idempotently(key=uuid.uuid4())

        def schedule(
            self,
            *,
            when: typing.Optional[datetime | timedelta] = None,
        ) -> Memoize_ScheduleTypeVar:
            return self._schedule_type(self._tasks, when=when)

        class _Schedule:

            def __init__(
                self,
                tasks: typing.Callable[[reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext], MemoizeTasksStub],
                *,
                when: typing.Optional[datetime | timedelta] = None,
                idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
            ) -> None:
                self._tasks = tasks
                self._when = when
                self._idempotency = idempotency

            # Memoize callable tasks:
            @typing.overload
            async def Reset(
                self,
                __context__: reboot.aio.contexts.TransactionContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
            ) -> reboot.aio.tasks.TaskEffect:
                ...

            @typing.overload
            async def Reset(
                self,
                __context__: reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
            ) -> Memoize.ResetFuture:
                ...

            async def Reset(
                self,
                __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
            ) -> reboot.aio.tasks.TaskEffect | Memoize.ResetFuture:
                # TODO: mypy-protobuf declares that
                # `google.protobuf.message.Message` constructor arguments are
                # always non-None, when in reality they are optional.
                request = reboot.memoize.v1.memoize_pb2.ResetRequest(
                )

                schedule: typing.Optional[datetime] = (datetime.now() + self._when) if isinstance(
                    self._when, timedelta
                ) else self._when

                metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
                idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = self._idempotency
                bearer_token: typing.Optional[str] = None

                if __options__ is not None:
                    if __options__.idempotency:
                        if idempotency is not None:
                            raise RuntimeError(
                                'Found redundant idempotency in `Options`'
                            )
                        idempotency = __options__.idempotency
                    if __options__.metadata is not None:
                        metadata = __options__.metadata
                    if __options__.bearer_token is not None:
                        bearer_token = __options__.bearer_token

                # Add scheduling information to the metadata.
                metadata = (
                    (reboot.aio.headers.TASK_SCHEDULE,
                    schedule.isoformat() if schedule else ''),
                ) + (metadata or tuple())

                task_id = await self._tasks(
                    __context__
                ).Reset(
                    request,
                    idempotency=idempotency,
                    metadata=metadata,
                    bearer_token=bearer_token,
                )

                if isinstance(__context__, reboot.aio.contexts.TransactionContext):
                    return reboot.aio.tasks.TaskEffect(
                        state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                        state_ref=__context__._state_ref,
                        method_name='Reset',
                        request=request,
                        task_uuid=task_id.task_uuid,
                        schedule=schedule,
                    )

                return Memoize.ResetFuture(
                    __context__,
                    task_id=task_id,
                )

            @typing.overload
            async def Start(
                self,
                __context__: reboot.aio.contexts.TransactionContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
            ) -> reboot.aio.tasks.TaskEffect:
                ...

            @typing.overload
            async def Start(
                self,
                __context__: reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
            ) -> Memoize.StartFuture:
                ...

            async def Start(
                self,
                __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
            ) -> reboot.aio.tasks.TaskEffect | Memoize.StartFuture:
                # TODO: mypy-protobuf declares that
                # `google.protobuf.message.Message` constructor arguments are
                # always non-None, when in reality they are optional.
                request = reboot.memoize.v1.memoize_pb2.StartRequest(
                )

                schedule: typing.Optional[datetime] = (datetime.now() + self._when) if isinstance(
                    self._when, timedelta
                ) else self._when

                metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
                idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = self._idempotency
                bearer_token: typing.Optional[str] = None

                if __options__ is not None:
                    if __options__.idempotency:
                        if idempotency is not None:
                            raise RuntimeError(
                                'Found redundant idempotency in `Options`'
                            )
                        idempotency = __options__.idempotency
                    if __options__.metadata is not None:
                        metadata = __options__.metadata
                    if __options__.bearer_token is not None:
                        bearer_token = __options__.bearer_token

                # Add scheduling information to the metadata.
                metadata = (
                    (reboot.aio.headers.TASK_SCHEDULE,
                    schedule.isoformat() if schedule else ''),
                ) + (metadata or tuple())

                task_id = await self._tasks(
                    __context__
                ).Start(
                    request,
                    idempotency=idempotency,
                    metadata=metadata,
                    bearer_token=bearer_token,
                )

                if isinstance(__context__, reboot.aio.contexts.TransactionContext):
                    return reboot.aio.tasks.TaskEffect(
                        state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                        state_ref=__context__._state_ref,
                        method_name='Start',
                        request=request,
                        task_uuid=task_id.task_uuid,
                        schedule=schedule,
                    )

                return Memoize.StartFuture(
                    __context__,
                    task_id=task_id,
                )

            @typing.overload
            async def Store(
                self,
                __context__: reboot.aio.contexts.TransactionContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
                *,
                data: typing.Optional[bytes] = None,
            ) -> reboot.aio.tasks.TaskEffect:
                ...

            @typing.overload
            async def Store(
                self,
                __context__: reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
                *,
                data: typing.Optional[bytes] = None,
            ) -> Memoize.StoreFuture:
                ...

            async def Store(
                self,
                __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
                *,
                data: typing.Optional[bytes] = None,
            ) -> reboot.aio.tasks.TaskEffect | Memoize.StoreFuture:
                if data is not None and not isinstance(
                    data,
                    bytes,
                ):
                    raise TypeError(
                        f"Can not construct protobuf message of type "
                        f"'reboot.memoize.v1.memoize_pb2.StoreRequest': field 'data' is not "
                        f"of required type 'bytes'"
                    )
                # TODO: mypy-protobuf declares that
                # `google.protobuf.message.Message` constructor arguments are
                # always non-None, when in reality they are optional.
                request = reboot.memoize.v1.memoize_pb2.StoreRequest(
                    data=data,  # type: ignore[arg-type]
                )

                schedule: typing.Optional[datetime] = (datetime.now() + self._when) if isinstance(
                    self._when, timedelta
                ) else self._when

                metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
                idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = self._idempotency
                bearer_token: typing.Optional[str] = None

                if __options__ is not None:
                    if __options__.idempotency:
                        if idempotency is not None:
                            raise RuntimeError(
                                'Found redundant idempotency in `Options`'
                            )
                        idempotency = __options__.idempotency
                    if __options__.metadata is not None:
                        metadata = __options__.metadata
                    if __options__.bearer_token is not None:
                        bearer_token = __options__.bearer_token

                # Add scheduling information to the metadata.
                metadata = (
                    (reboot.aio.headers.TASK_SCHEDULE,
                    schedule.isoformat() if schedule else ''),
                ) + (metadata or tuple())

                task_id = await self._tasks(
                    __context__
                ).Store(
                    request,
                    idempotency=idempotency,
                    metadata=metadata,
                    bearer_token=bearer_token,
                )

                if isinstance(__context__, reboot.aio.contexts.TransactionContext):
                    return reboot.aio.tasks.TaskEffect(
                        state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                        state_ref=__context__._state_ref,
                        method_name='Store',
                        request=request,
                        task_uuid=task_id.task_uuid,
                        schedule=schedule,
                    )

                return Memoize.StoreFuture(
                    __context__,
                    task_id=task_id,
                )

            @typing.overload
            async def Fail(
                self,
                __context__: reboot.aio.contexts.TransactionContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
                *,
                failure: typing.Optional[str] = None,
            ) -> reboot.aio.tasks.TaskEffect:
                ...

            @typing.overload
            async def Fail(
                self,
                __context__: reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
                *,
                failure: typing.Optional[str] = None,
            ) -> Memoize.FailFuture:
                ...

            async def Fail(
                self,
                __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
                *,
                failure: typing.Optional[str] = None,
            ) -> reboot.aio.tasks.TaskEffect | Memoize.FailFuture:
                if failure is not None and not isinstance(
                    failure,
                    str,
                ):
                    raise TypeError(
                        f"Can not construct protobuf message of type "
                        f"'reboot.memoize.v1.memoize_pb2.FailRequest': field 'failure' is not "
                        f"of required type 'str'"
                    )
                # TODO: mypy-protobuf declares that
                # `google.protobuf.message.Message` constructor arguments are
                # always non-None, when in reality they are optional.
                request = reboot.memoize.v1.memoize_pb2.FailRequest(
                    failure=failure,  # type: ignore[arg-type]
                )

                schedule: typing.Optional[datetime] = (datetime.now() + self._when) if isinstance(
                    self._when, timedelta
                ) else self._when

                metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
                idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = self._idempotency
                bearer_token: typing.Optional[str] = None

                if __options__ is not None:
                    if __options__.idempotency:
                        if idempotency is not None:
                            raise RuntimeError(
                                'Found redundant idempotency in `Options`'
                            )
                        idempotency = __options__.idempotency
                    if __options__.metadata is not None:
                        metadata = __options__.metadata
                    if __options__.bearer_token is not None:
                        bearer_token = __options__.bearer_token

                # Add scheduling information to the metadata.
                metadata = (
                    (reboot.aio.headers.TASK_SCHEDULE,
                    schedule.isoformat() if schedule else ''),
                ) + (metadata or tuple())

                task_id = await self._tasks(
                    __context__
                ).Fail(
                    request,
                    idempotency=idempotency,
                    metadata=metadata,
                    bearer_token=bearer_token,
                )

                if isinstance(__context__, reboot.aio.contexts.TransactionContext):
                    return reboot.aio.tasks.TaskEffect(
                        state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                        state_ref=__context__._state_ref,
                        method_name='Fail',
                        request=request,
                        task_uuid=task_id.task_uuid,
                        schedule=schedule,
                    )

                return Memoize.FailFuture(
                    __context__,
                    task_id=task_id,
                )

            @typing.overload
            async def Status(
                self,
                __context__: reboot.aio.contexts.TransactionContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
            ) -> reboot.aio.tasks.TaskEffect:
                ...

            @typing.overload
            async def Status(
                self,
                __context__: reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
            ) -> Memoize.StatusFuture:
                ...

            async def Status(
                self,
                __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
            ) -> reboot.aio.tasks.TaskEffect | Memoize.StatusFuture:
                # TODO: mypy-protobuf declares that
                # `google.protobuf.message.Message` constructor arguments are
                # always non-None, when in reality they are optional.
                request = reboot.memoize.v1.memoize_pb2.StatusRequest(
                )

                schedule: typing.Optional[datetime] = (datetime.now() + self._when) if isinstance(
                    self._when, timedelta
                ) else self._when

                metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
                idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = self._idempotency
                bearer_token: typing.Optional[str] = None

                if __options__ is not None:
                    if __options__.idempotency:
                        if idempotency is not None:
                            raise RuntimeError(
                                'Found redundant idempotency in `Options`'
                            )
                        idempotency = __options__.idempotency
                    if __options__.metadata is not None:
                        metadata = __options__.metadata
                    if __options__.bearer_token is not None:
                        bearer_token = __options__.bearer_token

                # Add scheduling information to the metadata.
                metadata = (
                    (reboot.aio.headers.TASK_SCHEDULE,
                    schedule.isoformat() if schedule else ''),
                ) + (metadata or tuple())

                task_id = await self._tasks(
                    __context__
                ).Status(
                    request,
                    idempotency=idempotency,
                    metadata=metadata,
                    bearer_token=bearer_token,
                )

                if isinstance(__context__, reboot.aio.contexts.TransactionContext):
                    return reboot.aio.tasks.TaskEffect(
                        state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                        state_ref=__context__._state_ref,
                        method_name='Status',
                        request=request,
                        task_uuid=task_id.task_uuid,
                        schedule=schedule,
                    )

                return Memoize.StatusFuture(
                    __context__,
                    task_id=task_id,
                )


        class _WriterSchedule:

            def __init__(
                self,
                tasks: typing.Callable[[reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext], MemoizeTasksStub],
                *,
                when: typing.Optional[datetime | timedelta] = None,
                idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
            ) -> None:
                self._tasks = tasks
                self._when = when
                self._idempotency = idempotency

            # Memoize callable tasks:
            async def Reset(
                self,
                __context__: reboot.aio.contexts.WriterContext | reboot.aio.contexts.TransactionContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
            ) -> reboot.aio.tasks.TaskEffect:
                # TODO: mypy-protobuf declares that
                # `google.protobuf.message.Message` constructor arguments are
                # always non-None, when in reality they are optional.
                request = reboot.memoize.v1.memoize_pb2.ResetRequest(
                )
                if isinstance(__context__, reboot.aio.contexts.WriterContext):
                    return MemoizeServicerTasksStub(
                        context=__context__,
                        state_ref=__context__._state_ref,
                    ).Reset(
                        request,
                        schedule=self._when,
                    )

                schedule: typing.Optional[datetime] = (datetime.now() + self._when) if isinstance(
                    self._when, timedelta
                ) else self._when

                metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
                idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = self._idempotency
                bearer_token: typing.Optional[str] = None

                if __options__ is not None:
                    if __options__.idempotency is not None:
                        if idempotency is not None:
                            raise RuntimeError(
                                'Found redundant idempotency in `Options`'
                            )
                        idempotency = __options__.idempotency
                    if __options__.metadata is not None:
                        metadata = __options__.metadata
                    if __options__.bearer_token is not None:
                        bearer_token = __options__.bearer_token

                # Add scheduling information to the metadata.
                metadata = (
                    (reboot.aio.headers.TASK_SCHEDULE,
                    schedule.isoformat() if schedule else ''),
                ) + (metadata or tuple())

                task_id = await self._tasks(
                    __context__
                ).Reset(
                    request,
                    idempotency=idempotency,
                    metadata=metadata,
                    bearer_token=bearer_token,
                )

                return reboot.aio.tasks.TaskEffect(
                    state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    state_ref=__context__._state_ref,
                    method_name='Reset',
                    request=request,
                    task_uuid=task_id.task_uuid,
                    schedule=schedule,
                )

            async def Start(
                self,
                __context__: reboot.aio.contexts.WriterContext | reboot.aio.contexts.TransactionContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
            ) -> reboot.aio.tasks.TaskEffect:
                # TODO: mypy-protobuf declares that
                # `google.protobuf.message.Message` constructor arguments are
                # always non-None, when in reality they are optional.
                request = reboot.memoize.v1.memoize_pb2.StartRequest(
                )
                if isinstance(__context__, reboot.aio.contexts.WriterContext):
                    return MemoizeServicerTasksStub(
                        context=__context__,
                        state_ref=__context__._state_ref,
                    ).Start(
                        request,
                        schedule=self._when,
                    )

                schedule: typing.Optional[datetime] = (datetime.now() + self._when) if isinstance(
                    self._when, timedelta
                ) else self._when

                metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
                idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = self._idempotency
                bearer_token: typing.Optional[str] = None

                if __options__ is not None:
                    if __options__.idempotency is not None:
                        if idempotency is not None:
                            raise RuntimeError(
                                'Found redundant idempotency in `Options`'
                            )
                        idempotency = __options__.idempotency
                    if __options__.metadata is not None:
                        metadata = __options__.metadata
                    if __options__.bearer_token is not None:
                        bearer_token = __options__.bearer_token

                # Add scheduling information to the metadata.
                metadata = (
                    (reboot.aio.headers.TASK_SCHEDULE,
                    schedule.isoformat() if schedule else ''),
                ) + (metadata or tuple())

                task_id = await self._tasks(
                    __context__
                ).Start(
                    request,
                    idempotency=idempotency,
                    metadata=metadata,
                    bearer_token=bearer_token,
                )

                return reboot.aio.tasks.TaskEffect(
                    state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    state_ref=__context__._state_ref,
                    method_name='Start',
                    request=request,
                    task_uuid=task_id.task_uuid,
                    schedule=schedule,
                )

            async def Store(
                self,
                __context__: reboot.aio.contexts.WriterContext | reboot.aio.contexts.TransactionContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
                *,
                data: typing.Optional[bytes] = None,
            ) -> reboot.aio.tasks.TaskEffect:
                if data is not None and not isinstance(
                    data,
                    bytes,
                ):
                    raise TypeError(
                        f"Can not construct protobuf message of type "
                        f"'reboot.memoize.v1.memoize_pb2.StoreRequest': field 'data' is not "
                        f"of required type 'bytes'"
                    )
                # TODO: mypy-protobuf declares that
                # `google.protobuf.message.Message` constructor arguments are
                # always non-None, when in reality they are optional.
                request = reboot.memoize.v1.memoize_pb2.StoreRequest(
                    data=data,  # type: ignore[arg-type]
                )
                if isinstance(__context__, reboot.aio.contexts.WriterContext):
                    return MemoizeServicerTasksStub(
                        context=__context__,
                        state_ref=__context__._state_ref,
                    ).Store(
                        request,
                        schedule=self._when,
                    )

                schedule: typing.Optional[datetime] = (datetime.now() + self._when) if isinstance(
                    self._when, timedelta
                ) else self._when

                metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
                idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = self._idempotency
                bearer_token: typing.Optional[str] = None

                if __options__ is not None:
                    if __options__.idempotency is not None:
                        if idempotency is not None:
                            raise RuntimeError(
                                'Found redundant idempotency in `Options`'
                            )
                        idempotency = __options__.idempotency
                    if __options__.metadata is not None:
                        metadata = __options__.metadata
                    if __options__.bearer_token is not None:
                        bearer_token = __options__.bearer_token

                # Add scheduling information to the metadata.
                metadata = (
                    (reboot.aio.headers.TASK_SCHEDULE,
                    schedule.isoformat() if schedule else ''),
                ) + (metadata or tuple())

                task_id = await self._tasks(
                    __context__
                ).Store(
                    request,
                    idempotency=idempotency,
                    metadata=metadata,
                    bearer_token=bearer_token,
                )

                return reboot.aio.tasks.TaskEffect(
                    state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    state_ref=__context__._state_ref,
                    method_name='Store',
                    request=request,
                    task_uuid=task_id.task_uuid,
                    schedule=schedule,
                )

            async def Fail(
                self,
                __context__: reboot.aio.contexts.WriterContext | reboot.aio.contexts.TransactionContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
                *,
                failure: typing.Optional[str] = None,
            ) -> reboot.aio.tasks.TaskEffect:
                if failure is not None and not isinstance(
                    failure,
                    str,
                ):
                    raise TypeError(
                        f"Can not construct protobuf message of type "
                        f"'reboot.memoize.v1.memoize_pb2.FailRequest': field 'failure' is not "
                        f"of required type 'str'"
                    )
                # TODO: mypy-protobuf declares that
                # `google.protobuf.message.Message` constructor arguments are
                # always non-None, when in reality they are optional.
                request = reboot.memoize.v1.memoize_pb2.FailRequest(
                    failure=failure,  # type: ignore[arg-type]
                )
                if isinstance(__context__, reboot.aio.contexts.WriterContext):
                    return MemoizeServicerTasksStub(
                        context=__context__,
                        state_ref=__context__._state_ref,
                    ).Fail(
                        request,
                        schedule=self._when,
                    )

                schedule: typing.Optional[datetime] = (datetime.now() + self._when) if isinstance(
                    self._when, timedelta
                ) else self._when

                metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
                idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = self._idempotency
                bearer_token: typing.Optional[str] = None

                if __options__ is not None:
                    if __options__.idempotency is not None:
                        if idempotency is not None:
                            raise RuntimeError(
                                'Found redundant idempotency in `Options`'
                            )
                        idempotency = __options__.idempotency
                    if __options__.metadata is not None:
                        metadata = __options__.metadata
                    if __options__.bearer_token is not None:
                        bearer_token = __options__.bearer_token

                # Add scheduling information to the metadata.
                metadata = (
                    (reboot.aio.headers.TASK_SCHEDULE,
                    schedule.isoformat() if schedule else ''),
                ) + (metadata or tuple())

                task_id = await self._tasks(
                    __context__
                ).Fail(
                    request,
                    idempotency=idempotency,
                    metadata=metadata,
                    bearer_token=bearer_token,
                )

                return reboot.aio.tasks.TaskEffect(
                    state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    state_ref=__context__._state_ref,
                    method_name='Fail',
                    request=request,
                    task_uuid=task_id.task_uuid,
                    schedule=schedule,
                )

            async def Status(
                self,
                __context__: reboot.aio.contexts.WriterContext | reboot.aio.contexts.TransactionContext,
                __options__: typing.Optional[reboot.aio.call.Options] = None,
            ) -> reboot.aio.tasks.TaskEffect:
                # TODO: mypy-protobuf declares that
                # `google.protobuf.message.Message` constructor arguments are
                # always non-None, when in reality they are optional.
                request = reboot.memoize.v1.memoize_pb2.StatusRequest(
                )
                if isinstance(__context__, reboot.aio.contexts.WriterContext):
                    return MemoizeServicerTasksStub(
                        context=__context__,
                        state_ref=__context__._state_ref,
                    ).Status(
                        request,
                        schedule=self._when,
                    )

                schedule: typing.Optional[datetime] = (datetime.now() + self._when) if isinstance(
                    self._when, timedelta
                ) else self._when

                metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
                idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = self._idempotency
                bearer_token: typing.Optional[str] = None

                if __options__ is not None:
                    if __options__.idempotency is not None:
                        if idempotency is not None:
                            raise RuntimeError(
                                'Found redundant idempotency in `Options`'
                            )
                        idempotency = __options__.idempotency
                    if __options__.metadata is not None:
                        metadata = __options__.metadata
                    if __options__.bearer_token is not None:
                        bearer_token = __options__.bearer_token

                # Add scheduling information to the metadata.
                metadata = (
                    (reboot.aio.headers.TASK_SCHEDULE,
                    schedule.isoformat() if schedule else ''),
                ) + (metadata or tuple())

                task_id = await self._tasks(
                    __context__
                ).Status(
                    request,
                    idempotency=idempotency,
                    metadata=metadata,
                    bearer_token=bearer_token,
                )

                return reboot.aio.tasks.TaskEffect(
                    state_type=reboot.aio.types.StateTypeName('reboot.memoize.v1.Memoize'),
                    state_ref=__context__._state_ref,
                    method_name='Status',
                    request=request,
                    task_uuid=task_id.task_uuid,
                    schedule=schedule,
                )


        # Memoize specific methods:
        async def Reset(
            self,
            __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
            __options__: typing.Optional[reboot.aio.call.Options] = None,
        ) -> reboot.memoize.v1.memoize_pb2.ResetResponse:
            # TODO: mypy-protobuf declares that
            # `google.protobuf.message.Message` constructor arguments are
            # always non-None, when in reality they are optional.
            request = reboot.memoize.v1.memoize_pb2.ResetRequest(
            )
            idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None
            metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
            bearer_token: typing.Optional[str] = None
            if __options__ is not None:
                if __options__.idempotency is not None:
                    idempotency = __options__.idempotency
                if __options__.metadata is not None:
                    metadata = __options__.metadata
                if __options__.bearer_token is not None:
                    bearer_token = __options__.bearer_token

            return await self._writer(__context__).Reset(
                request,
                idempotency=idempotency,
                metadata=metadata,
                bearer_token=bearer_token,
            )

        async def Start(
            self,
            __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
            __options__: typing.Optional[reboot.aio.call.Options] = None,
        ) -> reboot.memoize.v1.memoize_pb2.StartResponse:
            # TODO: mypy-protobuf declares that
            # `google.protobuf.message.Message` constructor arguments are
            # always non-None, when in reality they are optional.
            request = reboot.memoize.v1.memoize_pb2.StartRequest(
            )
            idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None
            metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
            bearer_token: typing.Optional[str] = None
            if __options__ is not None:
                if __options__.idempotency is not None:
                    idempotency = __options__.idempotency
                if __options__.metadata is not None:
                    metadata = __options__.metadata
                if __options__.bearer_token is not None:
                    bearer_token = __options__.bearer_token

            return await self._writer(__context__).Start(
                request,
                idempotency=idempotency,
                metadata=metadata,
                bearer_token=bearer_token,
            )

        async def Store(
            self,
            __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
            __options__: typing.Optional[reboot.aio.call.Options] = None,
            *,
            data: typing.Optional[bytes] = None,
        ) -> reboot.memoize.v1.memoize_pb2.StoreResponse:
            if data is not None and not isinstance(
                data,
                bytes,
            ):
                raise TypeError(
                    f"Can not construct protobuf message of type "
                    f"'reboot.memoize.v1.memoize_pb2.StoreRequest': field 'data' is not "
                    f"of required type 'bytes'"
                )
            # TODO: mypy-protobuf declares that
            # `google.protobuf.message.Message` constructor arguments are
            # always non-None, when in reality they are optional.
            request = reboot.memoize.v1.memoize_pb2.StoreRequest(
                data=data,  # type: ignore[arg-type]
            )
            idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None
            metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
            bearer_token: typing.Optional[str] = None
            if __options__ is not None:
                if __options__.idempotency is not None:
                    idempotency = __options__.idempotency
                if __options__.metadata is not None:
                    metadata = __options__.metadata
                if __options__.bearer_token is not None:
                    bearer_token = __options__.bearer_token

            return await self._writer(__context__).Store(
                request,
                idempotency=idempotency,
                metadata=metadata,
                bearer_token=bearer_token,
            )

        async def Fail(
            self,
            __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
            __options__: typing.Optional[reboot.aio.call.Options] = None,
            *,
            failure: typing.Optional[str] = None,
        ) -> reboot.memoize.v1.memoize_pb2.FailResponse:
            if failure is not None and not isinstance(
                failure,
                str,
            ):
                raise TypeError(
                    f"Can not construct protobuf message of type "
                    f"'reboot.memoize.v1.memoize_pb2.FailRequest': field 'failure' is not "
                    f"of required type 'str'"
                )
            # TODO: mypy-protobuf declares that
            # `google.protobuf.message.Message` constructor arguments are
            # always non-None, when in reality they are optional.
            request = reboot.memoize.v1.memoize_pb2.FailRequest(
                failure=failure,  # type: ignore[arg-type]
            )
            idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None
            metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
            bearer_token: typing.Optional[str] = None
            if __options__ is not None:
                if __options__.idempotency is not None:
                    idempotency = __options__.idempotency
                if __options__.metadata is not None:
                    metadata = __options__.metadata
                if __options__.bearer_token is not None:
                    bearer_token = __options__.bearer_token

            return await self._writer(__context__).Fail(
                request,
                idempotency=idempotency,
                metadata=metadata,
                bearer_token=bearer_token,
            )

        async def Status(
            self,
            __context__: reboot.aio.contexts.ReaderContext | reboot.aio.contexts.WriterContext | reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
            __options__: typing.Optional[reboot.aio.call.Options] = None,
        ) -> reboot.memoize.v1.memoize_pb2.StatusResponse:
            # TODO: mypy-protobuf declares that
            # `google.protobuf.message.Message` constructor arguments are
            # always non-None, when in reality they are optional.
            request = reboot.memoize.v1.memoize_pb2.StatusRequest(
            )
            metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
            bearer_token: typing.Optional[str] = None
            if __options__ is not None:
                if __options__.metadata is not None:
                    metadata = __options__.metadata
                if __options__.bearer_token is not None:
                    bearer_token = __options__.bearer_token
            return await self._reader(__context__).Status(
                request,
                metadata=metadata,
                bearer_token=bearer_token,
            )

    @classmethod
    def lookup(
        cls,
        state_id: reboot.aio.types.StateId,
        *,
        bearer_token: typing.Optional[str] = None,
    ) -> Memoize.WeakReference[Memoize.WeakReference._Schedule]:
        return Memoize.WeakReference(
            state_id=state_id,
            schedule_type=Memoize.WeakReference._Schedule,
            bearer_token=bearer_token,
        )

    @classmethod
    async def _Reset(
        cls,
        *,
        __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        __options__: typing.Optional[reboot.aio.call.Options] = None,
        __state_id__: typing.Optional[reboot.aio.types.StateId] = None,
        __idempotency__: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
    ) -> tuple[Memoize.WeakReference, reboot.memoize.v1.memoize_pb2.ResetResponse]:
        # TODO: mypy-protobuf declares that
        # `google.protobuf.message.Message` constructor arguments are
        # always non-None, when in reality they are optional.
        request = reboot.memoize.v1.memoize_pb2.ResetRequest(
        )

        idempotency = __idempotency__

        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
        bearer_token: typing.Optional[str] = None

        if __options__ is not None:
            if __options__.idempotency is not None:
                if idempotency is not None:
                    raise RuntimeError(
                        'Found redundant idempotency in `Options`'
                    )
                idempotency = __options__.idempotency
            if __options__.metadata is not None:
                metadata = __options__.metadata
            if __options__.bearer_token is not None:
                bearer_token = __options__.bearer_token

        state_id = __state_id__

        if state_id is None:
            if idempotency is None:
                state_id = str(uuid.uuid4())
            else:
                state_id = __context__.generate_idempotent_state_id(
                    state_type_name=cls.__state_type_name__,
                    service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                    method='Reset',
                    idempotency=idempotency,
                )

        reference = Memoize.lookup(
            state_id, bearer_token=bearer_token
        )
        stub = reference._writer(__context__)
        return (
            reference,
            await stub.Reset(
                request,
                idempotency=idempotency,
                metadata=metadata,
                bearer_token=bearer_token,
            )
        )

    @classmethod
    async def _Start(
        cls,
        *,
        __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        __options__: typing.Optional[reboot.aio.call.Options] = None,
        __state_id__: typing.Optional[reboot.aio.types.StateId] = None,
        __idempotency__: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
    ) -> tuple[Memoize.WeakReference, reboot.memoize.v1.memoize_pb2.StartResponse]:
        # TODO: mypy-protobuf declares that
        # `google.protobuf.message.Message` constructor arguments are
        # always non-None, when in reality they are optional.
        request = reboot.memoize.v1.memoize_pb2.StartRequest(
        )

        idempotency = __idempotency__

        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
        bearer_token: typing.Optional[str] = None

        if __options__ is not None:
            if __options__.idempotency is not None:
                if idempotency is not None:
                    raise RuntimeError(
                        'Found redundant idempotency in `Options`'
                    )
                idempotency = __options__.idempotency
            if __options__.metadata is not None:
                metadata = __options__.metadata
            if __options__.bearer_token is not None:
                bearer_token = __options__.bearer_token

        state_id = __state_id__

        if state_id is None:
            if idempotency is None:
                state_id = str(uuid.uuid4())
            else:
                state_id = __context__.generate_idempotent_state_id(
                    state_type_name=cls.__state_type_name__,
                    service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                    method='Start',
                    idempotency=idempotency,
                )

        reference = Memoize.lookup(
            state_id, bearer_token=bearer_token
        )
        stub = reference._writer(__context__)
        return (
            reference,
            await stub.Start(
                request,
                idempotency=idempotency,
                metadata=metadata,
                bearer_token=bearer_token,
            )
        )

    @classmethod
    async def _Store(
        cls,
        *,
        __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        __options__: typing.Optional[reboot.aio.call.Options] = None,
        __state_id__: typing.Optional[reboot.aio.types.StateId] = None,
        __idempotency__: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        data: typing.Optional[bytes] = None,
    ) -> tuple[Memoize.WeakReference, reboot.memoize.v1.memoize_pb2.StoreResponse]:
        if data is not None and not isinstance(
            data,
            bytes,
        ):
            raise TypeError(
                f"Can not construct protobuf message of type "
                f"'reboot.memoize.v1.memoize_pb2.StoreRequest': field 'data' is not "
                f"of required type 'bytes'"
            )
        # TODO: mypy-protobuf declares that
        # `google.protobuf.message.Message` constructor arguments are
        # always non-None, when in reality they are optional.
        request = reboot.memoize.v1.memoize_pb2.StoreRequest(
            data=data,  # type: ignore[arg-type]
        )

        idempotency = __idempotency__

        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
        bearer_token: typing.Optional[str] = None

        if __options__ is not None:
            if __options__.idempotency is not None:
                if idempotency is not None:
                    raise RuntimeError(
                        'Found redundant idempotency in `Options`'
                    )
                idempotency = __options__.idempotency
            if __options__.metadata is not None:
                metadata = __options__.metadata
            if __options__.bearer_token is not None:
                bearer_token = __options__.bearer_token

        state_id = __state_id__

        if state_id is None:
            if idempotency is None:
                state_id = str(uuid.uuid4())
            else:
                state_id = __context__.generate_idempotent_state_id(
                    state_type_name=cls.__state_type_name__,
                    service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                    method='Store',
                    idempotency=idempotency,
                )

        reference = Memoize.lookup(
            state_id, bearer_token=bearer_token
        )
        stub = reference._writer(__context__)
        return (
            reference,
            await stub.Store(
                request,
                idempotency=idempotency,
                metadata=metadata,
                bearer_token=bearer_token,
            )
        )

    @classmethod
    async def _Fail(
        cls,
        *,
        __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        __options__: typing.Optional[reboot.aio.call.Options] = None,
        __state_id__: typing.Optional[reboot.aio.types.StateId] = None,
        __idempotency__: typing.Optional[reboot.aio.idempotency.Idempotency] = None,
        failure: typing.Optional[str] = None,
    ) -> tuple[Memoize.WeakReference, reboot.memoize.v1.memoize_pb2.FailResponse]:
        if failure is not None and not isinstance(
            failure,
            str,
        ):
            raise TypeError(
                f"Can not construct protobuf message of type "
                f"'reboot.memoize.v1.memoize_pb2.FailRequest': field 'failure' is not "
                f"of required type 'str'"
            )
        # TODO: mypy-protobuf declares that
        # `google.protobuf.message.Message` constructor arguments are
        # always non-None, when in reality they are optional.
        request = reboot.memoize.v1.memoize_pb2.FailRequest(
            failure=failure,  # type: ignore[arg-type]
        )

        idempotency = __idempotency__

        metadata: typing.Optional[reboot.aio.types.GrpcMetadata] = None
        bearer_token: typing.Optional[str] = None

        if __options__ is not None:
            if __options__.idempotency is not None:
                if idempotency is not None:
                    raise RuntimeError(
                        'Found redundant idempotency in `Options`'
                    )
                idempotency = __options__.idempotency
            if __options__.metadata is not None:
                metadata = __options__.metadata
            if __options__.bearer_token is not None:
                bearer_token = __options__.bearer_token

        state_id = __state_id__

        if state_id is None:
            if idempotency is None:
                state_id = str(uuid.uuid4())
            else:
                state_id = __context__.generate_idempotent_state_id(
                    state_type_name=cls.__state_type_name__,
                    service_name=reboot.aio.types.ServiceName('reboot.memoize.v1.MemoizeMethods'),
                    method='Fail',
                    idempotency=idempotency,
                )

        reference = Memoize.lookup(
            state_id, bearer_token=bearer_token
        )
        stub = reference._writer(__context__)
        return (
            reference,
            await stub.Fail(
                request,
                idempotency=idempotency,
                metadata=metadata,
                bearer_token=bearer_token,
            )
        )


    @dataclasses.dataclass(frozen=True)
    class _Construct:

        _state_id: typing.Optional[reboot.aio.types.StateId]
        _bearer_token: typing.Optional[str]

        def __post_init__(self) -> None:
            reboot.aio.call.validate_ascii(
                self._state_id,
                'state_id',
                MAX_ACTOR_ID_LENGTH,
                length_min=MIN_ACTOR_ID_LENGTH,
                error_type=reboot.aio.call.InvalidStateRefError,
                illegal_characters='\n\x00\x01',
            )

        async def Reset(
            self,
            __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
            __options__: typing.Optional[reboot.aio.call.Options] = None,
        ) -> tuple[Memoize.WeakReference, reboot.memoize.v1.memoize_pb2.ResetResponse]:
            if self._bearer_token:
                if __options__:
                    __options__ = dataclasses.replace(__options__, bearer_token=self._bearer_token)
                else:
                    __options__ = reboot.aio.call.Options(bearer_token=self._bearer_token)
            return await Memoize._Reset(
                __context__=__context__,
                __options__=__options__,
                __state_id__=self._state_id,
            )

        async def Start(
            self,
            __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
            __options__: typing.Optional[reboot.aio.call.Options] = None,
        ) -> tuple[Memoize.WeakReference, reboot.memoize.v1.memoize_pb2.StartResponse]:
            if self._bearer_token:
                if __options__:
                    __options__ = dataclasses.replace(__options__, bearer_token=self._bearer_token)
                else:
                    __options__ = reboot.aio.call.Options(bearer_token=self._bearer_token)
            return await Memoize._Start(
                __context__=__context__,
                __options__=__options__,
                __state_id__=self._state_id,
            )

        async def Store(
            self,
            __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
            __options__: typing.Optional[reboot.aio.call.Options] = None,
            *,
            data: typing.Optional[bytes] = None,
        ) -> tuple[Memoize.WeakReference, reboot.memoize.v1.memoize_pb2.StoreResponse]:
            if self._bearer_token:
                if __options__:
                    __options__ = dataclasses.replace(__options__, bearer_token=self._bearer_token)
                else:
                    __options__ = reboot.aio.call.Options(bearer_token=self._bearer_token)
            return await Memoize._Store(
                __context__=__context__,
                __options__=__options__,
                __state_id__=self._state_id,
                data=data,
            )

        async def Fail(
            self,
            __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
            __options__: typing.Optional[reboot.aio.call.Options] = None,
            *,
            failure: typing.Optional[str] = None,
        ) -> tuple[Memoize.WeakReference, reboot.memoize.v1.memoize_pb2.FailResponse]:
            if self._bearer_token:
                if __options__:
                    __options__ = dataclasses.replace(__options__, bearer_token=self._bearer_token)
                else:
                    __options__ = reboot.aio.call.Options(bearer_token=self._bearer_token)
            return await Memoize._Fail(
                __context__=__context__,
                __options__=__options__,
                __state_id__=self._state_id,
                failure=failure,
            )


        @typing.overload
        def idempotently(self, alias: typing.Optional[str] = None, *, each_iteration: bool = False) -> Memoize._ConstructIdempotently:
            ...

        @typing.overload
        def idempotently(self, *, key: uuid.UUID) -> Memoize._ConstructIdempotently:
            ...

        def idempotently(
            self,
            alias: typing.Optional[str] = None,
            *,
            key: typing.Optional[uuid.UUID] = None,
            each_iteration: typing.Optional[bool] = None,
        ) -> Memoize._ConstructIdempotently:
            return Memoize._ConstructIdempotently(
                _idempotency=reboot.aio.contexts.Context.idempotency(
                    alias=alias, key=key, each_iteration=each_iteration
                ),
                _state_id=self._state_id,
                _bearer_token=self._bearer_token,
            )

    @classmethod
    def construct(
        cls,
        *,
        id: typing.Optional[reboot.aio.types.StateId] = None,
        bearer_token: typing.Optional[str] = None,
    ) -> Memoize._Construct:
        return Memoize._Construct(
            _state_id=id,
            _bearer_token=bearer_token,
        )

    @dataclasses.dataclass(frozen=True)
    class _ConstructIdempotently:

        _idempotency: reboot.aio.idempotency.Idempotency
        _state_id: typing.Optional[reboot.aio.types.StateId] = None
        _bearer_token: typing.Optional[str] = None

        async def Reset(
            self,
            __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
            __options__: typing.Optional[reboot.aio.call.Options] = None,
        ) -> tuple[Memoize.WeakReference, reboot.memoize.v1.memoize_pb2.ResetResponse]:
            if self._bearer_token:
                if __options__:
                    __options__ = dataclasses.replace(__options__, bearer_token=self._bearer_token)
                else:
                    __options__ = reboot.aio.call.Options(bearer_token=self._bearer_token)
            return await Memoize._Reset(
                __context__=__context__,
                __options__=__options__,
                __state_id__=self._state_id,
                __idempotency__=self._idempotency,
            )

        async def Start(
            self,
            __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
            __options__: typing.Optional[reboot.aio.call.Options] = None,
        ) -> tuple[Memoize.WeakReference, reboot.memoize.v1.memoize_pb2.StartResponse]:
            if self._bearer_token:
                if __options__:
                    __options__ = dataclasses.replace(__options__, bearer_token=self._bearer_token)
                else:
                    __options__ = reboot.aio.call.Options(bearer_token=self._bearer_token)
            return await Memoize._Start(
                __context__=__context__,
                __options__=__options__,
                __state_id__=self._state_id,
                __idempotency__=self._idempotency,
            )

        async def Store(
            self,
            __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
            __options__: typing.Optional[reboot.aio.call.Options] = None,
            *,
            data: typing.Optional[bytes] = None,
        ) -> tuple[Memoize.WeakReference, reboot.memoize.v1.memoize_pb2.StoreResponse]:
            if self._bearer_token:
                if __options__:
                    __options__ = dataclasses.replace(__options__, bearer_token=self._bearer_token)
                else:
                    __options__ = reboot.aio.call.Options(bearer_token=self._bearer_token)
            return await Memoize._Store(
                __context__=__context__,
                __options__=__options__,
                __state_id__=self._state_id,
                __idempotency__=self._idempotency,
                data=data,
            )

        async def Fail(
            self,
            __context__: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
            __options__: typing.Optional[reboot.aio.call.Options] = None,
            *,
            failure: typing.Optional[str] = None,
        ) -> tuple[Memoize.WeakReference, reboot.memoize.v1.memoize_pb2.FailResponse]:
            if self._bearer_token:
                if __options__:
                    __options__ = dataclasses.replace(__options__, bearer_token=self._bearer_token)
                else:
                    __options__ = reboot.aio.call.Options(bearer_token=self._bearer_token)
            return await Memoize._Fail(
                __context__=__context__,
                __options__=__options__,
                __state_id__=self._state_id,
                __idempotency__=self._idempotency,
                failure=failure,
            )



############################ Servicer Node adapters ############################
# Used by Node.js servicer implementations to access Python code and vice-versa.
# Relevant to servicers, irrelevant to clients.

class MemoizeServicerNodeAdaptor(Memoize.Servicer):

    def __init__(self):
        self._js_servicer_reference = self._construct_js_servicer()  # type: ignore[attr-defined]

    def authorizer(self) -> typing.Optional[reboot.aio.auth.authorizers.Authorizer]:
        return self._construct_authorizer(self._js_servicer_reference)  # type: ignore[attr-defined]

    async def _read(self, context: reboot.aio.contexts.WorkflowContext) -> str:
        return google.protobuf.json_format.MessageToJson(
            await super().state.read(context)
        )

    async def _write(
        self,
        context: reboot.aio.contexts.WorkflowContext,
        writer: typing.Callable[[str], typing.Awaitable[str]],
        json_options: str,
    ) -> str:

        async def _writer(state: google.protobuf.message.Message):
            json_result_state = await writer(
                google.protobuf.json_format.MessageToJson(state)
            )

            result_state = json.loads(json_result_state)

            state.CopyFrom(
                google.protobuf.json_format.ParseDict(
                    result_state['state'],
                    self.__state_type__(),
                )
            )

            assert 'result' in result_state
            result = result_state['result']
            assert type(result) == str
            return result

        options = json.loads(json_options)

        assert 'idempotency' in options

        return await super().state.idempotently(
            alias=options['idempotency'].get('alias'),
            key=options['idempotency'].get('key'),
            each_iteration=options['idempotency'].get('eachIteration', None),
        )._write(
            context,
            _writer,
            type_result=str,
            check_type=True,
            unidempotently=options.get('unidempotently', False),
        )

    # Memoize specific methods:
    async def Reset(
        self,
        context: reboot.aio.contexts.WriterContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.ResetRequest,
    ) -> reboot.memoize.v1.memoize_pb2.ResetResponse:
        json_state = google.protobuf.json_format.MessageToJson(state)
        json_request = google.protobuf.json_format.MessageToJson(request)

        aborted: asyncio.Future[None] = asyncio.Future()

        try:
            json_result = await self._trampoline(  # type: ignore[attr-defined]
                self._js_servicer_reference,
                'writer',
                'Reset',
                context,
                aborted,
                json_state,
                json_request,
            )
        except asyncio.CancelledError:
            aborted.set_result(None)
            raise
        else:
            result = json.loads(json_result)

            if 'effects' in result:
                effects = result['effects']

                state.CopyFrom(
                    google.protobuf.json_format.ParseDict(
                        effects['state'],
                        reboot.memoize.v1.memoize_pb2.Memoize(),
                    )
                )

                assert not hasattr(effects, 'tasks'), "JS tasks not yet implemented"

                return google.protobuf.json_format.ParseDict(
                    effects['response'],
                    reboot.memoize.v1.memoize_pb2.ResetResponse(),
                )
            elif 'status' in result:
                raise (
                    Memoize
                    .ResetAborted
                    .from_status(
                        google.protobuf.json_format.ParseDict(
                            result['status'],
                            status_pb2.Status(),
                        )
                    )
                )

    async def Start(
        self,
        context: reboot.aio.contexts.WriterContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.StartRequest,
    ) -> reboot.memoize.v1.memoize_pb2.StartResponse:
        json_state = google.protobuf.json_format.MessageToJson(state)
        json_request = google.protobuf.json_format.MessageToJson(request)

        aborted: asyncio.Future[None] = asyncio.Future()

        try:
            json_result = await self._trampoline(  # type: ignore[attr-defined]
                self._js_servicer_reference,
                'writer',
                'Start',
                context,
                aborted,
                json_state,
                json_request,
            )
        except asyncio.CancelledError:
            aborted.set_result(None)
            raise
        else:
            result = json.loads(json_result)

            if 'effects' in result:
                effects = result['effects']

                state.CopyFrom(
                    google.protobuf.json_format.ParseDict(
                        effects['state'],
                        reboot.memoize.v1.memoize_pb2.Memoize(),
                    )
                )

                assert not hasattr(effects, 'tasks'), "JS tasks not yet implemented"

                return google.protobuf.json_format.ParseDict(
                    effects['response'],
                    reboot.memoize.v1.memoize_pb2.StartResponse(),
                )
            elif 'status' in result:
                raise (
                    Memoize
                    .StartAborted
                    .from_status(
                        google.protobuf.json_format.ParseDict(
                            result['status'],
                            status_pb2.Status(),
                        )
                    )
                )

    async def Store(
        self,
        context: reboot.aio.contexts.WriterContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.StoreRequest,
    ) -> reboot.memoize.v1.memoize_pb2.StoreResponse:
        json_state = google.protobuf.json_format.MessageToJson(state)
        json_request = google.protobuf.json_format.MessageToJson(request)

        aborted: asyncio.Future[None] = asyncio.Future()

        try:
            json_result = await self._trampoline(  # type: ignore[attr-defined]
                self._js_servicer_reference,
                'writer',
                'Store',
                context,
                aborted,
                json_state,
                json_request,
            )
        except asyncio.CancelledError:
            aborted.set_result(None)
            raise
        else:
            result = json.loads(json_result)

            if 'effects' in result:
                effects = result['effects']

                state.CopyFrom(
                    google.protobuf.json_format.ParseDict(
                        effects['state'],
                        reboot.memoize.v1.memoize_pb2.Memoize(),
                    )
                )

                assert not hasattr(effects, 'tasks'), "JS tasks not yet implemented"

                return google.protobuf.json_format.ParseDict(
                    effects['response'],
                    reboot.memoize.v1.memoize_pb2.StoreResponse(),
                )
            elif 'status' in result:
                raise (
                    Memoize
                    .StoreAborted
                    .from_status(
                        google.protobuf.json_format.ParseDict(
                            result['status'],
                            status_pb2.Status(),
                        )
                    )
                )

    async def Fail(
        self,
        context: reboot.aio.contexts.WriterContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.FailRequest,
    ) -> reboot.memoize.v1.memoize_pb2.FailResponse:
        json_state = google.protobuf.json_format.MessageToJson(state)
        json_request = google.protobuf.json_format.MessageToJson(request)

        aborted: asyncio.Future[None] = asyncio.Future()

        try:
            json_result = await self._trampoline(  # type: ignore[attr-defined]
                self._js_servicer_reference,
                'writer',
                'Fail',
                context,
                aborted,
                json_state,
                json_request,
            )
        except asyncio.CancelledError:
            aborted.set_result(None)
            raise
        else:
            result = json.loads(json_result)

            if 'effects' in result:
                effects = result['effects']

                state.CopyFrom(
                    google.protobuf.json_format.ParseDict(
                        effects['state'],
                        reboot.memoize.v1.memoize_pb2.Memoize(),
                    )
                )

                assert not hasattr(effects, 'tasks'), "JS tasks not yet implemented"

                return google.protobuf.json_format.ParseDict(
                    effects['response'],
                    reboot.memoize.v1.memoize_pb2.FailResponse(),
                )
            elif 'status' in result:
                raise (
                    Memoize
                    .FailAborted
                    .from_status(
                        google.protobuf.json_format.ParseDict(
                            result['status'],
                            status_pb2.Status(),
                        )
                    )
                )

    async def Status(
        self,
        context: reboot.aio.contexts.ReaderContext,
        state: reboot.memoize.v1.memoize_pb2.Memoize,
        request: reboot.memoize.v1.memoize_pb2.StatusRequest,
    ) -> reboot.memoize.v1.memoize_pb2.StatusResponse:
        json_state = google.protobuf.json_format.MessageToJson(state)
        json_request = google.protobuf.json_format.MessageToJson(request)

        aborted: asyncio.Future[None] = asyncio.Future()

        try:
            json_result = await self._trampoline(  # type: ignore[attr-defined]
                self._js_servicer_reference,
                'reader',
                'Status',
                context,
                aborted,
                json_state,
                json_request,
            )
        except asyncio.CancelledError:
            aborted.set_result(None)
            raise
        else:
            result = json.loads(json_result)

            if 'response' in result:
                return google.protobuf.json_format.ParseDict(
                    result['response'],
                    reboot.memoize.v1.memoize_pb2.StatusResponse(),
                )
            elif 'status' in result:
                raise (
                    Memoize
                    .StatusAborted
                    .from_status(
                        google.protobuf.json_format.ParseDict(
                            result['status'],
                            status_pb2.Status(),
                        )
                    )
                )



############################ Reference Node adapters ############################
# Used by Node.js WeakReference implementations to access Python code and
# vice-versa. Relevant to clients.

class MemoizeWeakReferenceNodeAdaptor(Memoize.WeakReference[Memoize.WeakReference._Schedule]):

    async def _call(  # type: ignore[override]
        self,
        *,
        callable: typing.Callable[[google.protobuf.message.Message], typing.Awaitable],
        aborted_type: type[reboot.aio.aborted.Aborted],
        request_type: type[google.protobuf.message.Message],
        json_request: str,
    ) -> str:
        request = request_type()

        google.protobuf.json_format.Parse(json_request, request)

        try:
            response = await callable(request)
        except BaseException as exception:
            if isinstance(exception, aborted_type):
                return json.dumps(
                    {
                        'status': google.protobuf.json_format.MessageToDict(
                            exception.to_status()
                        )
                    }
                )
            raise
        else:
            return json.dumps(
                {
                    'response': google.protobuf.json_format.MessageToDict(
                        response
                    )
                }
            )

    async def _schedule(  # type: ignore[override]
        self,
        *,
        method: str,
        context: reboot.aio.contexts.WriterContext | reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        schedule: datetime,
        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency],
        request_type: type[google.protobuf.message.Message],
        json_request: str,
    ) -> str:
        request = request_type()

        google.protobuf.json_format.Parse(json_request, request)

        if isinstance(context, reboot.aio.contexts.WriterContext):
            task = getattr(
                MemoizeServicerTasksStub(
                    context=context,
                    state_ref=context._state_ref,
                ),
                method,
            )(request, schedule=schedule)

            return json.dumps(
                {
                    'taskId': google.protobuf.json_format.MessageToDict(
                        task.task_id
                    )
                }
            )

        # Add scheduling information to the metadata.
        metadata: reboot.aio.types.GrpcMetadata = (
            (reboot.aio.headers.TASK_SCHEDULE, schedule.isoformat()),
        )

        task_id = await getattr(super()._tasks(context), method)(
            request,
            idempotency=idempotency,
            metadata=metadata,
        )

        return json.dumps(
            {
                'taskId': google.protobuf.json_format.MessageToDict(task_id)
            }
        )

    async def _reader(  # type: ignore[override]
        self,
        method: str,
        context: reboot.aio.contexts.ReaderContext | reboot.aio.contexts.WriterContext | reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        request_type: type[google.protobuf.message.Message],
        json_request: str,
        json_options: str,
    ) -> str:
        options = json.loads(json_options)
        method_handle = functools.partial(
            getattr(super()._reader(context), method),
            bearer_token=options.get("bearerToken"),
        )
        return await self._call(
            callable=method_handle,
            aborted_type=getattr(
                Memoize, method + 'Aborted'
            ),
            request_type=request_type,
            json_request=json_request,
        )

    async def _writer(  # type: ignore[override]
        self,
        method: str,
        context: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        request_type: type[google.protobuf.message.Message],
        json_request: str,
        json_options: str,
    ) -> str:
        options = json.loads(json_options)

        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None

        if 'idempotency' in options:
            idempotency = reboot.aio.contexts.Context.idempotency(
                alias=options['idempotency'].get('alias'),
                key=options['idempotency'].get('key'),
                each_iteration=options['idempotency'].get('eachIteration', None),
            )

        if 'schedule' in options:
            when = timestamp_pb2.Timestamp()
            when.FromJsonString(options['schedule']['when'])
            return await self._schedule(
                method=method,
                context=context,
                schedule=when.ToDatetime(),
                idempotency=idempotency,
                request_type=request_type,
                json_request=json_request,
            )

        method_handle = functools.partial(
            getattr(super()._writer(context), method),
            idempotency=idempotency,
            bearer_token=options.get("bearerToken"),
        )
        return await self._call(
            callable=method_handle,
            aborted_type=getattr(
                Memoize, method + 'Aborted'
            ),
            request_type=request_type,
            json_request=json_request,
        )

    async def _transaction(  # type: ignore[override]
        self,
        method: str,
        context: reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        request_type: type[google.protobuf.message.Message],
        json_request: str,
        json_options: str,
    ) -> str:
        options = json.loads(json_options)

        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None

        if 'idempotency' in options:
            idempotency = reboot.aio.contexts.Context.idempotency(
                alias=options['idempotency'].get('alias'),
                key=options['idempotency'].get('key'),
                each_iteration=options['idempotency'].get('eachIteration', None),
            )

        if 'schedule' in options:
            when = timestamp_pb2.Timestamp()
            when.FromJsonString(options['schedule']['when'])
            return await self._schedule(
                method=method,
                context=context,
                schedule=when.ToDatetime(),
                idempotency=idempotency,
                request_type=request_type,
                json_request=json_request,
            )

        method_handle = functools.partial(
            getattr(super()._workflow(context), method),
            idempotency=idempotency,
            bearer_token=options.get("bearerToken"),
        )
        return await self._call(
            callable=method_handle,
            aborted_type=getattr(
                Memoize, method + 'Aborted'
            ),
            request_type=request_type,
            json_request=json_request,
        )

    async def _workflow(  # type: ignore[override]
        self,
        method: str,
        context: reboot.aio.contexts.WriterContext | reboot.aio.contexts.TransactionContext | reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        request_type: type[google.protobuf.message.Message],
        json_request: str,
        json_options: str,
    ) -> str:
        options = json.loads(json_options)

        idempotency: typing.Optional[reboot.aio.idempotency.Idempotency] = None

        if 'idempotency' in options:
            idempotency = reboot.aio.contexts.Context.idempotency(
                alias=options['idempotency'].get('alias'),
                key=options['idempotency'].get('key'),
                each_iteration=options['idempotency'].get('eachIteration', None),
            )

        assert 'schedule' in options

        when = timestamp_pb2.Timestamp()
        when.FromJsonString(options['schedule']['when'])

        return await self._schedule(
            method=method,
            context=context,
            schedule=when.ToDatetime(),
            idempotency=idempotency,
            request_type=request_type,
            json_request=json_request,
        )

    async def _future_await(  # type: ignore[override]
        self,
        method: str,
        context: reboot.aio.contexts.WorkflowContext | reboot.aio.external.ExternalContext,
        json_task_id: str,
    ) -> str:
        future = getattr(
            Memoize, method + 'Future'
        )(
            context,
            task_id=google.protobuf.json_format.Parse(
                json_task_id,
                tasks_pb2.TaskId(),
            ),
        )

        try:
            response = await future
        except BaseException as exception:
            if isinstance(exception, reboot.aio.aborted.Aborted):
                return json.dumps(
                    {
                        'status': google.protobuf.json_format.MessageToDict(
                            exception.to_status()
                        )
                    }
                )
            raise
        else:
            return json.dumps(
                {
                    'response': google.protobuf.json_format.MessageToDict(
                        response
                    )
                }
            )

# yapf: enable
