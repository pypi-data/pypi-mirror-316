{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following to check if the container is running:\n",
    "\n",
    "```$ docker ps --format \"table {{.Image}}\\t{{.Names}}\\t{{.Status}}\" | grep gai-ttt```\n",
    "\n",
    "Once it is started, the status will look like this:\n",
    "\n",
    "```gai-ttt:latest   gai-ttt   Up 2 minutes```\n",
    "\n",
    "Otherwise, run `gai docker start`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Patch OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "console = Console()\n",
    "\n",
    "import os\n",
    "# Replace this with your OpenAI API key if you want to use it\n",
    "if os.environ.get(\"OPENAI_API_KEY\") is None:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# Load and patch openai\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "from gai.ttt.client.completions import Completions\n",
    "\n",
    "# get url from default client config\n",
    "from gai.lib.config.config_utils import get_client_config\n",
    "\n",
    "client = Completions.PatchOpenAI(client, get_client_config(\"ttt\").url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Create Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffff00; text-decoration-color: #ffff00\">Use Exllama create:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[93mUse Exllama create:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[41m\u001b[30mERROR   \u001b[0m \u001b[31mcompletions._generate_dict: error='NoneType' object has no attribute 'startswith' response=None\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'startswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Use exllama\u001b[39;00m\n\u001b[1;32m     10\u001b[0m console\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[bright_yellow]Use Exllama create:[/]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m response\u001b[38;5;241m=\u001b[39m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexllamav2-mistral7b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTell me a one sentence story\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m console\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[bright_white italic]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m[/]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m console\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[bright_white italic]extract:[/]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/github/kakkoii1337/gai-sdk/gai-ttt/src/gai/ttt/client/completions.py:149\u001b[0m, in \u001b[0;36mCompletions.PatchOpenAI.<locals>.patched_create\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# \"self\" refers to the patched client.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# And if it contains override_url, that means the Completion Class is not used directly but is called via TTTClient with a custom URL, probably for testing.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     url \u001b[38;5;241m=\u001b[39m openai_client\u001b[38;5;241m.\u001b[39moverride_url\n\u001b[0;32m--> 149\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mCompletions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_schema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     response \u001b[38;5;241m=\u001b[39m attach_extractor(response,stream)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# fallback to openai's completions.create\u001b[39;00m\n",
      "File \u001b[0;32m~/github/kakkoii1337/gai-sdk/gai-ttt/src/gai/ttt/client/completions.py:249\u001b[0m, in \u001b[0;36mCompletions._create\u001b[0;34m(self, url, messages, stream, max_tokens, temperature, top_p, top_k, json_schema, tools, tool_choice, stop, timeout)\u001b[0m\n\u001b[1;32m    234\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url,\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m:timeout\n\u001b[1;32m    247\u001b[0m }\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 249\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (chunk \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream_dict(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/github/kakkoii1337/gai-sdk/gai-ttt/src/gai/ttt/client/completions.py:188\u001b[0m, in \u001b[0;36mCompletions._generate_dict\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    187\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletions._generate_dict: error=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m response=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
      "File \u001b[0;32m~/github/kakkoii1337/gai-sdk/gai-ttt/src/gai/ttt/client/completions.py:181\u001b[0m, in \u001b[0;36mCompletions._generate_dict\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m timeout \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;241m30.0\u001b[39m)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 181\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mhttp_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     jsoned\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    183\u001b[0m     completion \u001b[38;5;241m=\u001b[39m ChatCompletion(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjsoned)\n",
      "File \u001b[0;32m~/github/kakkoii1337/gai-sdk/gai-lib/src/gai/lib/common/http_utils.py:68\u001b[0m, in \u001b[0;36mhttp_post\u001b[0;34m(url, data, files, timeout)\u001b[0m\n\u001b[1;32m     66\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttppost:data=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpprint\u001b[38;5;241m.\u001b[39mpformat(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Disable SSL verification if URL is for localhost\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m verify_ssl \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[43murl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://localhost\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m url\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://127.0.0.1\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     69\u001b[0m gai_api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     70\u001b[0m headers \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'startswith'"
     ]
    }
   ],
   "source": [
    "# Use openai\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    console.print(\"[yellow]Use GPT-4o create:[/]\")\n",
    "    response=client.chat.completions.create(model=\"gpt-4o\",messages=[{\"role\":\"user\",\"content\":\"Tell me a one sentence story\"}])\n",
    "    console.print(f\"[white]{response}[/]\")\n",
    "    console.print(\"[white]extract:[/]\")\n",
    "    print(f\"[white]{response.extract()}[/]\")\n",
    "\n",
    "# Use exllama\n",
    "console.print(\"[bright_yellow]Use Exllama create:[/]\")\n",
    "response=client.chat.completions.create(model=\"exllamav2-mistral7b\",messages=[{\"role\":\"user\",\"content\":\"Tell me a one sentence story\"}])\n",
    "console.print(f\"[bright_white italic]{response}[/]\")\n",
    "console.print(\"[bright_white italic]extract:[/]\")\n",
    "console.print(f\"[bright_white italic]{response.extract()}[/]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Stream Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffff00; text-decoration-color: #ffff00\">Use Exllama stream:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[93mUse Exllama stream:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A young girl found a lost puppy and took it home to care for it"
     ]
    }
   ],
   "source": [
    "# Use openai\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    console.print(\"[yellow]Use GPT-4o stream:[/]\")\n",
    "    response=client.chat.completions.create(model=\"gpt-4o\",messages=[{\"role\":\"user\",\"content\":\"Tell me a one sentence story\"}],stream=True)\n",
    "    for chunk in response:\n",
    "        chunk = chunk.extract()\n",
    "        if chunk and type(chunk) is str:\n",
    "            print(chunk,end=\"\",flush=True)\n",
    "print()\n",
    "# Use exllama\n",
    "console.print(\"[bright_yellow]Use Exllama stream:[/]\")\n",
    "response=client.chat.completions.create(model=\"exllamav2-mistral7b\",messages=[{\"role\":\"user\",\"content\":\"Tell me a one sentence story\"}],stream=True)\n",
    "for chunk in response:\n",
    "    chunk = chunk.extract()\n",
    "    if chunk and type(chunk) is str:\n",
    "            print(chunk,end=\"\",flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Create Tool Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffff00; text-decoration-color: #ffff00\">Use Exllama create:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[93mUse Exllama create:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-weight: bold; font-style: italic\">{</span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">\"type\"</span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">: </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">\"function\"</span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">,</span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">\"name\"</span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">: </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">\"google\"</span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">,</span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">\"arguments\"</span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">: </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">\"{\\\"search_query\\\": \\\"current time Singapore\\\"}\"</span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-weight: bold; font-style: italic\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;97m{\u001b[0m\n",
       "\u001b[3;97m  \u001b[0m\u001b[3;97m\"type\"\u001b[0m\u001b[3;97m: \u001b[0m\u001b[3;97m\"function\"\u001b[0m\u001b[3;97m,\u001b[0m\n",
       "\u001b[3;97m  \u001b[0m\u001b[3;97m\"name\"\u001b[0m\u001b[3;97m: \u001b[0m\u001b[3;97m\"google\"\u001b[0m\u001b[3;97m,\u001b[0m\n",
       "\u001b[3;97m  \u001b[0m\u001b[3;97m\"arguments\"\u001b[0m\u001b[3;97m: \u001b[0m\u001b[3;97m\"\u001b[0m\u001b[3;97m{\u001b[0m\u001b[3;97m\\\"search_query\\\": \\\"current time Singapore\\\"\u001b[0m\u001b[3;97m}\u001b[0m\u001b[3;97m\"\u001b[0m\n",
       "\u001b[1;3;97m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use openai\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    console.print(\"[yellow]Use GPT-4o create tool call:[/]\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"What is the current time in Singapore?\"}],\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"google\",\n",
    "                    \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"search_query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"search_query\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        tool_choice=\"required\",\n",
    "        stream=False\n",
    "    )\n",
    "    console.print(f\"[bright_white italic]{json.dumps(response.extract(),indent=2)}[/]\")\n",
    "    print()\n",
    "\n",
    "# Use exllama\n",
    "console.print(\"[bright_yellow]Use Exllama create:[/]\")\n",
    "response = client.chat.completions.create(\n",
    "    model=\"exllamav2-mistral7b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the current time in Singapore?\"},\n",
    "              {\"role\": \"assistant\",\"content\":\"\"}],\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"google\",\n",
    "                \"description\": \"The 'google' function is a powerful tool that allows the AI to gather external information from the internet using Google search. It can be invoked when the AI needs to answer a question or provide information that requires up-to-date, comprehensive, and diverse sources which are not inherently known by the AI. For instance, it can be used to find current date, current news, weather updates, latest sports scores, trending topics, specific facts, or even the current date and time. The usage of this tool should be considered when the user's query implies or explicitly requests recent or wide-ranging data, or when the AI's inherent knowledge base may not have the required or most current information. The 'search_query' parameter should be a concise and accurate representation of the information needed.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"search_query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The search query to search google with. For example, to find the current date or time, use 'current date' or 'current time' respectively.\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"search_query\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    tool_choice=\"required\",\n",
    "    stream=False\n",
    ")\n",
    "import json\n",
    "console.print(f\"[bright_white italic]{json.dumps(response.extract(),indent=2)}[/]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) JSON Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffff00; text-decoration-color: #ffff00\">Use Exllama create:</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[93mUse Exllama create:\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-weight: bold; font-style: italic\">{</span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">\"type\"</span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">: </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">\"content\"</span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">,</span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">  </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">\"content\"</span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">: </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">\" {\\n    \\\"title\\\": \\\"Foundation\\\",\\n    \\\"summary\\\": \\\"Foundation is a science fiction novel by </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">American writer Isaac Asimov. It is the first published in his Foundation Trilogy (later expanded into the </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">Foundation series). Foundation is a cycle of five interrelated short stories, first published as a single book by </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">Gnome Press in 1951. Collectively they tell the early story of the Foundation, an institute founded by </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">psychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic </span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-style: italic\">Empire.\\\",\\n    \\\"author\\\": \\\"Isaac Asimov\\\",\\n    \\\"published_year\\\": 1951\\n}\"</span>\n",
       "<span style=\"color: #ffffff; text-decoration-color: #ffffff; font-weight: bold; font-style: italic\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;3;97m{\u001b[0m\n",
       "\u001b[3;97m  \u001b[0m\u001b[3;97m\"type\"\u001b[0m\u001b[3;97m: \u001b[0m\u001b[3;97m\"content\"\u001b[0m\u001b[3;97m,\u001b[0m\n",
       "\u001b[3;97m  \u001b[0m\u001b[3;97m\"content\"\u001b[0m\u001b[3;97m: \u001b[0m\u001b[3;97m\" \u001b[0m\u001b[3;97m{\u001b[0m\u001b[3;97m\\n    \\\"title\\\": \\\"Foundation\\\",\\n    \\\"summary\\\": \\\"Foundation is a science fiction novel by \u001b[0m\n",
       "\u001b[3;97mAmerican writer Isaac Asimov. It is the first published in his Foundation Trilogy \u001b[0m\u001b[3;97m(\u001b[0m\u001b[3;97mlater expanded into the \u001b[0m\n",
       "\u001b[3;97mFoundation series\u001b[0m\u001b[3;97m)\u001b[0m\u001b[3;97m. Foundation is a cycle of five interrelated short stories, first published as a single book by \u001b[0m\n",
       "\u001b[3;97mGnome Press in 1951. Collectively they tell the early story of the Foundation, an institute founded by \u001b[0m\n",
       "\u001b[3;97mpsychohistorian Hari Seldon to preserve the best of galactic civilization after the collapse of the Galactic \u001b[0m\n",
       "\u001b[3;97mEmpire.\\\",\\n    \\\"author\\\": \\\"Isaac Asimov\\\",\\n    \\\"published_year\\\": 1951\\n\u001b[0m\u001b[3;97m}\u001b[0m\u001b[3;97m\"\u001b[0m\n",
       "\u001b[1;3;97m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    summary: str\n",
    "    author: str\n",
    "    published_year: int\n",
    "response_model = Book.schema()\n",
    "\n",
    "data = \"\"\"Foundation is a science fiction novel by American writer\n",
    "        Isaac Asimov. It is the first published in his Foundation Trilogy (later\n",
    "        expanded into the Foundation series). Foundation is a cycle of five\n",
    "        interrelated short stories, first published as a single book by Gnome Press\n",
    "        in 1951. Collectively they tell the early story of the Foundation,\n",
    "        an institute founded by psychohistorian Hari Seldon to preserve the best\n",
    "        of galactic civilization after the collapse of the Galactic Empire.\"\"\"\n",
    "\n",
    "# Use openai\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "\n",
    "    console.print(\"[yellow]Use GPT-4o stream:[/]\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        tool_choice=\"none\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Refer to the following content:\\n\\n{data}\\n\\nFormat it into JSON validated by this schema:{response_model}\"}],\n",
    "        stream=False\n",
    "    )\n",
    "    console.print(f\"[bright_white italic]{json.dumps(response.extract(), indent=2)}[/]\")\n",
    "    print()\n",
    "\n",
    "# Use exllama\n",
    "console.print(\"[bright_yellow]Use Exllama create:[/]\")\n",
    "response = client.chat.completions.create(\n",
    "    model=\"exllamav2-mistral7b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": f\"Refer to the following content:\\n\\n{data}\\n\\nFormat it into JSON validated by this schema:{response_model}\"}],\n",
    "    response_model=response_model,\n",
    "    tool_choice=\"none\",\n",
    "    stream=False\n",
    ")\n",
    "import json\n",
    "console.print(f\"[bright_white italic]{json.dumps(response.extract(), indent=2)}[/]\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
