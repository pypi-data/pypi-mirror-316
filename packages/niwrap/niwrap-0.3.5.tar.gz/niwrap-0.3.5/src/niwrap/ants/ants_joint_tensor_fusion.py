# This file was auto generated by Styx.
# Do not edit this file directly.

import typing
import pathlib
from styxdefs import *
import dataclasses

ANTS_JOINT_TENSOR_FUSION_METADATA = Metadata(
    id="0060c77e83025b09ff07322e714ad4f9d9337634.boutiques",
    name="antsJointTensorFusion",
    package="ants",
    container_image_tag="antsx/ants:v2.5.3",
)


class AntsJointTensorFusionOutputs(typing.NamedTuple):
    """
    Output object returned when calling `ants_joint_tensor_fusion(...)`.
    """
    root: OutputPathType
    """Output root folder. This is the root folder for all outputs."""
    label_fusion_image: OutputPathType
    """The label fusion image output."""
    intensity_fusion_image: OutputPathType
    """The intensity fusion image output."""
    label_posterior_probability_image: OutputPathType
    """The label posterior probability images."""
    atlas_voting_weight_image: OutputPathType
    """The atlas voting weight images."""


def ants_joint_tensor_fusion(
    target_image: list[str],
    atlas_image: list[str],
    atlas_segmentation: InputPathType,
    output: str,
    dimensionality: typing.Literal[2, 3, 4] | None = None,
    alpha: float | None = 0.1,
    beta: float | None = 2.0,
    retain_label_posterior_images: typing.Literal[0, 1] | None = None,
    retain_atlas_voting_images: typing.Literal[0, 1] | None = None,
    constrain_nonnegative: typing.Literal[0, 1] | None = None,
    log_euclidean: typing.Literal[0, 1] | None = None,
    patch_radius: str | None = None,
    patch_metric: typing.Literal["PC", "MSQ"] | None = None,
    search_radius: str | None = None,
    exclusion_image: str | None = None,
    mask_image: InputPathType | None = None,
    verbose: typing.Literal[0, 1] | None = None,
    runner: Runner | None = None,
) -> AntsJointTensorFusionOutputs:
    """
    antsJointTensorFusion is an image fusion algorithm developed by Hongzhi Wang and
    Paul Yushkevich which won segmentation challenges at MICCAI 2012 and MICCAI
    2013. The original label fusion framework was extended to accommodate
    intensities by Brian Avants. This implementation is based on the original
    ITK-style implementation and ANTsR implementation.
    
    Author: ANTs Developers
    
    URL: https://github.com/ANTsX/ANTs
    
    Args:
        target_image: The target image (or multimodal target images) assumed to\
            be aligned to a common image domain.
        atlas_image: The atlas image (or multimodal atlas images) assumed to be\
            aligned to a common image domain.
        atlas_segmentation: The atlas segmentation images. For performing label\
            fusion the number of specified segmentations should be identical to the\
            number of atlas image sets.
        output: The output is the intensity and/or label fusion image.\
            Additional optional outputs include the label posterior probability\
            images and the atlas voting weight images.
        dimensionality: This option forces the image to be treated as a\
            specified-dimensional image. If not specified, the program tries to\
            infer the dimensionality from the input image.
        alpha: Regularization term added to matrix Mx for calculating the\
            inverse. Default = 0.1.
        beta: Exponent for mapping intensity difference to the joint error.\
            Default = 2.0.
        retain_label_posterior_images: Retain label posterior probability\
            images. Requires atlas segmentations to be specified. Default = false.
        retain_atlas_voting_images: Retain atlas voting images. Default = false.
        constrain_nonnegative: Constrain solution to non-negative weights.
        log_euclidean: Use log Euclidean space for tensor math.
        patch_radius: Patch radius for similarity measures. Default = 2x2x2.
        patch_metric: Metric to be used in determining the most similar\
            neighborhood patch. Options include Pearson's correlation (PC) and mean\
            squares (MSQ). Default = PC.
        search_radius: Search radius for similarity measures. Default = 3x3x3.
        exclusion_image: Specify an exclusion region for the given label.
        mask_image: If a mask image is specified, fusion is only performed in\
            the mask region.
        verbose: Verbose output.
        runner: Command runner.
    Returns:
        NamedTuple of outputs (described in `AntsJointTensorFusionOutputs`).
    """
    runner = runner or get_global_runner()
    execution = runner.start_execution(ANTS_JOINT_TENSOR_FUSION_METADATA)
    cargs = []
    cargs.append("antsJointTensorFusion")
    if dimensionality is not None:
        cargs.extend([
            "--image-dimensionality",
            str(dimensionality)
        ])
    cargs.extend([
        "-t",
        ",".join(target_image)
    ])
    cargs.extend([
        "-g",
        ",".join(atlas_image)
    ])
    cargs.extend([
        "-l",
        execution.input_file(atlas_segmentation)
    ])
    if alpha is not None:
        cargs.extend([
            "-a",
            str(alpha)
        ])
    if beta is not None:
        cargs.extend([
            "-b",
            str(beta)
        ])
    if retain_label_posterior_images is not None:
        cargs.extend([
            "-r",
            str(retain_label_posterior_images)
        ])
    if retain_atlas_voting_images is not None:
        cargs.extend([
            "-f",
            str(retain_atlas_voting_images)
        ])
    if constrain_nonnegative is not None:
        cargs.extend([
            "-c",
            str(constrain_nonnegative)
        ])
    if log_euclidean is not None:
        cargs.extend([
            "-u",
            str(log_euclidean)
        ])
    if patch_radius is not None:
        cargs.extend([
            "-p",
            patch_radius
        ])
    if patch_metric is not None:
        cargs.extend([
            "-m",
            patch_metric
        ])
    if search_radius is not None:
        cargs.extend([
            "-s",
            search_radius
        ])
    if exclusion_image is not None:
        cargs.extend([
            "-e",
            exclusion_image
        ])
    if mask_image is not None:
        cargs.extend([
            "-x",
            execution.input_file(mask_image)
        ])
    cargs.extend([
        "-o",
        output
    ])
    if verbose is not None:
        cargs.extend([
            "-v",
            str(verbose)
        ])
    ret = AntsJointTensorFusionOutputs(
        root=execution.output_file("."),
        label_fusion_image=execution.output_file(output + "_LabelFusion.nii.gz"),
        intensity_fusion_image=execution.output_file(output + "_IntensityFusion.nii.gz"),
        label_posterior_probability_image=execution.output_file(output + "_LabelPosterior.nii.gz"),
        atlas_voting_weight_image=execution.output_file(output + "_AtlasVoting.nii.gz"),
    )
    execution.run(cargs)
    return ret


__all__ = [
    "ANTS_JOINT_TENSOR_FUSION_METADATA",
    "AntsJointTensorFusionOutputs",
    "ants_joint_tensor_fusion",
]
